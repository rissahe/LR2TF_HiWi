{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "import anndata as ad\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import scanpy as sc\n",
    "import decoupler as dc\n",
    "import os\n",
    "import re\n",
    "import statistics\n",
    "#import pyreadr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def validate_input_arguments (arguments_list):\n",
    "    if arguments_list[\"out_path\"] is None:\n",
    "        print(\"Please provide an output path\")\n",
    "    elif arguments_list[\"out_path\"][-1] != \"/\":\n",
    "        arguments_list[\"out_path\"] = arguments_list[\"out_path\"] + \"/\"\n",
    "\n",
    "    if arguments_list[\"celltype\"] is None:\n",
    "        print(\"Please provide the name of the metadata field containing cell type annotations\")\n",
    "\n",
    "    if arguments_list[\"condition\"] is None:\n",
    "        print(\"Please provide the name of the metadata field containing condition annotations\")\n",
    "\n",
    "    if arguments_list[\"organism\"] is None:\n",
    "        arguments_list[\"organism\"] = \"human\"\n",
    "\n",
    "    if arguments_list[\"comparison_list\"] is None:\n",
    "        arguments_list[\"comparison_list\"] = np.nan\n",
    "\n",
    "    if arguments_list[\"logfc\"] is None:\n",
    "        arguments_list[\"logfc\"] = 0.0\n",
    "\n",
    "    if arguments_list [\"pval\"] is None:\n",
    "        arguments_list[\"pval\"] = 0.05\n",
    "\n",
    "    if arguments_list[\"reg\"] is None:\n",
    "        arguments_list[\"reg\"] = load_dorothea_regulon(arguments_list[\"organism\"])\n",
    "\n",
    "    elif isinstance(arguments_list[\"reg\"], str):\n",
    "        arguments_list[\"reg\"] = pd.read_csv(arguments_list[\"reg\"], index_col=0)\n",
    "        arguments_list[\"reg\"] = pd.DataFrame.rename(arguments_list[\"reg\"], columns={\"source\" : \"tf\"})\n",
    "\n",
    "    if not \"tf\" in arguments_list[\"reg\"] and \"target\" in arguments_list[\"reg\"] and \"weight\"in arguments_list[\"reg\"]:\n",
    "        raise Exception(\"Not all necessary columns found in regulon table! Please make sure that the regulon has the columns source, target and weight!\")\n",
    "    \n",
    " \n",
    "   \n",
    "    return(arguments_list)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def AverageExpression(sub_object, celltype = None, name_iterable = None, outpath = None):\n",
    "    gene_ids = sub_object.var.index.values\n",
    "    #cluster line even necessary if not returned?\n",
    "    #clusters = anndataobject.obs[celltype].cat.categories\n",
    "    obs = sub_object[:,gene_ids].X.toarray()\n",
    "    obs = np.expm1(obs)\n",
    "    avg_df = pd.DataFrame(obs,columns=gene_ids,index= sub_object.obs[celltype])\n",
    "    avg_df = avg_df.groupby(level=0, observed=False).mean()\n",
    "    avg_df.T.to_csv(outpath + name_iterable + \"_average_gene_expression_by_cluster_exp.csv\")\n",
    "\n",
    "    return avg_df.T\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def eval_pval(p_val):\n",
    "    p_val = float(p_val)\n",
    "    if p_val < 0.001: \n",
    "      txt = \"***\"\n",
    "    elif p_val < 0.01: \n",
    "      txt = \"**\"\n",
    "    elif p_val < 0.05: \n",
    "      txt = \"*\"\n",
    "    else:\n",
    "      txt = \"ns\"\n",
    "    return(txt)\n",
    "\n",
    "\n",
    "def eval_log_fc_tag(log_fc):\n",
    "    if log_fc >= 1.0: \n",
    "      txt = \"***\"\n",
    "    elif log_fc > 0.5: \n",
    "      txt = \"**\"\n",
    "    elif log_fc > 0.0: \n",
    "      txt = \"*\"\n",
    "    else:\n",
    "      txt = \"ns\"\n",
    "    return(txt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_unfiltered_tf_scores(tf_scores_df, condition, celltype, out_path):   \n",
    "    summarized_tf_scores_df = tf_scores_df.groupby((\"gene\", celltype), observed = False).mean().T\n",
    "    summarized_tf_scores_df.to_csv(out_path + '/unfiltered_tf_scores_' + condition + '.csv')\n",
    "    return summarized_tf_scores_df\n",
    "\n",
    "#np.var() returns a value that is different from R's var(), whereas statistics.variance() is the same as R's var()\n",
    "def save_variable_tf_score(filtered_summarized_tf_scores_df, condition, out_path):\n",
    "    filtered_summarized_tf_scores_df[\"var\"] = filtered_summarized_tf_scores_df.apply(statistics.variance, axis=1)\n",
    "    filtered_summarized_tf_scores_df.to_csv(out_path + '/variable_tf_scores_' + condition + '.csv')\n",
    "    return filtered_summarized_tf_scores_df\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#def map_z_value_filtered(filtered_summarized_tf_scores_df, anndataobject_markers):\n",
    " #   z_score = []\n",
    " #   for gene in anndataobject_markers[\"gene\"]:\n",
    " #       if gene in filtered_summarized_tf_scores_df.index:\n",
    " #           z_score.append(filtered_summarized_tf_scores_df.loc[gene, anndataobject_markers[\"cluster\"]])\n",
    " #   return z_score\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "#not per cluster but cluster and pval etc need to be added to csv (check against specific marker csv from lr2tf test run in R)\n",
    "\n",
    "def get_significant_tfs_single(tf_activities_sub, celltype, condition, out_path, pval, logfc, name):\n",
    "    \n",
    "    #does not work if condition is None\n",
    "    renamed_condition = condition.replace(\",\", \"_\")\n",
    "    name = name.replace(\",\", \"_\")\n",
    "\n",
    "    single_result_path = out_path + renamed_condition \n",
    "    if not os.path.isdir(single_result_path):\n",
    "        os.mkdir(single_result_path)\n",
    "    \n",
    "    \n",
    "    #tf_activities_scaled = sc.pp.scale(tf_activities_sub, copy=True, max_value=10)\n",
    "    #or sc.pp.normalize_total(anndataobject)\n",
    "    #sc.pp.log1p(tf_activities) \n",
    "    # \"warning: seems to be already log transformed\"\n",
    "\n",
    "    number_of_clusters = len(tf_activities_sub.obs[\"new_annotation\"].cat.categories) \n",
    "\n",
    "\n",
    "    sc.tl.rank_genes_groups(tf_activities_sub, groupby= \"new_annotation\", reference=\"rest\", method=\"wilcoxon\", key_added=\"wilcoxon_markers\", corr_method= \"bonferroni\")\n",
    "    #sc.tl.filter_rank_genes_groups(anndataobject, min_in_group_fraction=0, key=\"wilcoxon_markers\", key_added= \"wilcoxon_markers_filtered\")\n",
    "    \n",
    "\n",
    "    sc.tl.rank_genes_groups(tf_activities_sub, groupby= \"new_annotation\", reference=\"rest\", method=\"t-test_overestim_var\", key_added=\"t_test_overestim_var_markers\", corr_method= \"bonferroni\" )\n",
    "    #sc.tl.filter_rank_genes_groups(anndataobject, min_in_group_fraction=0, key=\"t_test_overestim_var_markers\", key_added=\"t_test_overestim_filtered\")\n",
    "\n",
    "    #FindAllMarkers(seuratobject, only.pos = TRUE, min.pct = 0, logfc.threshold = 0, verbose = FALSE)\n",
    "\n",
    "    result1 = tf_activities_sub.uns['wilcoxon_markers']\n",
    "    groups = result1['names'].dtype.names\n",
    "    anndataobject_markers = pd.DataFrame(\n",
    "    {group + '_' + key[:1]: result1[key][group]\n",
    "    for group in groups for key in ['names','logfoldchanges','pvals','pvals_adj']})\n",
    "\n",
    "    result2 = tf_activities_sub.uns['t_test_overestim_var_markers']\n",
    "    groups = result2['names'].dtype.names\n",
    "    anndataobject_markers = pd.DataFrame(\n",
    "    {group + '_' + key[:1]: result2[key][group]\n",
    "    for group in groups for key in ['names','logfoldchanges','pvals','pvals_adj']})\n",
    "\n",
    "    anndataobject_markers_wilcoxon = sc.get.rank_genes_groups_df(tf_activities_sub, group = None, log2fc_min=0, key=\"wilcoxon_markers\")\n",
    "    \n",
    "    anndataobject_markers_wilcoxon.rename(columns={\"names\":\"gene\", \"group\": \"cluster\"}, inplace=True)\n",
    "    \n",
    "    #documentation says this won't update the main dataframe but will only overwrite a copy in future pandas versions (after v3)\n",
    "    anndataobject_markers_wilcoxon[\"tag\"] = None\n",
    "    anndataobject_markers_wilcoxon[\"log_fc_tag\"] = None\n",
    "    for i in range(len(anndataobject_markers_wilcoxon[\"pvals_adj\"])):\n",
    "         anndataobject_markers_wilcoxon[\"tag\"].iloc[i,] = eval_pval(anndataobject_markers_wilcoxon[\"pvals_adj\"].iloc[i,])\n",
    "         anndataobject_markers_wilcoxon[\"log_fc_tag\"].iloc[i,] = eval_log_fc_tag(anndataobject_markers_wilcoxon[\"logfoldchanges\"].iloc[i,])\n",
    "     \n",
    "\n",
    "    anndataobject_markers_wilcoxon.to_csv(single_result_path + \"/\" + name + \"_specific_markers_wilcoxon_test.csv\",index=0)\n",
    "\n",
    "    anndataobject_markers_t_over = sc.get.rank_genes_groups_df(tf_activities_sub, group = None, log2fc_min=0, key=\"t_test_overestim_var_markers\")\n",
    " \n",
    "    anndataobject_markers_t_over.rename(columns={\"names\":\"gene\", \"group\": \"cluster\"}, inplace=True)\n",
    "\n",
    "    anndataobject_markers_t_over[\"tag\"] = None\n",
    "    anndataobject_markers_t_over[\"log_fc_tag\"] = None\n",
    "    for i in range(len(anndataobject_markers_t_over[\"pvals_adj\"])):\n",
    "         anndataobject_markers_t_over[\"tag\"].iloc[i,] = eval_pval(anndataobject_markers_t_over[\"pvals_adj\"].iloc[i,])\n",
    "         anndataobject_markers_t_over[\"log_fc_tag\"].iloc[i,] = eval_pval(anndataobject_markers_t_over[\"logfoldchanges\"].iloc[i,])\n",
    "\n",
    "    anndataobject_markers_t_over.to_csv(single_result_path + \"/\" + name + \"_specific_markers_t_test_overestim_test.csv\",index=0)\n",
    "\n",
    "   #tag mapping wilcoxon\n",
    "    tag_mapping_wilcox = anndataobject_markers_wilcoxon[[\"gene\", \"tag\", \"log_fc_tag\", \"cluster\", \"pvals_adj\", \"logfoldchanges\"]]\n",
    "\n",
    "    tag_mapping_wilcox = tag_mapping_wilcox[(tag_mapping_wilcox[\"pvals_adj\"] < float(pval)) & \n",
    "                              ((tag_mapping_wilcox[\"logfoldchanges\"] > float(logfc)) | \n",
    "                              (tag_mapping_wilcox[\"logfoldchanges\"] < -float(logfc)))]\n",
    "\n",
    "    tag_mapping_wilcox = tag_mapping_wilcox.pivot(index=\"gene\", columns=\"cluster\", values=\"tag\")\n",
    "    tag_mapping_wilcox.fillna(\"ns\", inplace=True)\n",
    "\n",
    "    tf_activities_sub.obs_names = tf_activities_sub.obs[celltype]\n",
    "    tf_scores_df = tf_activities_sub.to_df()\n",
    "    print(tf_scores_df)\n",
    "    unfiltered_tf_scores = create_unfiltered_tf_scores(tf_scores_df, condition, celltype, single_result_path)\n",
    "   \n",
    "    #Filter to only include tfs that match the tag_mapping/are markers\n",
    "    col_num = tf_scores_df.columns.isin(tag_mapping_wilcox.index)  \n",
    "    filtered_tf_scores_df = tf_scores_df.loc[:, col_num] \n",
    "    \n",
    "    filtered_summarized_tf_scores_df = filtered_tf_scores_df.groupby(celltype, observed = False).mean().T\n",
    "    filtered_summarized_tf_scores_df.index.name = \"gene\"\n",
    "    filtered_summarized_tf_scores_df.to_csv(f'{single_result_path}/tf_scores_{condition}.csv')\n",
    "    \n",
    "    tf_scores_variable_table = save_variable_tf_score(filtered_summarized_tf_scores_df, condition, single_result_path)\n",
    "    \n",
    "    #filtered_summarized_tf_scores_df.index = re.sub((\".,\"), \"_\", filtered_summarized_tf_scores_df.index)\n",
    "\n",
    "    \n",
    "    #anndataobject_markers_wilcoxon[\"z_score\"] = map_z_value_filtered(filtered_summarized_tf_scores_df, anndataobject_markers_wilcoxon)\n",
    "    #anndataobject_markers_t_over[\"z_score\"] = map_z_value_filtered(filtered_summarized_tf_scores_df, anndataobject_markers_t_over)\n",
    "    \n",
    "    #res needs to contain gene, pval tag, cluster and z score\n",
    "    #drop doubles??\n",
    "    res_wilcoxon = anndataobject_markers_wilcoxon[[\"gene\",\"tag\", \"cluster\"]]\n",
    "    #res_t_test = anndataobject_markers_t_over[[\"gene\",\"tag\", \"cluster\", \"z_score\"]]\n",
    "\n",
    "    \n",
    "\n",
    "     #//TODO: \n",
    "    #delete one variant and put test type as a variable\n",
    "\n",
    "    return res_wilcoxon #, res_t_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#check if it's okay to not pre set the column type as string or float (maybe no problem in python but was problem in r)\n",
    "\n",
    "def create_empty_CTR_dataframe():\n",
    "  \n",
    "  empty_df = pd.DataFrame(\n",
    "    columns=[\n",
    "    \"source\",\n",
    "    \"target\",\n",
    "    \"gene_A\",\n",
    "    \"gene_B\",\n",
    "    \"type_gene_A\",\n",
    "    \"type_gene_B\",\n",
    "    \"MeanLR\"\n",
    "    ])\n",
    "  \n",
    "  return(empty_df)\n",
    "\n",
    "\n",
    "def add_entry_to_CTR_dataframe(source, target, gene_A, gene_B, type_gene_A, type_gene_B, MeanLR):\n",
    "  df = pd.DataFrame(\n",
    "      source,\n",
    "      target,\n",
    "      gene_A,\n",
    "      gene_B,\n",
    "      type_gene_A,\n",
    "      type_gene_B,\n",
    "      MeanLR)\n",
    "\n",
    "  return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#def generate_CrossTalkeR_input(tf_activities, gene_expression, regulon = None):\n",
    "\n",
    "tf_activities =  pd.read_csv(\"tf_activities_test_wilcox.csv\")  \n",
    "#tf_activities[\"cluster\"] = \"Neural\"\n",
    "gene_expression = pd.read_csv(\"script_test/control_average_gene_expression_by_cluster_exp.csv\", index_col = 0)\n",
    "print(gene_expression)\n",
    "regulon = pd.read_csv(\"filterd_regulon.csv\", index_col = 0)  \n",
    "regulon = regulon.rename(columns={\"source\" : \"tf\"})\n",
    "\n",
    "\n",
    "\n",
    "ligands_readin = pyreadr.read_r(\"ligands_human.rda\")\n",
    "ligands = ligands_readin[\"ligands_human\"]\n",
    "\n",
    "rtf_readin = pyreadr.read_r(\"RTF_DB_2.rda\") \n",
    "rtf_db = rtf_readin[\"RTF_DB_2\"]\n",
    "\n",
    "#put tf as index column/rownames and receptors as column 1\n",
    "\n",
    "R2TF = rtf_db.set_index(\"tf\")\n",
    "\n",
    "sorted_regulon = regulon[[\"tf\", \"target\"]]\n",
    "sorted_regulon.rename(columns={\"target\" : \"targets\"})\n",
    "sorted_regulon = sorted_regulon.set_index(\"tf\")\n",
    "\n",
    "output_df = create_empty_CTR_dataframe()\n",
    "\n",
    "for row in range(len((tf_activities))):\n",
    "\n",
    "  #r_tf = create_empty_CTR_dataframe()\n",
    "  #tf_l = create_empty_CTR_dataframe()\n",
    "\n",
    "  #if (tf_activities[\"z_score\"].iloc[row] == 0):\n",
    "  tf_var = str(tf_activities[\"gene\"].iloc[row])\n",
    "  if tf_var in sorted_regulon.index:\n",
    "    targets = sorted_regulon.loc[tf_var]\n",
    "  if tf_var in R2TF.index:\n",
    "    receptors = R2TF.loc[tf_var]\n",
    "  tf_ligands = np.intersect1d(targets, ligands)\n",
    "  \n",
    "\n",
    "      expressed = False\n",
    "    if ligand in gene_expression.index:\n",
    "      ex_value = gene_expression.loc[ligand, \"Neural\"]\n",
    "      if (ex_value != 0):\n",
    "        expressed = True\n",
    "        \n",
    "    #print(tf_activities.iloc[row[]])\n",
    "    if (expressed == True):\n",
    "      df_list_l = list[tf_activities.iloc[row, 2],\n",
    "                                             tf_activities.iloc[row, 2],\n",
    "                                             tf_activities.iloc[row, 0],\n",
    "                                             ligand,\n",
    "                                             \"Transcription Factor\",\n",
    "                                             \"Ligand\",\n",
    "                                             tf_activities.iloc[row, 3]]\n",
    "      \n",
    "    if (len(receptors) > 0):\n",
    "       for receptor in receptors:\n",
    "         df_list_r = list[tf_activities.iloc[row, 2],\n",
    "                                         tf_activities.iloc[row, 2],\n",
    "                                         receptor,\n",
    "                                         tf_activities.iloc[row, 0],\n",
    "                                         'Receptor',\n",
    "                                         'Transcription Factor',\n",
    "                                         tf_activities.iloc[row, 3]]\n",
    "   \n",
    "tf_l = pd.DataFrame(df_list_l, columns=[\"source\", \"target\", \"gene_A\", \"gene_B\", \"type_gene_A\", \"type_gene_B\", \"MeanLR\"])\n",
    "print(tf_l)\n",
    "r_tf = pd.DataFrame(df_list_r)\n",
    "      \n",
    "  #    r_tf[\"gene_A\"] <- gsub(\"_\", \"+\", r_tf$gene_A, fixed = TRUE)\n",
    "   #   r_tf[\"gene_B\"] <- gsub(\"_\", \"+\", r_tf$gene_B, fixed = TRUE)\n",
    "   #   tf_l[\"gene_A\"] <- gsub(\"_\", \"+\", tf_l$gene_A, fixed = TRUE)\n",
    "   #   tf_l[\"gene_B\"] <- gsub(\"_\", \"+\", tf_l$gene_B, fixed = TRUE)\n",
    "\n",
    "   #   output_df = pd.concat(output_df, r_tf)\n",
    "   #   output_df = pd.concat(output_df, tf_l)\n",
    "\n",
    "  #return output_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#ignore extra tfs from decoupler while writing script \n",
    "\n",
    "def tf_activity_analysis (anndataobject, arguments_list = None):\n",
    "    \n",
    "    if (isinstance(anndataobject, str)):\n",
    "        anndataobject = ad.read_h5ad(anndataobject)\n",
    "\n",
    "    arguments_list = validate_input_arguments(arguments_list)\n",
    "\n",
    "    if not os.path.isdir(arguments_list[\"out_path\"]):\n",
    "        os.mkdir(arguments_list[\"out_path\"])\n",
    "        tf_path = arguments_list[\"out_path\"] + \"TF_results/\"\n",
    "        os.mkdir(tf_path)\n",
    "    else:\n",
    "        tf_path = arguments_list[\"out_path\"] + \"TF_results/\"\n",
    "\n",
    "    #rename the arguments inserted into argument list (eg protocol to condition)\n",
    "    condition = anndataobject.obs[arguments_list[\"condition\"]]\n",
    "\n",
    "    #checks for tf activity csv, if nothing there, runs decoupler\n",
    "    if isinstance(arguments_list[\"tf_activities\"], str):\n",
    "         tf_activities = ad.read_csv(arguments_list[\"tf_activities\"])\n",
    "         tf_activities.obsm = anndataobject.obsm\n",
    "         tf_activities.uns = anndataobject.uns\n",
    "         tf_activities.obs = anndataobject.obs\n",
    "    elif arguments_list[\"tf_activities\"] is None:\n",
    "         dc.run_ulm(mat = anndataobject, net = \"reg\", source ='source', target ='target', weight ='weight', verbose = True, use_raw = False)\n",
    "         tf_activities = anndataobject.obsm['ulm_estimate']\n",
    "         tf_activities.to_csv(\"decoupler_results.csv\")\n",
    "\n",
    "\n",
    "    #sets the stage for decision if single condition or comparison analysis is done\n",
    "\n",
    "    if not np.isnan(arguments_list[\"comparison_list\"]):\n",
    "        if len(arguments_list[\"comparison_list\"]) > 0 & len(anndataobject.obs[\"comparison_list\"]) < 2:\n",
    "            arguments_list[\"comparison_list\"] <- np.nan\n",
    "            print(\"Only one condition was found in the data, although a list of comparisons was provided. The analyses are performed only for the present condition!\")\n",
    "\n",
    "    #code for single condition  analysis\n",
    "\n",
    "    if np.isnan(arguments_list[\"comparison_list\"]):\n",
    "        result_list = []\n",
    "        gene_expression_list = []\n",
    "        CTR_cluster_list = []\n",
    "        intranet_cluster_list = []\n",
    "\n",
    "        #creates loop until after tf activity score\n",
    "        \n",
    "        for name_iterable in anndataobject.obs.protocol.unique():\n",
    "            sub_object = anndataobject[anndataobject.obs.protocol == name_iterable]\n",
    "            tf_activities_sub = tf_activities[tf_activities.obs.protocol == name_iterable]\n",
    "\n",
    "            sub_object_avg = AverageExpression(sub_object, name_iterable= name_iterable, celltype = arguments_list[\"celltype\"], outpath= arguments_list[\"out_path\"])\n",
    "            #check if its fine to only have the average expression as a dataframe and not as part of an anndata object\n",
    "\n",
    "            #check how sub object is returned by average expression (subobject.T) or rename return?\n",
    "            tf_activity_scores = get_significant_tfs_single(tf_activities_sub, celltype = arguments_list[\"celltype\"],condition = name_iterable, out_path= tf_path, pval = arguments_list[\"pval\"], logfc = arguments_list[\"logfc\"], name = name_iterable)\n",
    "           \n",
    "            #tf_activity_scores[0].to_csv(\"tf_activities_test_wilcox.csv\", index = 0)\n",
    "            #tf_activity_scores[1].to_csv(\"tf_activities_test_t_test.csv\", index = 0)\n",
    "\n",
    "            #result_list[[name_iterable]] = tf_activity_scores\n",
    "            #gene_expression_list[[name_iterable + \"_average_expression\"]] = sub_object_avg\n",
    "            \n",
    "            #if (arguments_list[\"organism\"] == \"human\"):\n",
    "            #    CTR_cluster_list[name_iterable] = generate_CrossTalkeR_input(tf_activity_scores[[\"cluster\"]],\n",
    "            #                                                                     gene_expression_list[[(name_iterable + \"_average_expression\")]],\n",
    "            #                                                                     arguments_list[\"reg\"])\n",
    "            #else:\n",
    "            #  CTR_cluster_list[[name_iterable]] = generate_CrossTalkeR_input_mouse(tf_activity_scores[[\"cluster\"]],\n",
    "            #                                                                     gene_expression_list[[(name_iterable + \"_average_expression\")]],\n",
    "            #                                                                     arguments_list[\"reg\"])\n",
    "              \n",
    "            #intranet_cluster_list[[name_iterable]] = generate_intracellular_network(tf_activity_scores[[\"cluster\"]],\n",
    "            #                                                          gene_expression_list[[paste0(name, \"_average_expression\")]],\n",
    "            #                                                          arguments_list$reg,\n",
    "            #                                                          arguments_list$organism)\n",
    "        #return(sub_object) #return tf when finished"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/larissa/miniconda3/envs/testpy/lib/python3.12/site-packages/scanpy/tools/_rank_genes_groups.py:640: ImplicitModificationWarning: Trying to modify attribute `._uns` of view, initializing view as actual.\n",
      "  adata.uns[key_added] = {}\n",
      "/home/larissa/miniconda3/envs/testpy/lib/python3.12/site-packages/scanpy/tools/_rank_genes_groups.py:455: RuntimeWarning: invalid value encountered in log2\n",
      "  self.stats[group_name, \"logfoldchanges\"] = np.log2(\n",
      "/home/larissa/miniconda3/envs/testpy/lib/python3.12/site-packages/scanpy/tools/_rank_genes_groups.py:455: RuntimeWarning: invalid value encountered in log2\n",
      "  self.stats[group_name, \"logfoldchanges\"] = np.log2(\n",
      "/home/larissa/miniconda3/envs/testpy/lib/python3.12/site-packages/scanpy/tools/_rank_genes_groups.py:455: RuntimeWarning: invalid value encountered in log2\n",
      "  self.stats[group_name, \"logfoldchanges\"] = np.log2(\n",
      "/home/larissa/miniconda3/envs/testpy/lib/python3.12/site-packages/scanpy/tools/_rank_genes_groups.py:455: RuntimeWarning: invalid value encountered in log2\n",
      "  self.stats[group_name, \"logfoldchanges\"] = np.log2(\n",
      "/home/larissa/miniconda3/envs/testpy/lib/python3.12/site-packages/scanpy/tools/_rank_genes_groups.py:455: RuntimeWarning: invalid value encountered in log2\n",
      "  self.stats[group_name, \"logfoldchanges\"] = np.log2(\n",
      "/home/larissa/miniconda3/envs/testpy/lib/python3.12/site-packages/scanpy/tools/_rank_genes_groups.py:455: RuntimeWarning: invalid value encountered in log2\n",
      "  self.stats[group_name, \"logfoldchanges\"] = np.log2(\n",
      "/home/larissa/miniconda3/envs/testpy/lib/python3.12/site-packages/scanpy/tools/_rank_genes_groups.py:455: RuntimeWarning: invalid value encountered in log2\n",
      "  self.stats[group_name, \"logfoldchanges\"] = np.log2(\n",
      "/home/larissa/miniconda3/envs/testpy/lib/python3.12/site-packages/scanpy/tools/_rank_genes_groups.py:455: RuntimeWarning: invalid value encountered in log2\n",
      "  self.stats[group_name, \"logfoldchanges\"] = np.log2(\n",
      "/home/larissa/miniconda3/envs/testpy/lib/python3.12/site-packages/scanpy/tools/_rank_genes_groups.py:455: RuntimeWarning: invalid value encountered in log2\n",
      "  self.stats[group_name, \"logfoldchanges\"] = np.log2(\n",
      "/home/larissa/miniconda3/envs/testpy/lib/python3.12/site-packages/scanpy/tools/_rank_genes_groups.py:455: RuntimeWarning: invalid value encountered in log2\n",
      "  self.stats[group_name, \"logfoldchanges\"] = np.log2(\n",
      "/tmp/ipykernel_3811/2034559872.py:51: FutureWarning: ChainedAssignmentError: behaviour will change in pandas 3.0!\n",
      "You are setting values through chained assignment. Currently this works in certain cases, but when using Copy-on-Write (which will become the default behaviour in pandas 3.0) this will never work to update the original DataFrame or Series, because the intermediate object on which we are setting values will behave as a copy.\n",
      "A typical example is when you are setting values in a column of a DataFrame, like:\n",
      "\n",
      "df[\"col\"][row_indexer] = value\n",
      "\n",
      "Use `df.loc[row_indexer, \"col\"] = values` instead, to perform the assignment in a single step and ensure this keeps updating the original `df`.\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "\n",
      "  anndataobject_markers_wilcoxon[\"tag\"].iloc[i,] = eval_pval(anndataobject_markers_wilcoxon[\"pvals_adj\"].iloc[i,])\n",
      "/tmp/ipykernel_3811/2034559872.py:51: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  anndataobject_markers_wilcoxon[\"tag\"].iloc[i,] = eval_pval(anndataobject_markers_wilcoxon[\"pvals_adj\"].iloc[i,])\n",
      "/tmp/ipykernel_3811/2034559872.py:52: FutureWarning: ChainedAssignmentError: behaviour will change in pandas 3.0!\n",
      "You are setting values through chained assignment. Currently this works in certain cases, but when using Copy-on-Write (which will become the default behaviour in pandas 3.0) this will never work to update the original DataFrame or Series, because the intermediate object on which we are setting values will behave as a copy.\n",
      "A typical example is when you are setting values in a column of a DataFrame, like:\n",
      "\n",
      "df[\"col\"][row_indexer] = value\n",
      "\n",
      "Use `df.loc[row_indexer, \"col\"] = values` instead, to perform the assignment in a single step and ensure this keeps updating the original `df`.\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "\n",
      "  anndataobject_markers_wilcoxon[\"log_fc_tag\"].iloc[i,] = eval_log_fc_tag(anndataobject_markers_wilcoxon[\"logfoldchanges\"].iloc[i,])\n",
      "/tmp/ipykernel_3811/2034559872.py:52: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  anndataobject_markers_wilcoxon[\"log_fc_tag\"].iloc[i,] = eval_log_fc_tag(anndataobject_markers_wilcoxon[\"logfoldchanges\"].iloc[i,])\n",
      "/tmp/ipykernel_3811/2034559872.py:64: FutureWarning: ChainedAssignmentError: behaviour will change in pandas 3.0!\n",
      "You are setting values through chained assignment. Currently this works in certain cases, but when using Copy-on-Write (which will become the default behaviour in pandas 3.0) this will never work to update the original DataFrame or Series, because the intermediate object on which we are setting values will behave as a copy.\n",
      "A typical example is when you are setting values in a column of a DataFrame, like:\n",
      "\n",
      "df[\"col\"][row_indexer] = value\n",
      "\n",
      "Use `df.loc[row_indexer, \"col\"] = values` instead, to perform the assignment in a single step and ensure this keeps updating the original `df`.\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "\n",
      "  anndataobject_markers_t_over[\"tag\"].iloc[i,] = eval_pval(anndataobject_markers_t_over[\"pvals_adj\"].iloc[i,])\n",
      "/tmp/ipykernel_3811/2034559872.py:64: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  anndataobject_markers_t_over[\"tag\"].iloc[i,] = eval_pval(anndataobject_markers_t_over[\"pvals_adj\"].iloc[i,])\n",
      "/tmp/ipykernel_3811/2034559872.py:65: FutureWarning: ChainedAssignmentError: behaviour will change in pandas 3.0!\n",
      "You are setting values through chained assignment. Currently this works in certain cases, but when using Copy-on-Write (which will become the default behaviour in pandas 3.0) this will never work to update the original DataFrame or Series, because the intermediate object on which we are setting values will behave as a copy.\n",
      "A typical example is when you are setting values in a column of a DataFrame, like:\n",
      "\n",
      "df[\"col\"][row_indexer] = value\n",
      "\n",
      "Use `df.loc[row_indexer, \"col\"] = values` instead, to perform the assignment in a single step and ensure this keeps updating the original `df`.\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "\n",
      "  anndataobject_markers_t_over[\"log_fc_tag\"].iloc[i,] = eval_pval(anndataobject_markers_t_over[\"logfoldchanges\"].iloc[i,])\n",
      "/tmp/ipykernel_3811/2034559872.py:65: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  anndataobject_markers_t_over[\"log_fc_tag\"].iloc[i,] = eval_pval(anndataobject_markers_t_over[\"logfoldchanges\"].iloc[i,])\n",
      "/home/larissa/.local/lib/python3.12/site-packages/anndata/_core/anndata.py:841: UserWarning: \n",
      "AnnData expects .obs.index to contain strings, but got values like:\n",
      "    ['Megakaryocyte', 'Fibroblast', 'MSC', 'Megakaryocyte', 'Megakaryocyte']\n",
      "\n",
      "    Inferred to be: categorical\n",
      "\n",
      "  names = self._prep_dim_index(names, \"obs\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                    ADNP       AHR        AR     ARID2    ARID3A      ARNT  \\\n",
      "new_annotation                                                               \n",
      "Megakaryocyte  -2.057124 -1.728771 -0.650971 -1.302446 -0.512560  0.966899   \n",
      "Fibroblast     -1.504947 -1.086288 -0.076325 -0.435353 -1.521925  1.277241   \n",
      "MSC            -0.886975  1.019133 -0.358027  1.154298  0.083175  0.774495   \n",
      "Megakaryocyte  -0.962614 -0.713145  0.451321  0.935562 -0.204955 -1.314856   \n",
      "Megakaryocyte  -1.368409 -1.100814 -0.640365 -0.424150 -0.142692 -0.065452   \n",
      "...                  ...       ...       ...       ...       ...       ...   \n",
      "Neural         -1.005217 -0.844808  1.729793  0.879658 -0.567200 -0.889656   \n",
      "Neural         -1.047994  0.018887  3.127711 -0.693770  0.804381  1.245624   \n",
      "Neural         -1.194201 -1.003628  0.727110 -0.367487 -0.312988  0.591762   \n",
      "Neural         -1.267747 -1.065434  0.370182 -0.322097  0.141417  0.456086   \n",
      "Neural         -1.099067  2.496887  0.454755  1.230883  0.628101 -2.522294   \n",
      "\n",
      "                   ASCL1      ATF1      ATF2      ATF3  ...    ZNF589  \\\n",
      "new_annotation                                          ...             \n",
      "Megakaryocyte  -1.483519 -0.525911  2.529577 -1.174340  ...  0.381661   \n",
      "Fibroblast     -0.436811  1.911485  4.563710 -0.334244  ...  0.152247   \n",
      "MSC            -2.084374 -0.483882  3.825168 -0.887740  ...  0.543690   \n",
      "Megakaryocyte  -0.704140 -0.120847  3.200122 -0.092897  ...  0.722059   \n",
      "Megakaryocyte  -1.274369  0.152797  1.940801 -0.072653  ...  1.255486   \n",
      "...                  ...       ...       ...       ...  ...       ...   \n",
      "Neural         -0.952011  1.197757  0.647093 -1.047722  ... -0.961539   \n",
      "Neural          0.274998  4.007155  3.904044  1.112169  ...  0.009111   \n",
      "Neural         -1.130988  1.771604  1.873642 -0.671226  ... -0.265188   \n",
      "Neural          1.429373  0.171550  0.126962  0.142322  ... -0.373078   \n",
      "Neural         -0.137439  1.496581  4.811591 -1.145540  ...  0.871359   \n",
      "\n",
      "                  ZNF592    ZNF639    ZNF644    ZNF740    ZNF750    ZNF766  \\\n",
      "new_annotation                                                               \n",
      "Megakaryocyte  -0.671417  2.128782 -0.464678 -1.510827 -1.788520 -0.109013   \n",
      "Fibroblast      0.107060 -1.307879 -0.602643 -0.121086 -1.244807 -1.462315   \n",
      "MSC             1.090877  0.544359  1.833333  2.940516 -0.745931 -0.733416   \n",
      "Megakaryocyte   0.161639  2.251135  0.922380  0.247673 -1.660396 -1.933346   \n",
      "Megakaryocyte   0.254800  1.821999 -0.181783 -0.890426 -1.558278 -1.327175   \n",
      "...                  ...       ...       ...       ...       ...       ...   \n",
      "Neural         -0.660673  1.026745 -1.026563  0.906058 -0.150877 -0.988245   \n",
      "Neural          0.703715  0.874722  0.807512  1.087975  0.662040 -1.030298   \n",
      "Neural         -0.784872 -1.536145 -0.405442  2.768999 -0.514145 -1.174034   \n",
      "Neural          1.478291 -0.400798  0.263793  1.769506 -0.627134 -0.433952   \n",
      "Neural          0.600998  0.698651 -1.122407  1.509379  0.517507 -1.080508   \n",
      "\n",
      "                   ZNF83     ZNF92      ZZZ3  \n",
      "new_annotation                                \n",
      "Megakaryocyte  -0.006466 -1.505159  0.944313  \n",
      "Fibroblast     -0.350595 -0.915450 -0.475175  \n",
      "MSC             0.864781  0.142596  0.702630  \n",
      "Megakaryocyte   0.286679 -0.862415  1.380019  \n",
      "Megakaryocyte   0.959999 -1.825512 -1.181966  \n",
      "...                  ...       ...       ...  \n",
      "Neural         -0.794770 -0.974113 -0.630758  \n",
      "Neural         -0.828590  0.982276 -0.657598  \n",
      "Neural          0.099989 -1.157250  0.572626  \n",
      "Neural         -0.002853 -0.399435 -0.795476  \n",
      "Neural          0.275486 -1.065059 -0.689643  \n",
      "\n",
      "[255 rows x 359 columns]\n"
     ]
    },
    {
     "ename": "KeyError",
     "evalue": "('gene', 'new_annotation')",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[57], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[43mtf_activity_analysis\u001b[49m\u001b[43m(\u001b[49m\u001b[43manndataobject\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mLR2TF_test_run/anndata_object.h5ad\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43marguments_list\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43m{\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mout_path\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m \u001b[49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mscript_test\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcelltype\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m \u001b[49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mnew_annotation\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcondition\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m \u001b[49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mprotocol\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43morganism\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m \u001b[49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcomparison_list\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m \u001b[49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mlogfc\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m \u001b[49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m0.5\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mpval\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m \u001b[49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mreg\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m \u001b[49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mfilterd_regulon.csv\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mtf_activities\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m \u001b[49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mdecoupler_results.csv\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m}\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[8], line 57\u001b[0m, in \u001b[0;36mtf_activity_analysis\u001b[0;34m(anndataobject, arguments_list)\u001b[0m\n\u001b[1;32m     53\u001b[0m sub_object_avg \u001b[38;5;241m=\u001b[39m AverageExpression(sub_object, name_iterable\u001b[38;5;241m=\u001b[39m name_iterable, celltype \u001b[38;5;241m=\u001b[39m arguments_list[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcelltype\u001b[39m\u001b[38;5;124m\"\u001b[39m], outpath\u001b[38;5;241m=\u001b[39m arguments_list[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mout_path\u001b[39m\u001b[38;5;124m\"\u001b[39m])\n\u001b[1;32m     54\u001b[0m \u001b[38;5;66;03m#check if its fine to only have the average expression as a dataframe and not as part of an anndata object\u001b[39;00m\n\u001b[1;32m     55\u001b[0m \n\u001b[1;32m     56\u001b[0m \u001b[38;5;66;03m#check how sub object is returned by average expression (subobject.T) or rename return?\u001b[39;00m\n\u001b[0;32m---> 57\u001b[0m tf_activity_scores \u001b[38;5;241m=\u001b[39m \u001b[43mget_significant_tfs_single\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtf_activities_sub\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcelltype\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43marguments_list\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcelltype\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43mcondition\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mname_iterable\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mout_path\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mtf_path\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpval\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43marguments_list\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mpval\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlogfc\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43marguments_list\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mlogfc\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mname\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mname_iterable\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[54], line 82\u001b[0m, in \u001b[0;36mget_significant_tfs_single\u001b[0;34m(tf_activities_sub, celltype, condition, out_path, pval, logfc, name)\u001b[0m\n\u001b[1;32m     80\u001b[0m tf_scores_df \u001b[38;5;241m=\u001b[39m tf_activities_sub\u001b[38;5;241m.\u001b[39mto_df()\n\u001b[1;32m     81\u001b[0m \u001b[38;5;28mprint\u001b[39m(tf_scores_df)\n\u001b[0;32m---> 82\u001b[0m unfiltered_tf_scores \u001b[38;5;241m=\u001b[39m \u001b[43mcreate_unfiltered_tf_scores\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtf_scores_df\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcondition\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcelltype\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msingle_result_path\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     84\u001b[0m \u001b[38;5;66;03m#Filter to only include tfs that match the tag_mapping/are markers\u001b[39;00m\n\u001b[1;32m     85\u001b[0m col_num \u001b[38;5;241m=\u001b[39m tf_scores_df\u001b[38;5;241m.\u001b[39mcolumns\u001b[38;5;241m.\u001b[39misin(tag_mapping_wilcox\u001b[38;5;241m.\u001b[39mindex)  \n",
      "Cell \u001b[0;32mIn[56], line 2\u001b[0m, in \u001b[0;36mcreate_unfiltered_tf_scores\u001b[0;34m(tf_scores_df, condition, celltype, out_path)\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcreate_unfiltered_tf_scores\u001b[39m(tf_scores_df, condition, celltype, out_path):   \n\u001b[0;32m----> 2\u001b[0m     summarized_tf_scores_df \u001b[38;5;241m=\u001b[39m \u001b[43mtf_scores_df\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgroupby\u001b[49m\u001b[43m(\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mgene\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcelltype\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mobserved\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39mmean()\u001b[38;5;241m.\u001b[39mT\n\u001b[1;32m      3\u001b[0m     summarized_tf_scores_df\u001b[38;5;241m.\u001b[39mto_csv(out_path \u001b[38;5;241m+\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m/unfiltered_tf_scores_\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;241m+\u001b[39m condition \u001b[38;5;241m+\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m.csv\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m      4\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m summarized_tf_scores_df\n",
      "File \u001b[0;32m~/.local/lib/python3.12/site-packages/pandas/core/frame.py:9183\u001b[0m, in \u001b[0;36mDataFrame.groupby\u001b[0;34m(self, by, axis, level, as_index, sort, group_keys, observed, dropna)\u001b[0m\n\u001b[1;32m   9180\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m level \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m by \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m   9181\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mYou have to supply one of \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mby\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m and \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlevel\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m-> 9183\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mDataFrameGroupBy\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   9184\u001b[0m \u001b[43m    \u001b[49m\u001b[43mobj\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m   9185\u001b[0m \u001b[43m    \u001b[49m\u001b[43mkeys\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mby\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   9186\u001b[0m \u001b[43m    \u001b[49m\u001b[43maxis\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43maxis\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   9187\u001b[0m \u001b[43m    \u001b[49m\u001b[43mlevel\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlevel\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   9188\u001b[0m \u001b[43m    \u001b[49m\u001b[43mas_index\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mas_index\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   9189\u001b[0m \u001b[43m    \u001b[49m\u001b[43msort\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msort\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   9190\u001b[0m \u001b[43m    \u001b[49m\u001b[43mgroup_keys\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgroup_keys\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   9191\u001b[0m \u001b[43m    \u001b[49m\u001b[43mobserved\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mobserved\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   9192\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdropna\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdropna\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   9193\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.local/lib/python3.12/site-packages/pandas/core/groupby/groupby.py:1329\u001b[0m, in \u001b[0;36mGroupBy.__init__\u001b[0;34m(self, obj, keys, axis, level, grouper, exclusions, selection, as_index, sort, group_keys, observed, dropna)\u001b[0m\n\u001b[1;32m   1326\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdropna \u001b[38;5;241m=\u001b[39m dropna\n\u001b[1;32m   1328\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m grouper \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m-> 1329\u001b[0m     grouper, exclusions, obj \u001b[38;5;241m=\u001b[39m \u001b[43mget_grouper\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1330\u001b[0m \u001b[43m        \u001b[49m\u001b[43mobj\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1331\u001b[0m \u001b[43m        \u001b[49m\u001b[43mkeys\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1332\u001b[0m \u001b[43m        \u001b[49m\u001b[43maxis\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43maxis\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1333\u001b[0m \u001b[43m        \u001b[49m\u001b[43mlevel\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlevel\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1334\u001b[0m \u001b[43m        \u001b[49m\u001b[43msort\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msort\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1335\u001b[0m \u001b[43m        \u001b[49m\u001b[43mobserved\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mobserved\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mis\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mlib\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mno_default\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mobserved\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1336\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdropna\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdropna\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1337\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1339\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m observed \u001b[38;5;129;01mis\u001b[39;00m lib\u001b[38;5;241m.\u001b[39mno_default:\n\u001b[1;32m   1340\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28many\u001b[39m(ping\u001b[38;5;241m.\u001b[39m_passed_categorical \u001b[38;5;28;01mfor\u001b[39;00m ping \u001b[38;5;129;01min\u001b[39;00m grouper\u001b[38;5;241m.\u001b[39mgroupings):\n",
      "File \u001b[0;32m~/.local/lib/python3.12/site-packages/pandas/core/groupby/grouper.py:1043\u001b[0m, in \u001b[0;36mget_grouper\u001b[0;34m(obj, key, axis, level, sort, observed, validate, dropna)\u001b[0m\n\u001b[1;32m   1041\u001b[0m         in_axis, level, gpr \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m, gpr, \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1042\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1043\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(gpr)\n\u001b[1;32m   1044\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(gpr, Grouper) \u001b[38;5;129;01mand\u001b[39;00m gpr\u001b[38;5;241m.\u001b[39mkey \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m   1045\u001b[0m     \u001b[38;5;66;03m# Add key to exclusions\u001b[39;00m\n\u001b[1;32m   1046\u001b[0m     exclusions\u001b[38;5;241m.\u001b[39madd(gpr\u001b[38;5;241m.\u001b[39mkey)\n",
      "\u001b[0;31mKeyError\u001b[0m: ('gene', 'new_annotation')"
     ]
    }
   ],
   "source": [
    "result = tf_activity_analysis(anndataobject= \"LR2TF_test_run/anndata_object.h5ad\", arguments_list= {\"out_path\" : \"script_test\", \"celltype\" : \"new_annotation\", \"condition\" : \"protocol\", \"organism\" : None, \"comparison_list\" : None, \"logfc\" : \"0.5\", \"pval\" : None, \"reg\" : \"filterd_regulon.csv\", \"tf_activities\" : \"decoupler_results.csv\"})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def csv_comparison (result_1, result_2, outpath, suffixes_df=(\"_py\", \"_r\")):\n",
    "    result1 = pd.read_csv(result_1)\n",
    "    result2 = pd.read_csv(result_2)\n",
    "\n",
    "\n",
    "    result1 = result1[result1[\"pvals_adj\"] < 0.05]\n",
    "    if \"p_val_adj\" in result2.columns:\n",
    "        result2 = result2[result2[\"p_val_adj\"] < 0.05]\n",
    "    else:\n",
    "        result2 = result2[result2[\"pvals_adj\"] < 0.05]\n",
    "\n",
    "    result1 = result1.rename(columns={\"names\": \"gene\", \"group\": \"cluster\"})\n",
    "    result2 = result2.rename(columns={\"names\": \"gene\", \"group\": \"cluster\"})\n",
    "\n",
    "\n",
    "    df_output_1 = pd.DataFrame()\n",
    "\n",
    "    for i in range(len(result1)):\n",
    "        a = result1[\"gene\"].iloc[i]\n",
    "        for j in range(len(result2)):\n",
    "            b = result2[\"gene\"].iloc[j]\n",
    "            if a == b:\n",
    "                df_output_1[i] = result1.iloc[i]\n",
    "            \n",
    "\n",
    "    df_output_1 = df_output_1.T\n",
    "\n",
    "    df_output_2 = pd.DataFrame()\n",
    "    for i in range(len(result2)):\n",
    "        a = result2[\"gene\"].iloc[i]\n",
    "        for j in range(len(result1)):\n",
    "            b = result1[\"gene\"].iloc[j]\n",
    "            if a == b:\n",
    "                df_output_2[i] = result2.iloc[i]\n",
    "\n",
    "\n",
    "    df_output_2 = df_output_2.T\n",
    "\n",
    "\n",
    "    df_output = pd.merge(df_output_1, df_output_2, on=\"gene\", suffixes=suffixes_df)\n",
    "\n",
    "    df_output_3 = pd.DataFrame()\n",
    "    for i in range(len(result1)):\n",
    "        a = result1[\"gene\"].iloc[i]\n",
    "        b = list(result2[\"gene\"])\n",
    "        if a not in b:\n",
    "            df_output_3[i] = result1.iloc[i]\n",
    "            \n",
    "    df_output_3 = df_output_3.T\n",
    "    df_output.rename(columns={\"Unnamed: 0\": \"gene_r\"}, inplace=True)\n",
    "    df_output_3.rename(columns={\"cluster\": \"cluster\" + suffixes_df[0]}, inplace=True)\n",
    "    if suffixes_df[0] == \"_py_wilcox\":\n",
    "        df_output_3.rename(columns={\"scores\": \"scores\" + suffixes_df[0], \"logfoldchanges\": \"logfoldchanges\" + suffixes_df[0], \"pvals\": \"pvals\" + suffixes_df[0], \"pvals_adj\": \"pvals_adj\" + suffixes_df[0]}, inplace=True)\n",
    "        df_output_4 = pd.DataFrame()\n",
    "        for i in range(len(result2)):\n",
    "            a = result2[\"gene\"].iloc[i]\n",
    "            b = list(result1[\"gene\"])\n",
    "            if a not in b:\n",
    "                df_output_4[i] = result2.iloc[i]\n",
    "        df_output_4 = df_output_4.T\n",
    "        df_output_4.rename(columns={\"cluster\": \"cluster\" + suffixes_df[1], \"scores\": \"scores\" + suffixes_df[1], \"logfoldchanges\": \"logfoldchanges\" + suffixes_df[1], \"pvals\": \"pvals\" + suffixes_df[1], \"pvals_adj\": \"pvals_adj\" + suffixes_df[1]}, inplace=True)\n",
    "        df_output_3 = pd.concat([df_output_3, df_output_4])\n",
    "        \n",
    "\n",
    "    df_output = pd.concat([df_output, df_output_3])\n",
    "\n",
    "    df_output.to_csv(outpath, index=0)\n",
    "    print(df_output_3.columns)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#WINDOWS VERSION\n",
    "\n",
    "#CONTROL\n",
    "#comparison python wilcoxon and r wilcoxon control\n",
    "csv_comparison(\"script_test\\\\TF_results\\\\control\\\\control_specific_markers_wilcoxon_test.csv\", \"LR2TF_test_run\\\\results\\\\TF_results\\\\control\\\\all_specificmarker__control.csv\",\n",
    "                \"tf_comparison_r_py\\\\py_wilcoxon_r_same_genes_control_filtered.csv\", suffixes_df=(\"_py\", \"_r\"))\n",
    "\n",
    "#comparison python t test and r wilcoxon control\n",
    "csv_comparison(\"script_test\\\\TF_results\\\\control\\\\control_specific_markers_t_test_overestim_test.csv\", \"LR2TF_test_run\\\\results\\\\TF_results\\\\control\\\\all_specificmarker__control.csv\",\n",
    "                \"tf_comparison_r_py\\\\py_t_test_r_same_genes_control_filtered.csv\", suffixes_df=(\"_py\", \"_r\"))\n",
    "\n",
    "# py wilcox vs py t test control\n",
    "\n",
    "csv_comparison(\"script_test\\\\TF_results\\\\control\\\\control_specific_markers_wilcoxon_test.csv\", \"script_test\\\\TF_results\\\\control\\\\control_specific_markers_t_test_overestim_test.csv\",\n",
    "                \"tf_comparison_r_py\\\\py_wilcox_py_t_test_same_genes_control_filtered.csv\", suffixes_df=(\"_py_wilcox\", \"_py_t_test\"))\n",
    "################################################################################################################################################################################################\n",
    "#PMF MF2\n",
    "#python wilcox vs r wilcox PMF MF2\n",
    "csv_comparison(\"script_test\\\\TF_results\\\\PMF_MF2\\\\PMF_MF2_specific_markers_wilcoxon_test.csv\", \"LR2TF_test_run\\\\results\\\\TF_results\\\\PMF_MF2\\\\all_specificmarker__PMF_MF2.csv\",\n",
    "                \"tf_comparison_r_py\\\\py_wilcoxon_r_same_genes_PMF_MF2_filtered.csv\", suffixes_df=(\"_py\", \"_r\"))\n",
    "\n",
    "#comparison python t test and r wilcoxon PMF MF2\n",
    "csv_comparison(\"script_test\\\\TF_results\\\\PMF_MF2\\\\PMF_MF2_specific_markers_t_test_overestim_test.csv\", \"LR2TF_test_run\\\\results\\\\TF_results\\\\PMF_MF2\\\\all_specificmarker__PMF_MF2.csv\",\n",
    "                \"tf_comparison_r_py\\\\py_t_test_r_same_genes_PMF_MF2_filtered.csv\", suffixes_df=(\"_py\", \"_r\"))\n",
    "\n",
    "csv_comparison(\"script_test\\\\TF_results\\\\PMF_MF2\\\\PMF_MF2_specific_markers_wilcoxon_test.csv\", \"script_test\\\\TF_results\\\\PMF_MF2\\\\PMF_MF2_specific_markers_t_test_overestim_test.csv\",\n",
    "                \"tf_comparison_r_py\\\\py_wilcox_py_t_test_same_genes_PMF_MF2_filtered.csv\", suffixes_df=(\"_py_wilcox\", \"_py_t_test\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#LINUX VERSION\n",
    "\n",
    "#CONTROL\n",
    "#comparison python wilcoxon and r wilcoxon control\n",
    "csv_comparison(\"script_test/TF_results/control/control_specific_markers_wilcoxon_test.csv\", \"LR2TF_test_run/results/TF_results/control/all_specificmarker__control.csv\",\n",
    "                \"tf_comparison_r_py//py_wilcoxon_r_same_genes_control_filtered.csv\", suffixes_df=(\"_py\", \"_r\"))\n",
    "\n",
    "#comparison python t test and r wilcoxon control\n",
    "csv_comparison(\"script_test/TF_results/control/control_specific_markers_t_test_overestim_test.csv\", \"LR2TF_test_run/results/TF_results/control/all_specificmarker__control.csv\",\n",
    "                \"tf_comparison_r_py/py_t_test_r_same_genes_control_filtered.csv\", suffixes_df=(\"_py\", \"_r\"))\n",
    "\n",
    "# py wilcox vs py t test control\n",
    "\n",
    "csv_comparison(\"script_test/TF_results/control/control_specific_markers_wilcoxon_test.csv\", \"script_test/TF_results/control/control_specific_markers_t_test_overestim_test.csv\",\n",
    "                \"tf_comparison_r_py/py_wilcox_py_t_test_same_genes_control_filtered.csv\", suffixes_df=(\"_py_wilcox\", \"_py_t_test\"))\n",
    "################################################################################################################################################################################################\n",
    "#PMF MF2\n",
    "#python wilcox vs r wilcox PMF MF2\n",
    "csv_comparison(\"script_test/TF_results/PMF_MF2/PMF_MF2_specific_markers_wilcoxon_test.csv\", \"LR2TF_test_run/results/TF_results/PMF_MF2/all_specificmarker__PMF_MF2.csv\",\n",
    "                \"tf_comparison_r_py/py_wilcoxon_r_same_genes_PMF_MF2_filtered.csv\", suffixes_df=(\"_py\", \"_r\"))\n",
    "\n",
    "#comparison python t test and r wilcoxon PMF MF2\n",
    "csv_comparison(\"script_test/TF_results/PMF_MF2/PMF_MF2_specific_markers_t_test_overestim_test.csv\", \"LR2TF_test_run/results/TF_results/PMF_MF2/all_specificmarker__PMF_MF2.csv\",\n",
    "                \"tf_comparison_r_py/py_t_test_r_same_genes_PMF_MF2_filtered.csv\", suffixes_df=(\"_py\", \"_r\"))\n",
    "\n",
    "csv_comparison(\"script_test/TF_results/PMF_MF2/PMF_MF2_specific_markers_wilcoxon_test.csv\", \"script_test/TF_results/PMF_MF2/PMF_MF2_specific_markers_t_test_overestim_test.csv\",\n",
    "                \"tf_comparison_r_py/py_wilcox_py_t_test_same_genes_PMF_MF2_filtered.csv\", suffixes_df=(\"_py_wilcox\", \"_py_t_test\"))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
