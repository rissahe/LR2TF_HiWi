{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/larissa/.local/lib/python3.12/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import anndata as ad\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import scanpy as sc\n",
    "import decoupler as dc\n",
    "import os\n",
    "import statistics\n",
    "import seaborn as sns\n",
    "from scipy.spatial.distance import pdist\n",
    "from scipy.cluster.hierarchy import linkage\n",
    "import matplotlib.pyplot as plt\n",
    "from statsmodels.stats.multitest import multipletests\n",
    "import re \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def validate_input_arguments (arguments_list):\n",
    "    if arguments_list[\"out_path\"] is None:\n",
    "        print(\"Please provide an output path\")\n",
    "    elif arguments_list[\"out_path\"][-1] != \"/\":\n",
    "        arguments_list[\"out_path\"] = arguments_list[\"out_path\"] + \"/\"\n",
    "\n",
    "    if arguments_list[\"celltype\"] is None:\n",
    "        print(\"Please provide the name of the metadata field containing cell type annotations\")\n",
    "\n",
    "    if arguments_list[\"condition\"] is None:\n",
    "        print(\"Please provide the name of the metadata field containing condition annotations\")\n",
    "\n",
    "    if arguments_list[\"organism\"] is None:\n",
    "        arguments_list[\"organism\"] = \"human\"\n",
    "\n",
    "    #if arguments_list[\"comparison_list\"] is None:\n",
    "    #    arguments_list[\"comparison_list\"] = np.nan\n",
    "\n",
    "    if arguments_list[\"meanchange\"] is None:\n",
    "        arguments_list[\"meanchange\"] = 0.0\n",
    "\n",
    "    if arguments_list [\"pval\"] is None:\n",
    "        arguments_list[\"pval\"] = 0.05\n",
    "\n",
    "    if arguments_list [\"num_cell_filter\"] is None:\n",
    "        arguments_list[\"num_cell_filter\"] = 0\n",
    "\n",
    "    if arguments_list[\"reg\"] is None:\n",
    "        raise ValueError(\"Please provide a regulon csv.\")\n",
    "\n",
    "    elif isinstance(arguments_list[\"reg\"], str):\n",
    "        arguments_list[\"reg\"] = pd.read_csv(arguments_list[\"reg\"], index_col=0)\n",
    "        arguments_list[\"reg\"] = pd.DataFrame.rename(arguments_list[\"reg\"], columns={\"source\" : \"tf\"})\n",
    "\n",
    "    #is the naming of tf fine like this?\n",
    "    if not \"tf\" in arguments_list[\"reg\"] and \"target\" in arguments_list[\"reg\"] and \"weight\" in arguments_list[\"reg\"]:\n",
    "        raise NameException(\"Not all necessary columns found in regulon table! Please make sure that the regulon has the columns 'source', 'target' and 'weight'!\")\n",
    "    \n",
    "    if arguments_list[\"plot\"] is None:\n",
    "        arguments_list[\"plot\"] = True\n",
    "    elif not isinstance(arguments_list[\"plot\"], (bool)):\n",
    "        raise ValueError(\"lot argument must be a boolean value.\")\n",
    "        \n",
    "   \n",
    "    return(arguments_list)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TFObj:\n",
    "    def __init__(self,\n",
    "    tf_activities_condition : list,\n",
    "    tf_activities_cluster : list,\n",
    "    average_gene_expression : list,\n",
    "    regulon : pd.DataFrame,\n",
    "    CTR_input_condition : list,\n",
    "    CTR_input_cluster : list,\n",
    "    intracellular_network_condition : list,\n",
    "    intracellular_network_cluster : list):\n",
    "\n",
    "        self.tf_activities_condition = tf_activities_condition\n",
    "        self.tf_activities_cluster = tf_activities_cluster\n",
    "        self.average_gene_expression = average_gene_expression\n",
    "        self.regulon = regulon\n",
    "        self.CTR_input_condition = CTR_input_condition\n",
    "        self.CTR_input_cluster = CTR_input_cluster\n",
    "        self.intracellular_network_condition = intracellular_network_condition\n",
    "        self.intracellular_network_cluster = intracellular_network_cluster\n",
    "\n",
    "def make_TFOBj(tf_activities_condition : list,\n",
    "    tf_activities_cluster : list,\n",
    "    average_gene_expression : list,\n",
    "    regulon : pd.DataFrame,\n",
    "    CTR_input_condition : list,\n",
    "    CTR_input_cluster : list,\n",
    "    intracellular_network_condition : list,\n",
    "    intracellular_network_cluster : list):\n",
    "\n",
    "        tf = TFObj(tf_activities_condition,\n",
    "            tf_activities_cluster,\n",
    "            average_gene_expression,\n",
    "            regulon,\n",
    "            CTR_input_condition,\n",
    "            CTR_input_cluster,\n",
    "            intracellular_network_condition,\n",
    "            intracellular_network_cluster)\n",
    "\n",
    "        return tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def AverageExpression(sub_object, celltype = None, name_iterable = None, outpath = None):\n",
    "    gene_ids = sub_object.var.index.values\n",
    "    obs = sub_object[:,gene_ids].X.toarray()\n",
    "    obs = np.expm1(obs)\n",
    "    avg_df = pd.DataFrame(obs,columns=gene_ids,index= sub_object.obs[celltype])\n",
    "    avg_df = avg_df.groupby(level=0, observed=False).mean()\n",
    "    avg_df.T.to_csv(outpath + name_iterable + \"_average_gene_expression_by_cluster_exp.csv\")\n",
    "\n",
    "    return avg_df.T\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def eval_pval(p_val):\n",
    "    p_val = float(p_val)\n",
    "    if p_val < 0.001: \n",
    "      txt = \"***\"\n",
    "    elif p_val < 0.01: \n",
    "      txt = \"**\"\n",
    "    elif p_val < 0.05: \n",
    "      txt = \"*\"\n",
    "    else:\n",
    "      txt = \"ns\"\n",
    "    return(txt)\n",
    "\n",
    "\n",
    "def eval_meanchange_tag(meanchange):\n",
    "    if meanchange >= 1.0: \n",
    "      txt = \"***\"\n",
    "    elif meanchange > 0.5: \n",
    "      txt = \"**\"\n",
    "    elif meanchange > 0.0: \n",
    "      txt = \"*\"\n",
    "    else:\n",
    "      txt = \"ns\"\n",
    "    return(txt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_unfiltered_tf_scores(tf_scores_df, condition, celltype, out_path):   \n",
    "    summarized_tf_scores_df = tf_scores_df.groupby(celltype, observed = True).mean().T\n",
    "    #tf_scores_df.groupby(celltype, observed = True).apply(display)\n",
    "    #agg([\"mean\", \"var\"])\n",
    "    summarized_tf_scores_df.to_csv(out_path + \"/unfiltered_tf_scores_\" + condition + \".csv\")\n",
    "    return summarized_tf_scores_df\n",
    "\n",
    "#np.var() returns a value that is different from R's var(), whereas statistics.variance() is the same as R's var()\n",
    "def save_variable_tf_score(filtered_summarized_tf_scores_df, condition, out_path, plot):\n",
    "    filtered_summarized_tf_scores_df[\"var\"] = filtered_summarized_tf_scores_df.apply(statistics.variance, axis=1).unique()\n",
    "    filtered_summarized_tf_scores_df.to_csv(out_path + \"/variable_tf_scores_\" + condition + \".csv\")\n",
    "\n",
    "    if plot:\n",
    "        top_variable_tfs = filtered_summarized_tf_scores_df.sort_values(\"var\", ascending=False).head(n=20).drop(columns=\"var\")\n",
    "        cluster_map = sns.clustermap(top_variable_tfs, cmap=\"vlag\", center=0, vmin=top_variable_tfs.min(axis=None), cbar_kws={\"label\": \"t-score\"},\n",
    "                                    cbar_pos=(1, 0.5, 0.02, 0.1), dendrogram_ratio=(0.2, 0.05))\n",
    "        cluster_map.ax_heatmap.set_xlabel(\"Cell Type\")\n",
    "        cluster_map.ax_heatmap.set_ylabel(\"Transcription Factor\")\n",
    "        plt.setp(cluster_map.ax_heatmap.get_xticklabels(), rotation=45) \n",
    "        plt.savefig(out_path + \"/tf_activity_top20_variable_\" + condition + \".pdf\", bbox_inches='tight')\n",
    "        plt.close()\n",
    "\n",
    "    filtered_summarized_tf_scores_df_var = filtered_summarized_tf_scores_df\n",
    "    return filtered_summarized_tf_scores_df_var\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_tf_activity(filtered_summarized_tf_scores_df, tag_mapping, condition, out_path):\n",
    "    filtered_summarized_tf_scores_df = filtered_summarized_tf_scores_df.drop(columns=\"var\")\n",
    "    calc_size = ((len(filtered_summarized_tf_scores_df.columns.unique()) * 1.5), (len(filtered_summarized_tf_scores_df) * 0.06))\n",
    "    cluster_map = sns.clustermap(filtered_summarized_tf_scores_df, cbar_kws={\"label\": \"t-score\"}, figsize=calc_size, cmap=\"vlag\", center=0, \n",
    "                                yticklabels=False, cbar_pos=(1, 0.5, 0.02, 0.1), dendrogram_ratio=(0.2, 0.05))\n",
    "    cluster_map.ax_heatmap.set_xlabel(\"Cell Type\")\n",
    "    cluster_map.ax_heatmap.set_ylabel(\"Transcription Factor\")\n",
    "    plt.setp(cluster_map.ax_heatmap.get_xticklabels(), rotation=45) \n",
    "    \n",
    "    plt.savefig(out_path + \"/tf_activity_compressed_\" + condition + \".pdf\", bbox_inches='tight')\n",
    "    plt.close()\n",
    "\n",
    "\n",
    "    cols_all_ns = tag_mapping.columns[(tag_mapping == \"ns\").all()]\n",
    "    tag_mapping = tag_mapping.drop(columns=cols_all_ns)\n",
    "    filtered_summarized_tf_scores_df = filtered_summarized_tf_scores_df.drop(columns=cols_all_ns)\n",
    "\n",
    "    calc_size = ((len(filtered_summarized_tf_scores_df.columns.unique()) * 1.5), (len(filtered_summarized_tf_scores_df) * 0.2))\n",
    "    cluster_map = sns.clustermap(filtered_summarized_tf_scores_df, cbar_kws={\"label\": \"t-score\"}, figsize=calc_size, cmap=\"vlag\", center=0, annot= tag_mapping, fmt=\"\", \n",
    "                                yticklabels=True, cbar_pos=(1, 0.5, 0.03, 0.05), dendrogram_ratio=(0.2, 0.05))\n",
    "    cluster_map.ax_heatmap.set_xlabel(\"Cell Type\")\n",
    "    cluster_map.ax_heatmap.set_ylabel(\"Transcription Factor\")\n",
    "    plt.setp(cluster_map.ax_heatmap.get_xticklabels(), rotation=45) \n",
    "\n",
    "    plt.savefig(out_path + \"/tf_activity_\" + condition + \".pdf\", bbox_inches='tight')\n",
    "    plt.close()\n",
    "\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def h_clust(data):\n",
    "            dist_matrix = pdist(data.T)\n",
    "            linkage_matrix = linkage(dist_matrix, method = \"average\")   \n",
    "            return linkage_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_condition_tf_activities(tf_activity_tables, out_path):\n",
    "       \n",
    "   for result_name, df in tf_activity_tables.items():\n",
    "        name_df = pd.DataFrame(df)\n",
    "        #print(name_df)\n",
    "        significant_res = name_df[name_df[\"tag\"] == \"***\"]\n",
    "        significant_genes = np.unique(significant_res[\"tf\"])\n",
    "        name_df = name_df[name_df['tf'].isin(significant_genes)]\n",
    "        #print(name_df)cha\n",
    "\n",
    "        tag_mapping = name_df[[\"tf\", \"tag\", \"CellType\"]]\n",
    "\n",
    "        tag_mapping = tag_mapping.pivot(index=\"tf\", columns=\"CellType\", values=\"tag\")\n",
    "        tag_mapping.fillna(\"ns\", inplace=True)\n",
    "\n",
    "        cols_all_ns = tag_mapping.columns[(tag_mapping == \"ns\").all()]\n",
    "        tag_mapping = tag_mapping.drop(columns=cols_all_ns)\n",
    "\n",
    "    \n",
    "        name_df_r = name_df[[\"r\", \"tf\", \"CellType\"]]\n",
    "        name_df_cluster = name_df_r.pivot_table(index = \"tf\", columns = \"CellType\", values = \"r\", aggfunc = \"mean\")\n",
    "        name_df_cluster.fillna(0, inplace=True) \n",
    "        name_df_cluster = name_df_cluster.drop(columns=cols_all_ns)\n",
    "        h_clust_matrix = h_clust(name_df_cluster)\n",
    "\n",
    "\n",
    "      \n",
    "        calc_size = ((len(name_df[\"CellType\"].unique()) * 1.5), (len(name_df_cluster) * 0.2))\n",
    "      \n",
    "        cluster_map = sns.clustermap(name_df_cluster, cbar_kws={\"label\": \"r\"}, figsize=calc_size, cmap=\"vlag\", center=0, annot= tag_mapping,\n",
    "                      col_linkage= h_clust_matrix, fmt=\"\", yticklabels=True, cbar_pos=(1, 0.5, 0.03, 0.05), dendrogram_ratio=(0.2, 0.05))\n",
    "        plt.setp(cluster_map.ax_heatmap.get_xticklabels(), rotation=45)  \n",
    "\n",
    "        plt.savefig(out_path + \"/\" + result_name + \"_cluster_condition_activity_difference.pdf\", bbox_inches='tight')\n",
    "        plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_condition_tf_activities_compressed(tf_activity_tables, out_path):\n",
    " \n",
    "  \n",
    "    for result_name, df in tf_activity_tables.items():\n",
    "        name_df = pd.DataFrame(df)\n",
    "        \n",
    "        significant_res = name_df[name_df[\"tag\"] == \"***\"]\n",
    "        significant_genes = np.unique(significant_res[\"tf\"])\n",
    "        name_df = name_df[name_df['tf'].isin(significant_genes)]\n",
    "        \n",
    "        name_df_r = name_df[[\"r\", \"tf\", \"CellType\"]]\n",
    "        name_df_cluster = name_df_r.pivot_table(index = \"tf\", columns = \"CellType\", values = \"r\", aggfunc = \"mean\")\n",
    "        name_df_cluster.fillna(0, inplace=True) \n",
    "\n",
    "        h_clust_matrix = h_clust(name_df_cluster)\n",
    "        name_df_cluster.reset_index()\n",
    "\n",
    "        calc_size = ((len(name_df[\"CellType\"].unique()) * 1.5\n",
    "        ), (len(name_df_cluster) * 0.06))\n",
    "        cluster_map = sns.clustermap(name_df_cluster, cbar_kws={\"label\": \"r\"}, figsize=calc_size, cmap=\"vlag\", center=0, annot= None,\n",
    "                       yticklabels=False, col_linkage= h_clust_matrix, fmt=\"\", cbar_pos=(1, 0.5, 0.02, 0.1), dendrogram_ratio=(0.2, 0.05))\n",
    "        plt.setp(cluster_map.ax_heatmap.get_xticklabels(), rotation=45) \n",
    "        #cluster_map.figure.suptitle(result_name)\n",
    "        \n",
    "        \n",
    "        plt.savefig(out_path + \"/\" + result_name +  \"_cluster_condition_activity_difference_compressed.pdf\", bbox_inches='tight')\n",
    "        plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def map_t_value(tf_scores_df, anndataobject_markers):\n",
    "    genes = []\n",
    "    clusters = []\n",
    "    t_values = []  \n",
    "    anndataobject_markers = anndataobject_markers.set_index(\"gene\")\n",
    "    \n",
    "    for i in range(len(anndataobject_markers.index)):\n",
    "        a = anndataobject_markers.index[i]\n",
    "        for j in range(len(tf_scores_df.index)):\n",
    "            b = tf_scores_df.index[j]\n",
    "            if a == b:\n",
    "                c = anndataobject_markers.columns.get_loc(\"cluster\")\n",
    "                cluster = anndataobject_markers.iloc[i, c]\n",
    "                gene_rows = tf_scores_df.iloc[j]\n",
    "                if isinstance(gene_rows, pd.Series):\n",
    "                    gene_rows = gene_rows.to_frame().T\n",
    "\n",
    "                for _, gene_row in gene_rows.iterrows():\n",
    "                     score = gene_row[cluster]\n",
    "                     genes.append(a)\n",
    "                     clusters.append(cluster)\n",
    "                     t_values.append(score)\n",
    "\n",
    "    t_value_df = pd.DataFrame({\n",
    "        'gene': genes,\n",
    "        'cluster': clusters,\n",
    "        't_value': t_values\n",
    "    })\n",
    "\n",
    "    return t_value_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_entry(source, target, gene_A, gene_B, type_gene_A, type_gene_B, MeanLR):\n",
    "  df = {\"source\" : source,\n",
    "      \"target\" : target,\n",
    "      \"gene_A\" : gene_A,\n",
    "      \"gene_B\" : gene_B,\n",
    "      \"type_gene_A\" : type_gene_A,\n",
    "      \"type_gene_B\" : type_gene_B,\n",
    "      \"MeanLR\" : MeanLR}\n",
    "\n",
    "  return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_CrossTalkeR_input(tf_activities, gene_expression, out_path, regulon = None, organism = \"human\"):\n",
    "\n",
    "  if organism == \"human\":\n",
    "    ligands = pd.read_csv(\"ligands_human.csv\")\n",
    "    R2TF = pd.read_csv(\"rtf_db_human.csv\")\n",
    "  elif organism == \"mouse\": \n",
    "    ligands = pd.read_csv(\"ligands_mouse.csv\")\n",
    "    R2TF = pd.read_csv(\"rtf_db_mouse.csv\")\n",
    "  else:\n",
    "    NameError(\"Invalid organism to generate CrossTalkeR input!\")\n",
    "\n",
    "  ligands = ligands.drop_duplicates()\n",
    "  R2TF = R2TF.set_index(\"tf\")\n",
    "\n",
    "  sorted_regulon = regulon[[\"tf\", \"target\"]]\n",
    "  sorted_regulon = sorted_regulon.set_index(\"tf\")\n",
    "\n",
    "  tf_activities = tf_activities[tf_activities[\"t_value\"] > 0]\n",
    "  output_list = []\n",
    "  df_list_l = {}\n",
    "  df_list_r = {}\n",
    "  tf_activities.reset_index(drop = True)\n",
    "\n",
    "  for row in range(len((tf_activities))):\n",
    "    \n",
    "    targets = []\n",
    "    tf_ligands = []\n",
    "    tf = str(tf_activities[\"gene\"].iloc[row])\n",
    "\n",
    "    if tf in sorted_regulon.index:\n",
    "      targets = sorted_regulon.loc[tf, \"target\"]\n",
    "      if isinstance(targets, str):\n",
    "        targets = [targets]\n",
    "      \n",
    "    if tf in R2TF.index:\n",
    "        receptors = R2TF.loc[tf, \"receptor\"]\n",
    "        if isinstance(receptors, str):\n",
    "          receptors = [receptors]\n",
    "          \n",
    "    else:\n",
    "        receptors = []\n",
    "\n",
    "\n",
    "    if len(targets) > 0:\n",
    "      tf_ligands = np.intersect1d(targets, ligands)\n",
    "    #print(tf_ligands)\n",
    "\n",
    "    if organism == \"human\":\n",
    "      if len(tf_ligands) > 0:\n",
    "        existing_entries = set()\n",
    "        for ligand in tf_ligands:\n",
    "            expressed = False\n",
    "            if ligand in gene_expression.index:\n",
    "              ex_value = gene_expression.loc[ligand, tf_activities.iloc[row, tf_activities.columns.get_loc(\"cluster\")]]\n",
    "              if (ex_value != 0):\n",
    "                expressed = True\n",
    "\n",
    "            if (expressed == True):\n",
    "              df_list_l = add_entry(source = tf_activities.iloc[row, tf_activities.columns.get_loc(\"cluster\")],\n",
    "                                                      target = tf_activities.iloc[row, tf_activities.columns.get_loc(\"cluster\")],\n",
    "                                                      gene_A =tf_activities.iloc[row, tf_activities.columns.get_loc(\"gene\")],\n",
    "                                                      gene_B = ligand,\n",
    "                                                      type_gene_A = \"Transcription Factor\",\n",
    "                                                      type_gene_B= \"Ligand\",\n",
    "                                                      MeanLR= tf_activities.iloc[row, tf_activities.columns.get_loc(\"t_value\")]\n",
    "                                                      )\n",
    "              \n",
    "              if (ligand, tf) not in existing_entries:\n",
    "                existing_entries.add((ligand, tf))\n",
    "                output_list.append(df_list_l)\n",
    "              \n",
    "\n",
    "      if (len(receptors) > 0):\n",
    "        for receptor in receptors:\n",
    "          df_list_r = add_entry(source =  tf_activities.iloc[row, tf_activities.columns.get_loc(\"cluster\")],\n",
    "                                                target = tf_activities.iloc[row, tf_activities.columns.get_loc(\"cluster\")],\n",
    "                                                gene_A= receptor,\n",
    "                                                gene_B= tf_activities.iloc[row, tf_activities.columns.get_loc(\"gene\")],\n",
    "                                                type_gene_A= \"Receptor\",\n",
    "                                                type_gene_B= \"Transcription Factor\",\n",
    "                                                MeanLR= tf_activities.iloc[row, tf_activities.columns.get_loc(\"t_value\")]\n",
    "                                                )\n",
    "          output_list.append(df_list_r)\n",
    "\n",
    "      \n",
    "          \n",
    "    else: \n",
    "      if len(tf_ligands) > 0:\n",
    "        existing_entries = set()\n",
    "        for ligand in tf_ligands:\n",
    "            expressed = False\n",
    "            if ligand in gene_expression.index:\n",
    "              ex_value = gene_expression.loc[ligand, tf_activities.iloc[row, tf_activities.columns.get_loc(\"cluster\")]]\n",
    "              if (ex_value != 0):\n",
    "                 expressed = True\n",
    "          \n",
    "  \n",
    "              if (expressed == True):\n",
    "                df_list_l = add_entry(source = tf_activities.iloc[row, tf_activities.columns.get_loc(\"cluster\")],\n",
    "                                                      target = tf_activities.iloc[row, tf_activities.columns.get_loc(\"cluster\")],\n",
    "                                                      gene_A =tf_activities.iloc[row, tf_activities.columns.get_loc(\"gene\")],\n",
    "                                                      gene_B = ligand,\n",
    "                                                      type_gene_A = \"Transcription Factor\",\n",
    "                                                      type_gene_B= \"Ligand\",\n",
    "                                                      MeanLR= tf_activities.iloc[row, tf_activities.columns.get_loc(\"t_value\")]\n",
    "                                                      )\n",
    "                \n",
    "                if (ligand, tf) not in existing_entries:\n",
    "                  existing_entries.add((ligand, tf))\n",
    "                  output_list.append(df_list_l)\n",
    "                  \n",
    "      if (len(receptors) > 0):\n",
    "        for receptor in receptors:\n",
    "          df_list_r = add_entry(source =  tf_activities.iloc[row, tf_activities.columns.get_loc(\"cluster\")],\n",
    "                                                target = tf_activities.iloc[row, tf_activities.columns.get_loc(\"cluster\")],\n",
    "                                                gene_A= receptor,\n",
    "                                                gene_B= tf_activities.iloc[row, tf_activities.columns.get_loc(\"gene\")],\n",
    "                                                type_gene_A= \"Receptor\",\n",
    "                                                type_gene_B= \"Transcription Factor\",\n",
    "                                                MeanLR= tf_activities.iloc[row, tf_activities.columns.get_loc(\"t_value\")]\n",
    "                                                )\n",
    "                                                \n",
    "          output_list.append(df_list_r)\n",
    "        #tf_l.to_csv(single_result_path + \"/\" + renamed_condition + \"_ctr_test_l.csv\", index=0)\n",
    "        #r_tf.to_csv(single_result_path + \"/\" + renamed_condition + \"_ctr_test_r.csv\", index=0)\n",
    "   \n",
    "\n",
    "  output_df = pd.DataFrame(output_list)\n",
    "  output_df[\"gene_A\"] = output_df[\"gene_A\"].apply(lambda x: re.sub(\"_\", \"+\", x))\n",
    "  output_df[\"gene_B\"] = output_df[\"gene_B\"].apply(lambda x: re.sub(\"_\", \"+\", x))\n",
    "  output_df.drop_duplicates(inplace=True)\n",
    "  output_df.to_csv(\"tf_l_r_R_data_cond_contr.csv\", index=0)\n",
    "\n",
    "\n",
    "  return output_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_intracellular_network(tf_activities, gene_expression, outpath, regulon, organism=\"human\"):\n",
    "\n",
    "    if len(tf_activities.shape) > 0:\n",
    "        if organism == \"human\":\n",
    "            R2TF = pd.read_csv(\"rtf_db_human.csv\").set_index(\"tf\")\n",
    "        else:\n",
    "            R2TF = pd.read_csv(\"rtf_db_mouse.csv\").set_index(\"tf\")\n",
    "\n",
    "    sorted_regulon = regulon[[\"tf\", \"target\"]].set_index(\"tf\")\n",
    "\n",
    "    #preextract values\n",
    "    tf_genes = tf_activities[\"gene\"].values\n",
    "    tf_celltypes = tf_activities.iloc[:, 2].values\n",
    "    tf_scores = tf_activities.iloc[:, 3].values\n",
    "\n",
    "    TFTG_list = []\n",
    "    RTF_list = []\n",
    "\n",
    "    tf_activities = tf_activities[tf_activities[\"t_value\"] > 0]\n",
    "    tf_activities.reset_index(drop = True)\n",
    "    for row in range(len(tf_activities)):\n",
    "        tf = str(tf_genes[row])\n",
    "        celltype = tf_celltypes[row]\n",
    "        tf_score = tf_scores[row]\n",
    "\n",
    "        targets = sorted_regulon.loc[tf, \"target\"] if tf in sorted_regulon.index else []\n",
    "        #print(targets)\n",
    "        if tf in R2TF.index:\n",
    "           receptors = R2TF.loc[tf, \"receptor\"]\n",
    "           receptors = [receptors] if isinstance(receptors, str) else receptors\n",
    "        else:\n",
    "           receptors = []\n",
    "\n",
    "        if len(targets) > 0 and len(receptors) > 0:\n",
    "            for target in targets:\n",
    "          \n",
    "                if target in gene_expression.index:\n",
    "                    ex_value = gene_expression.at[target, celltype]\n",
    "         \n",
    "                    if ex_value != 0:\n",
    "                        TFTG_list.append({\n",
    "                            \"celltype\": celltype,\n",
    "                            \"TF\": tf,\n",
    "                            \"Target_Gene\": target,\n",
    "                            \"TF_Score\": tf_score\n",
    "                        })\n",
    "\n",
    "            for receptor in receptors:\n",
    "                RTF_list.append({\n",
    "                    \"TF\": tf,\n",
    "                    \"Receptor\": receptor\n",
    "                })\n",
    "\n",
    "    TFTG_df = pd.DataFrame(TFTG_list)\n",
    "    RTF_df = pd.DataFrame(RTF_list)\n",
    "\n",
    "    recept_regulon = pd.merge(RTF_df, TFTG_df, on=\"TF\")\n",
    "    recept_regulon = recept_regulon.sort_values(\"TF\")\n",
    "    return recept_regulon"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "#decoupler condition comparison\n",
    "def condition_comparison_significant(tf_activities, out_path, celltype, condition, comparison_list, num_cell_filter = 0):\n",
    "\n",
    "    vs_df_dic = {}\n",
    "\n",
    "    if isinstance(comparison_list[0], str):  \n",
    "        comparison_list = [comparison_list]\n",
    "    \n",
    "    for vs1, vs2 in comparison_list:\n",
    "\n",
    "        print(f\"vs1: {vs1}, vs2: {vs2}\") \n",
    "\n",
    "        all_tf_list = tf_activities.var_names\n",
    "\n",
    "        res = pd.DataFrame()\n",
    "        for i in tf_activities.obs[celltype].unique(): \n",
    "            comparison_sub = tf_activities[(tf_activities.obs[celltype] == i) & (tf_activities.obs[condition].isin([vs1, vs2]))]\n",
    "            if len(pd.unique(comparison_sub.obs[condition])) == 2:\n",
    "                condition_table = comparison_sub.obs[[condition]].copy()\n",
    "                condition_table.columns = [\"condition\"]\n",
    "                metadata_counts = condition_table.groupby(\"condition\", observed = False).size()\n",
    "                \n",
    "                if (metadata_counts.iloc[0] + metadata_counts.iloc[1]) > num_cell_filter:\n",
    "                    g = comparison_sub.obs[condition].astype(\"category\")\n",
    "                    g = g.cat.set_categories([vs1, vs2])\n",
    "        \n",
    "                    #finding markers for the condition comparison\n",
    "                    res_tmp = dc.rank_sources_groups(comparison_sub, groupby= condition, reference=\"rest\", method=\"t-test\")\n",
    "                    res_tmp.rename(columns={\"group\": \"condition\", \"statistic\" : \"scores\"}, inplace=True)\n",
    "            \n",
    "                    #calculating wilcoxon scores to use for r value calculation (used in heatmaps)\n",
    "                    res_heatmap = dc.rank_sources_groups(comparison_sub, groupby= condition, reference=\"rest\", method=\"wilcoxon\")\n",
    "                    res_heatmap.rename(columns={\"group\": \"condition\", \"statistic\" : \"scores\"}, inplace=True)\n",
    "\n",
    "                    group1 = comparison_sub.X[g == vs1]\n",
    "                    group2 = comparison_sub.X[g == vs2]\n",
    "                        \n",
    "                    res_heatmap[\"r\"] = (res_heatmap[\"scores\"] / np.sqrt(len(group1) + len(group2)))\n",
    "                    res_heatmap[\"CellType\"] = i\n",
    "                    res_tmp[\"CellType\"] = i\n",
    "                    _, res_tmp[\"FDR\"], _, _ = multipletests(res_tmp[\"pvals\"], alpha=0.05, method='fdr_bh')\n",
    "                    \n",
    "                    \n",
    "                    res_tmp = res_tmp[res_tmp[\"condition\"] == vs1]\n",
    "\n",
    "                    res_heatmap = res_heatmap[[\"names\", \"r\", \"CellType\", \"condition\"]]\n",
    "                    res_tmp = pd.merge(res_tmp, res_heatmap, on = [\"names\",\"CellType\", \"condition\"])\n",
    "\n",
    "                    res = pd.concat([res, res_tmp], ignore_index=True)\n",
    "\n",
    "        res_df = res.dropna()\n",
    "\n",
    "        def assign_significance_tag(fdr):\n",
    "            if fdr < 0.001:\n",
    "                return \"***\"\n",
    "            elif fdr < 0.01:\n",
    "                return \"**\"\n",
    "            elif fdr < 0.05:\n",
    "                return \"*\"\n",
    "            else:\n",
    "                return \"ns\"\n",
    "\n",
    "        res_df = res_df.assign(tag=res_df[\"FDR\"].apply(assign_significance_tag))\n",
    "\n",
    "        res_df.rename(columns={\"names\":\"tf\", \"group\": \"condition\"}, inplace=True)\n",
    "        res_df.to_csv(f\"{out_path}/all_tfs_{vs1}_vs_{vs2}.csv\", index=False)\n",
    "\n",
    "        result_name = f\"{vs1}_{vs2}\"\n",
    "        vs_df_dic[result_name] = res_df\n",
    "    return vs_df_dic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "#decoupler significant tfs\n",
    "\n",
    "def get_significant_tfs(tf_activities_sub, condition, out_path, tf_condition_significant, celltype, pval, meanchange, plot, condition_comparison = False):\n",
    "    \n",
    "\n",
    "    renamed_condition = condition.replace(\",\", \"_\")\n",
    "\n",
    "    single_result_path = out_path + renamed_condition \n",
    "    if not os.path.isdir(single_result_path):\n",
    "        os.mkdir(single_result_path)\n",
    "\n",
    "    #number_of_clusters = len(tf_activities_sub.obs[celltype].cat.categories) \n",
    "    number_of_clusters = (len(tf_activities_sub.obs[celltype].unique()))\n",
    "                          \n",
    "    anndataobject_markers_wilcoxon = dc.rank_sources_groups(tf_activities_sub, groupby= celltype, reference=\"rest\", method=\"t-test\")\n",
    "\n",
    "    anndataobject_markers_wilcoxon.rename(columns={\"names\" : \"gene\", \"group\": \"cluster\", \"statistic\" : \"scores\"}, inplace=True)\n",
    "    \n",
    "    \n",
    "    anndataobject_markers_wilcoxon[\"tag\"] = None\n",
    "    anndataobject_markers_wilcoxon[\"meanchange_tag\"] = None\n",
    "    \n",
    "    #print(\"after concat\", anndataobject_markers_wilcoxon)\n",
    "    \n",
    "    anndataobject_markers_wilcoxon[\"tag\"] = anndataobject_markers_wilcoxon[\"pvals_adj\"].apply(eval_pval)\n",
    "    anndataobject_markers_wilcoxon[\"meanchange_tag\"] = anndataobject_markers_wilcoxon[\"meanchange\"].apply(eval_meanchange_tag)\n",
    "     \n",
    "\n",
    "    anndataobject_markers_wilcoxon.to_csv(single_result_path + \"/\" + renamed_condition + \"_specific_markers_wilcoxon_test.csv\",index=0)\n",
    "\n",
    "   #tag mapping wilcoxon\n",
    "    clusters = sorted(anndataobject_markers_wilcoxon[\"cluster\"].unique())\n",
    "    tag_mapping_wilcox = anndataobject_markers_wilcoxon[[\"gene\", \"tag\", \"meanchange_tag\", \"cluster\", \"pvals_adj\", \"meanchange\"]]\n",
    "    tag_mapping_wilcox = tag_mapping_wilcox[(tag_mapping_wilcox[\"pvals_adj\"] < float(pval))] \n",
    "    tag_mapping_wilcox = tag_mapping_wilcox[(tag_mapping_wilcox[\"meanchange\"] > float(meanchange)) | \n",
    "                              (tag_mapping_wilcox[\"meanchange\"] < -float(meanchange))]\n",
    "\n",
    "    tag_mapping_wilcox = tag_mapping_wilcox.pivot(index=\"gene\", columns=\"cluster\", values=\"tag\")\n",
    "\n",
    "    for cluster in clusters:\n",
    "        if cluster not in tag_mapping_wilcox.columns:\n",
    "            tag_mapping_wilcox[cluster] = np.nan\n",
    "\n",
    "    tag_mapping_wilcox = tag_mapping_wilcox[clusters]\n",
    "    tag_mapping_wilcox = tag_mapping_wilcox.astype(\"object\")\n",
    "    tag_mapping_wilcox.fillna(\"ns\", inplace=True)\n",
    "\n",
    "    #tag_mapping_wilcox.to_csv(\"tag_mapping.csv\",index=0)\n",
    "\n",
    "    tf_activities_sub.obs_names = tf_activities_sub.obs[celltype].astype(str)\n",
    "    tf_scores_df = tf_activities_sub.to_df()\n",
    "    #tf_scores_df.columns.name = None\n",
    "    unfiltered_tf_scores = create_unfiltered_tf_scores(tf_scores_df, condition, celltype, single_result_path)\n",
    "   \n",
    "    #Filter to only include tfs that match the tag_mapping/are markers\n",
    "    #print(tag_mapping_wilcox)\n",
    "    col_num = tf_scores_df.columns.isin(tag_mapping_wilcox.index)  \n",
    "    filtered_tf_scores_df = tf_scores_df.loc[:, col_num]\n",
    "\n",
    "\n",
    "    filtered_summarized_tf_scores_df = filtered_tf_scores_df.groupby(celltype, observed = False).mean().T\n",
    "    filtered_summarized_tf_scores_df.sort_index(axis=1, inplace=True)\n",
    "    filtered_summarized_tf_scores_df.index.name = \"gene\"\n",
    "    filtered_summarized_tf_scores_df.to_csv(f\"{single_result_path}/tf_scores_{condition}.csv\")\n",
    "    tf_scores_variable_table = save_variable_tf_score(filtered_summarized_tf_scores_df, condition, single_result_path, plot)\n",
    "\n",
    "    if plot:\n",
    "        plot_tf_activity(filtered_summarized_tf_scores_df, tag_mapping_wilcox, condition, single_result_path)\n",
    "    \n",
    "    filtered_summarized_tf_scores_df.index = filtered_summarized_tf_scores_df.index.map(lambda x: re.sub(\".,\", \"_\", x))\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    anndataobject_markers_wilcoxon_merged = anndataobject_markers_wilcoxon.merge(map_t_value(filtered_summarized_tf_scores_df, anndataobject_markers_wilcoxon),  on=['gene', 'cluster'], how='inner')\n",
    "    anndataobject_markers_wilcoxon_merged = anndataobject_markers_wilcoxon_merged[anndataobject_markers_wilcoxon_merged.tag != \"ns\"]\n",
    "    anndataobject_markers_wilcoxon_merged = anndataobject_markers_wilcoxon_merged.where(anndataobject_markers_wilcoxon_merged[\"t_value\"] > 0, np.nan) \n",
    "    anndataobject_markers_wilcoxon_merged.dropna(inplace=True)\n",
    "    res_wilcoxon = anndataobject_markers_wilcoxon_merged[[\"gene\",\"tag\", \"cluster\", \"t_value\"]]\n",
    "\n",
    "\n",
    "    #anndataobject_markers_t_over_merged = anndataobject_markers_t_over.merge(map_z_value_filtered(filtered_summarized_tf_scores_df, anndataobject_markers_t_over),  on=['gene', 'cluster'], how='inner')\n",
    "    #anndataobject_markers_t_over_merged = anndataobject_markers_t_over_merged[anndataobject_markers_t_over_merged.tag != \"ns\"]\n",
    "    #anndataobject_markers_t_over_merged.dropna(inplace=True)\n",
    "    #res_t_test = anndataobject_markers_t_over[[\"gene\",\"tag\", \"cluster\", \"t_value\"]]\n",
    "\n",
    "    res_wilcoxon.to_csv(single_result_path + \"/significant_cluster_tf_results_wilcoxon_\" + renamed_condition + \".csv\", index=0)\n",
    "    #res_t_test.to_csv(single_result_path  + \"/_significant_cluster_tf_results_t_test_\" + renamed_condition + \".csv\", index=0)\n",
    "\n",
    "    res = {}\n",
    "    res[\"cluster\"] = res_wilcoxon\n",
    "    \n",
    "\n",
    "    if condition_comparison:\n",
    "        unfiltered_tf_scores = unfiltered_tf_scores.where(unfiltered_tf_scores > 0, np.nan) \n",
    "        tf_condition_significant[\"gene\"] = tf_condition_significant[\"gene\"].apply(lambda x: re.sub(\".,\", \"_\", x))\n",
    "        tf_condition_significant = tf_condition_significant.merge(map_t_value(unfiltered_tf_scores, tf_condition_significant), left_on=None, right_on=None, left_index=False, right_index=False)\n",
    "        tf_condition_significant.dropna(inplace=True)\n",
    "    \n",
    "        res[\"condition\"] = tf_condition_significant\n",
    "        res[\"condition\"].to_csv(f\"{single_result_path}/significant_condition_tf_results_{condition}.csv\", index=0)\n",
    "\n",
    "    return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def IntraTalker_analysis(anndataobject, tf_activities = None, arguments_list = None):\n",
    "    \n",
    "    if (isinstance(anndataobject, str)):\n",
    "        anndataobject = ad.read_h5ad(anndataobject)\n",
    "\n",
    "    arguments_list = validate_input_arguments(arguments_list)\n",
    "\n",
    "    if arguments_list[\"decoupler_matrix_format\"] == \"R\":\n",
    "        anndataobject = anndataobject.T\n",
    "\n",
    "    if not os.path.isdir(arguments_list[\"out_path\"]):\n",
    "        os.mkdir(arguments_list[\"out_path\"])\n",
    "        tf_path = arguments_list[\"out_path\"] + \"TF_results/\"\n",
    "        os.mkdir(tf_path)\n",
    "    else:\n",
    "        tf_path = arguments_list[\"out_path\"] + \"TF_results/\"\n",
    "\n",
    "\n",
    "    condition = anndataobject.obs[arguments_list[\"condition\"]]\n",
    "\n",
    "    if isinstance(tf_activities, str):\n",
    "         tf_activities = ad.read_csv(tf_activities)\n",
    "         tf_activities.obs = anndataobject.obs.reindex(tf_activities.obs.index)\n",
    "         tf_activities.obsm = anndataobject.obsm\n",
    "         tf_activities.uns = anndataobject.uns\n",
    "\n",
    "    elif isinstance(tf_activities, pd.DataFrame):\n",
    "         tf_activities = ad.AnnData(tf_activities)\n",
    "         tf_activities.obs = anndataobject.obs.reindex(tf_activities.obs.index)\n",
    "         tf_activities.obsm = anndataobject.obsm\n",
    "         tf_activities.uns = anndataobject.uns\n",
    "\n",
    "    elif tf_activities is None:\n",
    "         raise NameError(\"Please attach a csv file with the tf activity values. (For further clarification view the 'Decoupler' section of the vignette.)\")\n",
    "    \n",
    "    sc.pp.scale(tf_activities)\n",
    "\n",
    "    #sets the stage for decision if single condition or comparison analysis is done\n",
    "    \n",
    "    if not arguments_list[\"comparison_list\"] is None:\n",
    "        if (len(arguments_list[\"comparison_list\"]) > 0) & (len(pd.unique(anndataobject.obs[arguments_list[\"condition\"]])) < 2):\n",
    "            arguments_list[\"comparison_list\"] = None\n",
    "            print(\"Only one condition was found in the data, although a list of comparisons was provided. The analyses are performed only for the present condition!\")\n",
    "\n",
    "    #code for single condition  analysis\n",
    "\n",
    "    if arguments_list[\"comparison_list\"] is None:\n",
    "\n",
    "        result_list = {}\n",
    "        gene_expression_list = {}\n",
    "        CTR_cluster_list = {}\n",
    "        intranet_cluster_list = {}\n",
    "\n",
    "        #creates loop until after tf activity score\n",
    "        \n",
    "        for name_iterable in anndataobject.obs[arguments_list[\"condition\"]].unique():\n",
    "            sub_object = anndataobject[anndataobject.obs[arguments_list[\"condition\"]] == name_iterable].copy()\n",
    "            tf_activities_sub = tf_activities[tf_activities.obs[arguments_list[\"condition\"]] == name_iterable].copy()\n",
    "\n",
    "            sub_object_avg = AverageExpression(sub_object, name_iterable= name_iterable, celltype = arguments_list[\"celltype\"], outpath= arguments_list[\"out_path\"])\n",
    "        \n",
    "            \n",
    "            tf_activity_scores = get_significant_tfs(tf_activities_sub,\n",
    "                                                        name_iterable,\n",
    "                                                        tf_path,\n",
    "                                                        None,\n",
    "                                                        celltype = arguments_list[\"celltype\"],\n",
    "                                                        pval = arguments_list[\"pval\"],\n",
    "                                                        meanchange = arguments_list[\"meanchange\"],\n",
    "                                                        plot = arguments_list[\"plot\"],\n",
    "                                                        condition_comparison= False)\n",
    "            \n",
    "\n",
    "            result_list[name_iterable] = tf_activity_scores\n",
    "            \n",
    "            gene_expression_list[name_iterable] = sub_object_avg\n",
    "            \n",
    "        \n",
    "    \n",
    "            CTR_cluster_list[name_iterable] = generate_CrossTalkeR_input(tf_activity_scores[\"cluster\"],\n",
    "                                                                            gene_expression_list[name_iterable],\n",
    "                                                                            arguments_list[\"out_path\"],                                             \n",
    "                                                                            arguments_list[\"reg\"],\n",
    "                                                                            arguments_list[\"organism\"])\n",
    "    \n",
    "              \n",
    "            intranet_cluster_list[name_iterable] = generate_intracellular_network(tf_activity_scores[\"cluster\"],\n",
    "                                                                                  gene_expression_list[name_iterable],\n",
    "                                                                                  arguments_list[\"out_path\"],\n",
    "                                                                                  arguments_list[\"reg\"],\n",
    "                                                                                  arguments_list[\"organism\"])\n",
    "            \n",
    "\n",
    "        tf = make_TFOBj(\n",
    "                tf_activities_condition = list(),\n",
    "                tf_activities_cluster = result_list,\n",
    "                average_gene_expression = gene_expression_list,\n",
    "                regulon = arguments_list[\"reg\"],\n",
    "                CTR_input_condition = list(),\n",
    "                CTR_input_cluster = CTR_cluster_list,\n",
    "                intracellular_network_condition = list(),\n",
    "                intracellular_network_cluster = intranet_cluster_list)\n",
    "\n",
    "        #with open((arguments_list[\"out_path\"] + \"tf.pickle\"), \"wb\") as file:\n",
    "        #    pickle.dump(tf, file)\n",
    "\n",
    "        return tf\n",
    "\n",
    "    else:\n",
    "        out_path_compared = (tf_path + \"compared\")\n",
    "        if not os.path.isdir(out_path_compared):\n",
    "            os.mkdir(out_path_compared)\n",
    "\n",
    "        compared_significant_tfs = condition_comparison_significant(tf_activities, out_path_compared, arguments_list[\"celltype\"], \n",
    "                                                                    arguments_list[\"condition\"], arguments_list[\"comparison_list\"], \n",
    "                                                                    arguments_list[\"num_cell_filter\"])\n",
    "        \n",
    "        print(\"compared tfs done\")\n",
    "        \n",
    "        if arguments_list[\"plot\"] == True:\n",
    "            plot_condition_tf_activities(compared_significant_tfs, out_path_compared)\n",
    "            plot_condition_tf_activities_compressed(compared_significant_tfs, out_path_compared)\n",
    "\n",
    "    \n",
    "        result_condition_list = {}\n",
    "        result_cluster_list = {}\n",
    "        gene_expression_list = {}\n",
    "        CTR_condition_list = {}\n",
    "        CTR_cluster_list = {}\n",
    "        intranet_condition_list = {}\n",
    "        intranet_cluster_list = {}\n",
    "\n",
    "        for name_iterable in anndataobject.obs[arguments_list[\"condition\"]].unique():\n",
    "            sub_object = anndataobject[anndataobject.obs[arguments_list[\"condition\"]] == name_iterable]\n",
    "            tf_activities_sub = tf_activities[tf_activities.obs[arguments_list[\"condition\"]] == name_iterable]\n",
    "            \n",
    "\n",
    "            compared_tfs = pd.DataFrame({\"gene\" : pd.Series(dtype=\"str\"), \"tag\" : pd.Series(dtype=\"str\"), \"cluster\" : pd.Series(dtype=\"str\")})\n",
    "        \n",
    "            for result_name, df in compared_significant_tfs.items(): \n",
    "                if name_iterable in result_name:\n",
    "                    tf_condition_significant = compared_significant_tfs[result_name]\n",
    "                    tf_condition_significant = tf_condition_significant[tf_condition_significant[\"FDR\"] < arguments_list[\"pval\"]]\n",
    "                    tf_condition_significant = tf_condition_significant[(tf_condition_significant[\"meanchange\"] > float(arguments_list[\"meanchange\"])) | (tf_condition_significant[\"meanchange\"] < (0 - float(arguments_list[\"meanchange\"])))]\n",
    "                    tf_condition_significant = tf_condition_significant[[\"tf\", \"tag\", \"CellType\"]]\n",
    "                    tf_condition_significant.rename(columns={\"tf\":\"gene\", \"CellType\": \"cluster\"}, inplace=True)\n",
    "                    compared_tfs = pd.concat([compared_tfs, tf_condition_significant])\n",
    "\n",
    "        \n",
    "            \n",
    "            re.sub(\"([,;.:-])\", \"_\", name_iterable)\n",
    "\n",
    "            sub_object_avg = AverageExpression(sub_object, name_iterable= name_iterable, celltype = arguments_list[\"celltype\"], \n",
    "                                               outpath= arguments_list[\"out_path\"])\n",
    "            \n",
    "            tf_activity_scores = get_significant_tfs(tf_activities_sub,\n",
    "                                               name_iterable,\n",
    "                                               tf_path,\n",
    "                                               compared_tfs,\n",
    "                                               celltype = arguments_list[\"celltype\"],\n",
    "                                               pval = arguments_list[\"pval\"],\n",
    "                                               meanchange = arguments_list[\"meanchange\"],\n",
    "                                               plot = arguments_list[\"plot\"],\n",
    "                                               condition_comparison= True)\n",
    "            \n",
    "            print(\"tf_activities done\")\n",
    "\n",
    "            result_condition_list[name_iterable] = tf_activity_scores[\"condition\"]\n",
    "            result_cluster_list[name_iterable] = tf_activity_scores[\"cluster\"]\n",
    "\n",
    "\n",
    "            gene_expression_list[name_iterable] = sub_object_avg\n",
    "            \n",
    "        \n",
    "            CTR_condition_list[name_iterable] = generate_CrossTalkeR_input(tf_activity_scores[\"condition\"],\n",
    "                                                                            gene_expression_list[name_iterable],\n",
    "                                                                           arguments_list[\"out_path\"],                                             \n",
    "                                                                           arguments_list[\"reg\"],\n",
    "                                                                           arguments_list[\"organism\"])\n",
    "            \n",
    "            print(\"CTR input condition done\")\n",
    "    \n",
    "            CTR_cluster_list[name_iterable] = generate_CrossTalkeR_input(tf_activity_scores[\"cluster\"],\n",
    "                                                                            gene_expression_list[name_iterable],\n",
    "                                                                            arguments_list[\"out_path\"],                                             \n",
    "                                                                            arguments_list[\"reg\"],\n",
    "                                                                            arguments_list[\"organism\"])\n",
    "    \n",
    "            print(\"CTR input cluster done\")\n",
    "\n",
    "            intranet_condition_list[name_iterable] = generate_intracellular_network(tf_activity_scores[\"condition\"],\n",
    "                                                                                  gene_expression_list[name_iterable],\n",
    "                                                                                  arguments_list[\"out_path\"],\n",
    "                                                                                  arguments_list[\"reg\"],\n",
    "                                                                                  arguments_list[\"organism\"])\n",
    "    \n",
    "            print(\"intranet input condition done\")\n",
    "\n",
    "            intranet_cluster_list[name_iterable] = generate_intracellular_network(tf_activity_scores[\"cluster\"],\n",
    "                                                                                  gene_expression_list[name_iterable],\n",
    "                                                                                  arguments_list[\"out_path\"],\n",
    "                                                                                  arguments_list[\"reg\"],\n",
    "                                                                                  arguments_list[\"organism\"])\n",
    "            print(\"intranet input cluster done\")\n",
    "            #print(CTR_cluster_list[name_iterable])\n",
    "            #print(CTR_condition_list[name_iterable])\n",
    "            \n",
    "        tf = make_TFOBj(\n",
    "                tf_activities_condition = result_condition_list,\n",
    "                tf_activities_cluster = result_cluster_list,\n",
    "                average_gene_expression = gene_expression_list,\n",
    "                regulon = arguments_list[\"reg\"],\n",
    "                CTR_input_condition = CTR_condition_list,\n",
    "                CTR_input_cluster = CTR_cluster_list,\n",
    "                intracellular_network_condition = intranet_condition_list,\n",
    "                intracellular_network_cluster = intranet_cluster_list)\n",
    "\n",
    "        #with open((arguments_list[\"out_path\"] + \"tf.pickle\"), \"wb\") as file:\n",
    "        #    pickle.dump(tf, file)\n",
    "        \n",
    "        return tf\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1596 features of mat are empty, they will be removed.\n",
      "Running ulm on mat with 498 samples and 9830 targets for 141 sources.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00, 13.37it/s]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>AHR</th>\n",
       "      <th>AR</th>\n",
       "      <th>ARNT</th>\n",
       "      <th>ATF1</th>\n",
       "      <th>ATF2</th>\n",
       "      <th>ATF3</th>\n",
       "      <th>ATF4</th>\n",
       "      <th>ATF6</th>\n",
       "      <th>BACH1</th>\n",
       "      <th>BCL6</th>\n",
       "      <th>...</th>\n",
       "      <th>TP73</th>\n",
       "      <th>TWIST1</th>\n",
       "      <th>USF1</th>\n",
       "      <th>USF2</th>\n",
       "      <th>VDR</th>\n",
       "      <th>WT1</th>\n",
       "      <th>YY1</th>\n",
       "      <th>ZBTB33</th>\n",
       "      <th>ZEB1</th>\n",
       "      <th>ZNF263</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>H18_19086_TB_AAATGCCAGTGTACGG-1</th>\n",
       "      <td>-0.325906</td>\n",
       "      <td>-0.358793</td>\n",
       "      <td>2.993710</td>\n",
       "      <td>1.619173</td>\n",
       "      <td>-0.534671</td>\n",
       "      <td>-0.078113</td>\n",
       "      <td>-0.613460</td>\n",
       "      <td>-0.443634</td>\n",
       "      <td>-0.550418</td>\n",
       "      <td>0.102025</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.336646</td>\n",
       "      <td>-0.288940</td>\n",
       "      <td>1.951161</td>\n",
       "      <td>1.460380</td>\n",
       "      <td>0.387064</td>\n",
       "      <td>0.036205</td>\n",
       "      <td>-1.123608</td>\n",
       "      <td>-0.443631</td>\n",
       "      <td>-0.211403</td>\n",
       "      <td>-1.754107</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>H18_19086_TB_AACTCTTCATCGTCGG-1</th>\n",
       "      <td>-0.315984</td>\n",
       "      <td>0.421477</td>\n",
       "      <td>3.141227</td>\n",
       "      <td>3.050140</td>\n",
       "      <td>1.410944</td>\n",
       "      <td>-0.075735</td>\n",
       "      <td>-0.594783</td>\n",
       "      <td>-0.430128</td>\n",
       "      <td>0.856580</td>\n",
       "      <td>-3.338824</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.326397</td>\n",
       "      <td>-0.280143</td>\n",
       "      <td>1.787498</td>\n",
       "      <td>-0.653394</td>\n",
       "      <td>0.500689</td>\n",
       "      <td>0.035103</td>\n",
       "      <td>-0.216114</td>\n",
       "      <td>2.216989</td>\n",
       "      <td>1.931203</td>\n",
       "      <td>-0.549862</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>H18_19086_TB_AATCGGTAGAGAGCTC-1</th>\n",
       "      <td>2.926114</td>\n",
       "      <td>-0.205126</td>\n",
       "      <td>2.748416</td>\n",
       "      <td>-0.569662</td>\n",
       "      <td>-0.572027</td>\n",
       "      <td>-2.438098</td>\n",
       "      <td>1.024219</td>\n",
       "      <td>1.530754</td>\n",
       "      <td>0.655075</td>\n",
       "      <td>-2.966506</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.360167</td>\n",
       "      <td>-0.309127</td>\n",
       "      <td>1.753196</td>\n",
       "      <td>2.721181</td>\n",
       "      <td>0.592756</td>\n",
       "      <td>1.675334</td>\n",
       "      <td>-0.658278</td>\n",
       "      <td>-0.474626</td>\n",
       "      <td>-0.226172</td>\n",
       "      <td>-0.332084</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>H18_19086_TB_ACACCAAGTAAGTGTA-1</th>\n",
       "      <td>-0.311565</td>\n",
       "      <td>1.244379</td>\n",
       "      <td>-0.292659</td>\n",
       "      <td>-0.509029</td>\n",
       "      <td>-0.511143</td>\n",
       "      <td>-0.074676</td>\n",
       "      <td>-0.586464</td>\n",
       "      <td>-0.424112</td>\n",
       "      <td>-0.526197</td>\n",
       "      <td>0.097536</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.321832</td>\n",
       "      <td>-0.276225</td>\n",
       "      <td>0.632570</td>\n",
       "      <td>1.226090</td>\n",
       "      <td>1.226637</td>\n",
       "      <td>0.034612</td>\n",
       "      <td>-1.175481</td>\n",
       "      <td>-0.424109</td>\n",
       "      <td>-0.202100</td>\n",
       "      <td>-1.086718</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>H18_19086_TB_ACAGCCGTCATCTGTT-1</th>\n",
       "      <td>-0.298459</td>\n",
       "      <td>-0.519062</td>\n",
       "      <td>-0.280349</td>\n",
       "      <td>-0.487617</td>\n",
       "      <td>-0.489642</td>\n",
       "      <td>2.699297</td>\n",
       "      <td>-0.561795</td>\n",
       "      <td>-0.406272</td>\n",
       "      <td>2.424264</td>\n",
       "      <td>-3.526518</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.308295</td>\n",
       "      <td>-0.264606</td>\n",
       "      <td>0.704175</td>\n",
       "      <td>1.301231</td>\n",
       "      <td>3.129439</td>\n",
       "      <td>0.033156</td>\n",
       "      <td>-1.192200</td>\n",
       "      <td>-0.406269</td>\n",
       "      <td>-0.193599</td>\n",
       "      <td>-1.000435</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>H18_19892_TB_CAGCAGCGTAACGCGA-1</th>\n",
       "      <td>-0.157385</td>\n",
       "      <td>-0.671958</td>\n",
       "      <td>-0.147835</td>\n",
       "      <td>-0.257130</td>\n",
       "      <td>-0.258198</td>\n",
       "      <td>-0.037722</td>\n",
       "      <td>-0.296245</td>\n",
       "      <td>-0.214237</td>\n",
       "      <td>-0.265802</td>\n",
       "      <td>0.049270</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.162569</td>\n",
       "      <td>-0.139531</td>\n",
       "      <td>-0.412792</td>\n",
       "      <td>-0.325434</td>\n",
       "      <td>-0.674567</td>\n",
       "      <td>0.017483</td>\n",
       "      <td>-0.107640</td>\n",
       "      <td>-0.214234</td>\n",
       "      <td>-0.102089</td>\n",
       "      <td>0.336059</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>H18_19892_TB_GGTGCGTGTTTGTTTC-1</th>\n",
       "      <td>-0.172655</td>\n",
       "      <td>0.622051</td>\n",
       "      <td>-0.162179</td>\n",
       "      <td>-0.282078</td>\n",
       "      <td>-0.283250</td>\n",
       "      <td>-0.041382</td>\n",
       "      <td>-0.324988</td>\n",
       "      <td>-0.235023</td>\n",
       "      <td>-0.291591</td>\n",
       "      <td>0.054050</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.178343</td>\n",
       "      <td>-0.153069</td>\n",
       "      <td>4.096654</td>\n",
       "      <td>2.576151</td>\n",
       "      <td>0.365094</td>\n",
       "      <td>0.019180</td>\n",
       "      <td>-0.118084</td>\n",
       "      <td>-0.235021</td>\n",
       "      <td>-0.111994</td>\n",
       "      <td>0.161071</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>H18_19892_TB_TACCTATCACAGGCCT-1</th>\n",
       "      <td>-0.266279</td>\n",
       "      <td>-1.136935</td>\n",
       "      <td>-0.250122</td>\n",
       "      <td>0.872418</td>\n",
       "      <td>-0.436847</td>\n",
       "      <td>-0.063822</td>\n",
       "      <td>1.690018</td>\n",
       "      <td>-0.362467</td>\n",
       "      <td>-0.449712</td>\n",
       "      <td>0.083359</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.275053</td>\n",
       "      <td>-0.236075</td>\n",
       "      <td>3.743020</td>\n",
       "      <td>1.565482</td>\n",
       "      <td>1.580169</td>\n",
       "      <td>0.029580</td>\n",
       "      <td>-0.182117</td>\n",
       "      <td>2.252446</td>\n",
       "      <td>-0.172724</td>\n",
       "      <td>-0.090670</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>H18_19892_TB_TAGAGCTGTTAGATGA-1</th>\n",
       "      <td>-0.159131</td>\n",
       "      <td>-0.679413</td>\n",
       "      <td>-0.149475</td>\n",
       "      <td>-0.259983</td>\n",
       "      <td>-0.261062</td>\n",
       "      <td>-0.038141</td>\n",
       "      <td>-0.299532</td>\n",
       "      <td>-0.216613</td>\n",
       "      <td>-0.268751</td>\n",
       "      <td>0.049816</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.164373</td>\n",
       "      <td>-0.141079</td>\n",
       "      <td>2.011739</td>\n",
       "      <td>-0.329045</td>\n",
       "      <td>1.679758</td>\n",
       "      <td>0.017677</td>\n",
       "      <td>-0.108834</td>\n",
       "      <td>-0.216612</td>\n",
       "      <td>4.225257</td>\n",
       "      <td>-0.856378</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>H18_19892_TB_TCAACGACAGGTCCAC-1</th>\n",
       "      <td>-0.203516</td>\n",
       "      <td>-0.868931</td>\n",
       "      <td>-0.191167</td>\n",
       "      <td>-0.332499</td>\n",
       "      <td>-0.333879</td>\n",
       "      <td>-0.048779</td>\n",
       "      <td>-0.383079</td>\n",
       "      <td>-0.277032</td>\n",
       "      <td>-0.343712</td>\n",
       "      <td>0.063711</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.210221</td>\n",
       "      <td>-0.180430</td>\n",
       "      <td>-0.533793</td>\n",
       "      <td>-0.420826</td>\n",
       "      <td>0.056480</td>\n",
       "      <td>0.022608</td>\n",
       "      <td>-0.139191</td>\n",
       "      <td>-0.277029</td>\n",
       "      <td>-0.132013</td>\n",
       "      <td>-1.095268</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>498 rows × 141 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                      AHR        AR      ARNT      ATF1  \\\n",
       "H18_19086_TB_AAATGCCAGTGTACGG-1 -0.325906 -0.358793  2.993710  1.619173   \n",
       "H18_19086_TB_AACTCTTCATCGTCGG-1 -0.315984  0.421477  3.141227  3.050140   \n",
       "H18_19086_TB_AATCGGTAGAGAGCTC-1  2.926114 -0.205126  2.748416 -0.569662   \n",
       "H18_19086_TB_ACACCAAGTAAGTGTA-1 -0.311565  1.244379 -0.292659 -0.509029   \n",
       "H18_19086_TB_ACAGCCGTCATCTGTT-1 -0.298459 -0.519062 -0.280349 -0.487617   \n",
       "...                                   ...       ...       ...       ...   \n",
       "H18_19892_TB_CAGCAGCGTAACGCGA-1 -0.157385 -0.671958 -0.147835 -0.257130   \n",
       "H18_19892_TB_GGTGCGTGTTTGTTTC-1 -0.172655  0.622051 -0.162179 -0.282078   \n",
       "H18_19892_TB_TACCTATCACAGGCCT-1 -0.266279 -1.136935 -0.250122  0.872418   \n",
       "H18_19892_TB_TAGAGCTGTTAGATGA-1 -0.159131 -0.679413 -0.149475 -0.259983   \n",
       "H18_19892_TB_TCAACGACAGGTCCAC-1 -0.203516 -0.868931 -0.191167 -0.332499   \n",
       "\n",
       "                                     ATF2      ATF3      ATF4      ATF6  \\\n",
       "H18_19086_TB_AAATGCCAGTGTACGG-1 -0.534671 -0.078113 -0.613460 -0.443634   \n",
       "H18_19086_TB_AACTCTTCATCGTCGG-1  1.410944 -0.075735 -0.594783 -0.430128   \n",
       "H18_19086_TB_AATCGGTAGAGAGCTC-1 -0.572027 -2.438098  1.024219  1.530754   \n",
       "H18_19086_TB_ACACCAAGTAAGTGTA-1 -0.511143 -0.074676 -0.586464 -0.424112   \n",
       "H18_19086_TB_ACAGCCGTCATCTGTT-1 -0.489642  2.699297 -0.561795 -0.406272   \n",
       "...                                   ...       ...       ...       ...   \n",
       "H18_19892_TB_CAGCAGCGTAACGCGA-1 -0.258198 -0.037722 -0.296245 -0.214237   \n",
       "H18_19892_TB_GGTGCGTGTTTGTTTC-1 -0.283250 -0.041382 -0.324988 -0.235023   \n",
       "H18_19892_TB_TACCTATCACAGGCCT-1 -0.436847 -0.063822  1.690018 -0.362467   \n",
       "H18_19892_TB_TAGAGCTGTTAGATGA-1 -0.261062 -0.038141 -0.299532 -0.216613   \n",
       "H18_19892_TB_TCAACGACAGGTCCAC-1 -0.333879 -0.048779 -0.383079 -0.277032   \n",
       "\n",
       "                                    BACH1      BCL6  ...      TP73    TWIST1  \\\n",
       "H18_19086_TB_AAATGCCAGTGTACGG-1 -0.550418  0.102025  ... -0.336646 -0.288940   \n",
       "H18_19086_TB_AACTCTTCATCGTCGG-1  0.856580 -3.338824  ... -0.326397 -0.280143   \n",
       "H18_19086_TB_AATCGGTAGAGAGCTC-1  0.655075 -2.966506  ... -0.360167 -0.309127   \n",
       "H18_19086_TB_ACACCAAGTAAGTGTA-1 -0.526197  0.097536  ... -0.321832 -0.276225   \n",
       "H18_19086_TB_ACAGCCGTCATCTGTT-1  2.424264 -3.526518  ... -0.308295 -0.264606   \n",
       "...                                   ...       ...  ...       ...       ...   \n",
       "H18_19892_TB_CAGCAGCGTAACGCGA-1 -0.265802  0.049270  ... -0.162569 -0.139531   \n",
       "H18_19892_TB_GGTGCGTGTTTGTTTC-1 -0.291591  0.054050  ... -0.178343 -0.153069   \n",
       "H18_19892_TB_TACCTATCACAGGCCT-1 -0.449712  0.083359  ... -0.275053 -0.236075   \n",
       "H18_19892_TB_TAGAGCTGTTAGATGA-1 -0.268751  0.049816  ... -0.164373 -0.141079   \n",
       "H18_19892_TB_TCAACGACAGGTCCAC-1 -0.343712  0.063711  ... -0.210221 -0.180430   \n",
       "\n",
       "                                     USF1      USF2       VDR       WT1  \\\n",
       "H18_19086_TB_AAATGCCAGTGTACGG-1  1.951161  1.460380  0.387064  0.036205   \n",
       "H18_19086_TB_AACTCTTCATCGTCGG-1  1.787498 -0.653394  0.500689  0.035103   \n",
       "H18_19086_TB_AATCGGTAGAGAGCTC-1  1.753196  2.721181  0.592756  1.675334   \n",
       "H18_19086_TB_ACACCAAGTAAGTGTA-1  0.632570  1.226090  1.226637  0.034612   \n",
       "H18_19086_TB_ACAGCCGTCATCTGTT-1  0.704175  1.301231  3.129439  0.033156   \n",
       "...                                   ...       ...       ...       ...   \n",
       "H18_19892_TB_CAGCAGCGTAACGCGA-1 -0.412792 -0.325434 -0.674567  0.017483   \n",
       "H18_19892_TB_GGTGCGTGTTTGTTTC-1  4.096654  2.576151  0.365094  0.019180   \n",
       "H18_19892_TB_TACCTATCACAGGCCT-1  3.743020  1.565482  1.580169  0.029580   \n",
       "H18_19892_TB_TAGAGCTGTTAGATGA-1  2.011739 -0.329045  1.679758  0.017677   \n",
       "H18_19892_TB_TCAACGACAGGTCCAC-1 -0.533793 -0.420826  0.056480  0.022608   \n",
       "\n",
       "                                      YY1    ZBTB33      ZEB1    ZNF263  \n",
       "H18_19086_TB_AAATGCCAGTGTACGG-1 -1.123608 -0.443631 -0.211403 -1.754107  \n",
       "H18_19086_TB_AACTCTTCATCGTCGG-1 -0.216114  2.216989  1.931203 -0.549862  \n",
       "H18_19086_TB_AATCGGTAGAGAGCTC-1 -0.658278 -0.474626 -0.226172 -0.332084  \n",
       "H18_19086_TB_ACACCAAGTAAGTGTA-1 -1.175481 -0.424109 -0.202100 -1.086718  \n",
       "H18_19086_TB_ACAGCCGTCATCTGTT-1 -1.192200 -0.406269 -0.193599 -1.000435  \n",
       "...                                   ...       ...       ...       ...  \n",
       "H18_19892_TB_CAGCAGCGTAACGCGA-1 -0.107640 -0.214234 -0.102089  0.336059  \n",
       "H18_19892_TB_GGTGCGTGTTTGTTTC-1 -0.118084 -0.235021 -0.111994  0.161071  \n",
       "H18_19892_TB_TACCTATCACAGGCCT-1 -0.182117  2.252446 -0.172724 -0.090670  \n",
       "H18_19892_TB_TAGAGCTGTTAGATGA-1 -0.108834 -0.216612  4.225257 -0.856378  \n",
       "H18_19892_TB_TCAACGACAGGTCCAC-1 -0.139191 -0.277029 -0.132013 -1.095268  \n",
       "\n",
       "[498 rows x 141 columns]"
      ]
     },
     "execution_count": 192,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tmpp = sc.read_h5ad(\"LR2TF_test_run/anndata_object.h5ad\")\n",
    "reg = pd.read_csv(\"LR2TF_test_run/filterd_regulon.csv\")\n",
    "\n",
    "dc.run_ulm(mat=tmpp, net=reg, source='source', target='target', weight='weight', verbose=True, use_raw=False)\n",
    "\n",
    "estimates =tmpp.obsm['ulm_estimate']\n",
    "tmpp.obsm[\"ulm_estimate\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "vs1: PMF,MF2, vs2: control\n",
      "compared tfs done\n",
      "tf_activities done\n",
      "CTR input condition done\n",
      "CTR input cluster done\n",
      "intranet input condition done\n",
      "intranet input cluster done\n",
      "tf_activities done\n",
      "CTR input condition done\n",
      "CTR input cluster done\n",
      "intranet input condition done\n",
      "intranet input cluster done\n"
     ]
    }
   ],
   "source": [
    "result = IntraTalker_analysis(anndataobject= \"LR2TF_test_run/anndata_object.h5ad\", \n",
    "                              tf_activities= \"decoupler_results_test.csv\",\n",
    "                              arguments_list= {\"out_path\" : \"script_test\", \n",
    "                                                \"celltype\" : \"new_annotation\",\n",
    "                                                \"condition\" : \"protocol\", \n",
    "                                                \"organism\" : \"human\", \n",
    "                                                \"comparison_list\" : [\"PMF,MF2\", \"control\"], #[\"control\", \"PMF,MF2\"]], \n",
    "                                                \"meanchange\" : \"0.5\",\n",
    "                                                \"pval\" : None, \n",
    "                                                \"num_cell_filter\": None,\n",
    "                                                \"reg\" : \"LR2TF_test_run/filterd_regulon.csv\",                                                                                              \n",
    "                                                \"plot\" : True,\n",
    "                                                \"decoupler_matrix_format\" : \"Python\"})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7351 features of mat are empty, they will be removed.\n",
      "Running ulm on mat with 35435 samples and 20647 targets for 160 sources.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4/4 [00:03<00:00,  1.13it/s]\n"
     ]
    }
   ],
   "source": [
    "tmpp = sc.read_h5ad(\"Il1rn_KO_Maus_Data/Myeloid_Stromal_LSK_integrated_harmony.h5ad\")\n",
    "reg = pd.read_csv(\"Il1rn_KO_Maus_Data/decoupler_mousereg_AB.csv\")\n",
    "\n",
    "dc.run_ulm(mat=tmpp, net=reg, source='source', target='target', weight='weight', verbose=True, use_raw=False)\n",
    "\n",
    "estimates = tmpp.obsm['ulm_estimate']\n",
    "estimates.to_csv(\"Il1rn_KO_Maus_Data/decoupler_results_mouse.csv\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "vs1: KO, vs2: WT\n",
      "compared tfs done\n",
      "tf_activities done\n",
      "CTR input condition done\n",
      "CTR input cluster done\n",
      "intranet input condition done\n",
      "intranet input cluster done\n",
      "tf_activities done\n",
      "CTR input condition done\n",
      "CTR input cluster done\n",
      "intranet input condition done\n",
      "intranet input cluster done\n"
     ]
    }
   ],
   "source": [
    "mouse_result = IntraTalker_analysis(anndataobject= \"Il1rn_KO_Maus_Data/Myeloid_Stromal_LSK_integrated_harmony.h5ad\", \n",
    "                                    tf_activities= \"Il1rn_KO_Maus_Data/decoupler_results_mouse.csv\",   \n",
    "                                    arguments_list= {\"out_path\": \"Il1rn_KO_Maus_Data/test\",\n",
    "                                                    \"reg\" : \"Il1rn_KO_Maus_Data/decoupler_mousereg_AB.csv\",\n",
    "                                                    \"organism\" : \"mouse\",\n",
    "                                                    \"celltype\" : \"cluster_names\",\n",
    "                                                    \"condition\" : \"Condition\",\n",
    "                                                    \"comparison_list\": [\"KO\", \"WT\"],\n",
    "                                                    \"meanchange\" : 0.4,\n",
    "                                                    \"pval\" : 0.01,\n",
    "                                                    \"num_cell_filter\" : None,\n",
    "                                                    \"plot\" : True,\n",
    "                                                    \"decoupler_matrix_format\" : \"Python\"})\n",
    "                            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>source</th>\n",
       "      <th>target</th>\n",
       "      <th>gene_A</th>\n",
       "      <th>gene_B</th>\n",
       "      <th>type_gene_A</th>\n",
       "      <th>type_gene_B</th>\n",
       "      <th>MeanLR</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Megakaryocyte</td>\n",
       "      <td>Megakaryocyte</td>\n",
       "      <td>ATF3</td>\n",
       "      <td>ANXA1</td>\n",
       "      <td>Transcription Factor</td>\n",
       "      <td>Ligand</td>\n",
       "      <td>0.190079</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Megakaryocyte</td>\n",
       "      <td>Megakaryocyte</td>\n",
       "      <td>ATF3</td>\n",
       "      <td>ANXA2</td>\n",
       "      <td>Transcription Factor</td>\n",
       "      <td>Ligand</td>\n",
       "      <td>0.190079</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Megakaryocyte</td>\n",
       "      <td>Megakaryocyte</td>\n",
       "      <td>ATF3</td>\n",
       "      <td>CCL5</td>\n",
       "      <td>Transcription Factor</td>\n",
       "      <td>Ligand</td>\n",
       "      <td>0.190079</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Megakaryocyte</td>\n",
       "      <td>Megakaryocyte</td>\n",
       "      <td>ATF3</td>\n",
       "      <td>CIRBP</td>\n",
       "      <td>Transcription Factor</td>\n",
       "      <td>Ligand</td>\n",
       "      <td>0.190079</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Megakaryocyte</td>\n",
       "      <td>Megakaryocyte</td>\n",
       "      <td>ATF3</td>\n",
       "      <td>SORL1</td>\n",
       "      <td>Transcription Factor</td>\n",
       "      <td>Ligand</td>\n",
       "      <td>0.190079</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5280</th>\n",
       "      <td>Neural</td>\n",
       "      <td>Neural</td>\n",
       "      <td>INSR</td>\n",
       "      <td>ZNF24</td>\n",
       "      <td>Receptor</td>\n",
       "      <td>Transcription Factor</td>\n",
       "      <td>0.532363</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5281</th>\n",
       "      <td>Neural</td>\n",
       "      <td>Neural</td>\n",
       "      <td>NGFR</td>\n",
       "      <td>ZNF274</td>\n",
       "      <td>Receptor</td>\n",
       "      <td>Transcription Factor</td>\n",
       "      <td>1.279600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5282</th>\n",
       "      <td>Neural</td>\n",
       "      <td>Neural</td>\n",
       "      <td>ZNF318</td>\n",
       "      <td>LGALS1</td>\n",
       "      <td>Transcription Factor</td>\n",
       "      <td>Ligand</td>\n",
       "      <td>0.713510</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5283</th>\n",
       "      <td>Neural</td>\n",
       "      <td>Neural</td>\n",
       "      <td>ZNF589</td>\n",
       "      <td>ANP32B</td>\n",
       "      <td>Transcription Factor</td>\n",
       "      <td>Ligand</td>\n",
       "      <td>0.506688</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5284</th>\n",
       "      <td>Neural</td>\n",
       "      <td>Neural</td>\n",
       "      <td>ZNF644</td>\n",
       "      <td>ANP32B</td>\n",
       "      <td>Transcription Factor</td>\n",
       "      <td>Ligand</td>\n",
       "      <td>0.774643</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5285 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             source         target  gene_A  gene_B           type_gene_A  \\\n",
       "0     Megakaryocyte  Megakaryocyte    ATF3   ANXA1  Transcription Factor   \n",
       "1     Megakaryocyte  Megakaryocyte    ATF3   ANXA2  Transcription Factor   \n",
       "2     Megakaryocyte  Megakaryocyte    ATF3    CCL5  Transcription Factor   \n",
       "3     Megakaryocyte  Megakaryocyte    ATF3   CIRBP  Transcription Factor   \n",
       "4     Megakaryocyte  Megakaryocyte    ATF3   SORL1  Transcription Factor   \n",
       "...             ...            ...     ...     ...                   ...   \n",
       "5280         Neural         Neural    INSR   ZNF24              Receptor   \n",
       "5281         Neural         Neural    NGFR  ZNF274              Receptor   \n",
       "5282         Neural         Neural  ZNF318  LGALS1  Transcription Factor   \n",
       "5283         Neural         Neural  ZNF589  ANP32B  Transcription Factor   \n",
       "5284         Neural         Neural  ZNF644  ANP32B  Transcription Factor   \n",
       "\n",
       "               type_gene_B    MeanLR  \n",
       "0                   Ligand  0.190079  \n",
       "1                   Ligand  0.190079  \n",
       "2                   Ligand  0.190079  \n",
       "3                   Ligand  0.190079  \n",
       "4                   Ligand  0.190079  \n",
       "...                    ...       ...  \n",
       "5280  Transcription Factor  0.532363  \n",
       "5281  Transcription Factor  1.279600  \n",
       "5282                Ligand  0.713510  \n",
       "5283                Ligand  0.506688  \n",
       "5284                Ligand  0.774643  \n",
       "\n",
       "[5285 rows x 7 columns]"
      ]
     },
     "execution_count": 194,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#inputt = pd.read_csv(\"new_test//TF_results//control//significant_condition_tf_results_control.csv\")\n",
    "inputt = pd.read_csv(\"new_test/TF_results/PMF_MF2/significant_condition_tf_results_PMF_MF2.csv\")\n",
    "inputt = inputt.iloc[:,1:5]\n",
    "inputt.rename(columns={\"z_score\" : \"t_value\"}, inplace=True)\n",
    "#inputt = inputt.set_index(\"tf\")\n",
    "#print(inputt)\n",
    "\n",
    "reguloninput = pd.read_csv(\"filterd_regulon.csv\")\n",
    "reguloninput.rename(columns={\"source\" : \"tf\"}, inplace=True)\n",
    "\n",
    "generate_CrossTalkeR_input(inputt, result.average_gene_expression[\"control\"], \"R_CTR_input_w_py_code\", regulon = reguloninput, organism = \"human\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'control': new_annotation  Neural       MSC  Fibroblast  Megakaryocyte   Myeloid\n",
       " FO538757.2         0.0  1.838987    0.000000       0.000000  0.000000\n",
       " RP11-206L10.9      0.0  0.000000    0.386757       0.000000  0.000000\n",
       " SAMD11             0.0  0.000000    0.000000       0.000000  0.000000\n",
       " NOC2L              0.0  0.197924    2.134077       0.780153  0.561325\n",
       " HES4               0.0  0.545435    0.000000       1.190760  0.000000\n",
       " ...                ...       ...         ...            ...       ...\n",
       " SMYD5              0.0  0.000000    0.000000       0.000000  0.000000\n",
       " CCDC85C            0.0  0.000000    0.000000       0.000000  0.000000\n",
       " CPNE2              0.0  0.000000    0.000000       0.000000  0.000000\n",
       " TMEM206            0.0  0.000000    0.000000       0.000000  0.000000\n",
       " CCDC9              0.0  0.000000    0.000000       0.000000  0.000000\n",
       " \n",
       " [11426 rows x 5 columns],\n",
       " 'PMF,MF2': new_annotation    Neural       MSC  Fibroblast  Megakaryocyte   Myeloid\n",
       " FO538757.2      0.642955  2.677013    0.937268       2.670278  1.214477\n",
       " RP11-206L10.9   0.000000  0.134618    0.000000       0.000000  0.000000\n",
       " SAMD11          0.000000  0.000000    0.000000       0.000000  0.000000\n",
       " NOC2L           0.000000  0.331859    0.000000       0.000000  0.000000\n",
       " HES4            0.000000  2.463197    0.000000       0.062941  0.000000\n",
       " ...                  ...       ...         ...            ...       ...\n",
       " SMYD5           0.000000  0.000000    0.000000       0.000000  0.000000\n",
       " CCDC85C         0.000000  0.000000    0.000000       0.000000  0.000000\n",
       " CPNE2           0.000000  0.000000    0.000000       0.000000  0.000000\n",
       " TMEM206         0.000000  0.000000    0.000000       0.000000  0.000000\n",
       " CCDC9           0.000000  0.000000    0.000000       0.000000  0.000000\n",
       " \n",
       " [11426 rows x 5 columns]}"
      ]
     },
     "execution_count": 195,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result.CTR_input_condition[\"control\"].to_csv(\"py_ctr_input_wo_ctr_exp_tables.csv\", index = False)\n",
    "result.average_gene_expression\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "metadata": {},
   "outputs": [],
   "source": [
    "result.intracellular_network_condition[\"control\"].to_csv(\"py_intra_network_ctrl.csv\")\n",
    "result.intracellular_network_condition[\"PMF,MF2\"].to_csv(\"py_intra_network_PMF.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "metadata": {},
   "outputs": [],
   "source": [
    "result.intracellular_network_cluster[\"control\"].to_csv(\"py_intra_network_ctrl_cluster.csv\")\n",
    "result.intracellular_network_cluster[\"PMF,MF2\"].to_csv(\"py_intra_network_PMF_cluster.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_node_type(df):\n",
    "    \n",
    "    df['gene_A'] = np.where(df['type_gene_A'] == 'Ligand', df['gene_A'] + '|L', df['gene_A'])\n",
    "    df['gene_A'] = np.where(df['type_gene_A'] == 'Receptor', df['gene_A'] + '|R', df['gene_A'])\n",
    "    df['gene_A'] = np.where(df['type_gene_A'] == 'Transcription Factor', df['gene_A'] + '|TF', df['gene_A'])\n",
    "    df['gene_B'] = np.where(df['type_gene_B'] == 'Ligand', df['gene_B'] + '|L', df['gene_B'])\n",
    "    df['gene_B'] = np.where(df['type_gene_B'] == 'Receptor', df['gene_B'] + '|R', df['gene_B'])\n",
    "    df['gene_B'] = np.where(df['type_gene_B'] == 'Transcription Factor', df['gene_B'] + '|TF', df['gene_B'])\n",
    "    return df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "metadata": {},
   "outputs": [],
   "source": [
    "def combine_LR_and_TF(tf_table, LR_prediction, out_path, condition, add_nodetype = False):\n",
    "\n",
    "  if isinstance(LR_prediction, pd.DataFrame):\n",
    "    lr_table = LR_prediction\n",
    "  else: \n",
    "    lr_table = pd.read_csv(LR_prediction, index_col=0)\n",
    "  \n",
    "\n",
    "  intra_connections = pd.DataFrame()\n",
    "  for celltype in np.unique([lr_table[\"source\"], lr_table[\"target\"]]):\n",
    "    lr_filtered_ligands = lr_table[lr_table[\"source\"] == celltype]\n",
    "    lr_filtered_receptors = lr_table[lr_table[\"target\"] == celltype]\n",
    "    lr_ligands = np.unique(lr_filtered_ligands[\"gene_A\"])\n",
    "    lr_receptors = np.unique(lr_filtered_receptors[\"gene_B\"])\n",
    "    #print(condition, celltype, lr_receptors)\n",
    "\n",
    "    tf_table_receptors = tf_table[(tf_table[\"target\"] == celltype) & (tf_table[\"type_gene_A\"] == \"Receptor\")]\n",
    "    tf_table_ligands = tf_table[(tf_table[\"source\"] == celltype) & (tf_table[\"type_gene_B\"] == \"Ligand\")]\n",
    "\n",
    "    tf_receptor_interactions =  tf_table_receptors[tf_table_receptors[\"gene_A\"].isin(lr_receptors)]\n",
    "    tf_ligand_interactions = tf_table_ligands[tf_table_ligands[\"gene_B\"].isin(lr_ligands)]\n",
    "\n",
    "\n",
    "    intra_connections = pd.concat([intra_connections, tf_receptor_interactions, tf_ligand_interactions])\n",
    "  intra_connections[\"all_pair\"] = (intra_connections[\"source\"] + \"/\" \n",
    "                                    + intra_connections[\"gene_A\"] + \"/\"\n",
    "                                    + intra_connections[\"target\"] + \"/\"\n",
    "                                    + intra_connections[\"gene_B\"])\n",
    "    \n",
    "  intra_connections = intra_connections.drop_duplicates(subset=[\"all_pair\"])\n",
    "  intra_connections.drop(columns=[\"all_pair\"], inplace=True)\n",
    "\n",
    "  complete_interactions = pd.concat([intra_connections, lr_table])\n",
    "\n",
    "  if add_nodetype:\n",
    "    complete_interactions = add_node_type(complete_interactions)\n",
    "      \n",
    "  complete_interactions.to_csv((out_path + \"CrossTalkeR_input_\" + condition + \".csv\"), index=0)\n",
    "  return(complete_interactions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "metadata": {},
   "outputs": [],
   "source": [
    "def combine_LR_and_TF_unfiltered(tf_table, LR_prediction, out_path, condition, add_nodetype = False):\n",
    "\n",
    "  if isinstance(LR_prediction, pd.DataFrame):\n",
    "    lr_table = LR_prediction\n",
    "  else: \n",
    "    lr_table = pd.read_csv(LR_prediction, index_col=0)\n",
    "  \n",
    "\n",
    "\n",
    "  complete_interactions = pd.concat([tf_table, lr_table])\n",
    "\n",
    "  if add_nodetype:\n",
    "    complete_interactions = add_node_type(complete_interactions)\n",
    "      \n",
    "  complete_interactions.to_csv((out_path + \"CrossTalkeR_input_\" + condition + \"_unfiltered.csv\"), index=0)\n",
    "  return(complete_interactions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def combine_LR_and_TF_complexes(tf_table, LR_prediction, out_path, condition, add_nodetype = False):\n",
    "\n",
    "  if isinstance(LR_prediction, pd.DataFrame):\n",
    "    lr_table = LR_prediction\n",
    "  else: \n",
    "    lr_table = pd.read_csv(LR_prediction, index_col=False)\n",
    "  \n",
    "  intra_connections = pd.DataFrame()\n",
    "  for celltype in np.unique([lr_table[\"source\"], lr_table[\"target\"]]):\n",
    "    lr_filtered_ligands = lr_table[lr_table[\"source\"] == celltype]\n",
    "    lr_filtered_receptors = lr_table[lr_table[\"target\"] == celltype]\n",
    "    lr_ligands = np.unique(lr_filtered_ligands[\"gene_A\"])\n",
    "    lr_receptors = np.unique(lr_filtered_receptors[\"gene_B\"])\n",
    "    #print(lr_filtered_receptors)\n",
    "\n",
    "    lr_receptors = pd.Series(lr_receptors)\n",
    "    contains_complex = lr_receptors.str.contains(\"_\", na=False)\n",
    "    \n",
    "    R_with_complex = lr_receptors[contains_complex]\n",
    "    #print(\"R_with_complex\", R_with_complex)\n",
    "    R_without_complex = lr_receptors[(~contains_complex)]\n",
    "  \n",
    "    tf_table_receptors = tf_table[(tf_table[\"target\"] == celltype) & (tf_table[\"type_gene_A\"] == \"Receptor\")]\n",
    "    tf_receptor_interactions =  tf_table_receptors[tf_table_receptors[\"gene_A\"].isin(R_without_complex)]\n",
    "\n",
    "    c_receptors = tf_table_receptors[tf_table_receptors[\"gene_A\"].apply(lambda x: any(gene in x.split(\"+\") for gene in lr_receptors))]\n",
    "\n",
    "    complex_df = pd.DataFrame()\n",
    "    if len(R_with_complex) > 0:\n",
    "      for complex in R_with_complex:\n",
    "        receptors = complex.split(\"_\")\n",
    "        R_TF_with_complex = tf_table_receptors[tf_table_receptors[\"gene_A\"].isin(receptors)]\n",
    " \n",
    "        if len(R_TF_with_complex) == 0:\n",
    "          continue\n",
    "        \n",
    "        R_TF_with_complex.drop_duplicates()\n",
    "        R_TF_with_complex.loc[:,\"gene_A\"] = complex\n",
    "        complex_df = pd.concat([complex_df, R_TF_with_complex])\n",
    "\n",
    "      #complex_df.drop_duplicates()\n",
    "\n",
    "    tf_receptor_interactions = pd.concat([tf_receptor_interactions, complex_df])\n",
    "    #print(\"tf_receptor_interactions\", tf_receptor_interactions)\n",
    "    \n",
    "    tf_table_ligands = tf_table[(tf_table[\"source\"] == celltype) & (tf_table[\"type_gene_B\"] == \"Ligand\")]\n",
    "\n",
    "    \n",
    "    tf_ligand_interactions = tf_table_ligands[tf_table_ligands[\"gene_B\"].isin(lr_ligands)]\n",
    "\n",
    "    intra_connections = pd.concat([intra_connections, tf_receptor_interactions, c_receptors, tf_ligand_interactions])\n",
    "  \n",
    "  intra_connections[\"all_pair\"] = (intra_connections[\"source\"] + \"/\" \n",
    "                                    + intra_connections[\"gene_A\"] + \"/\"\n",
    "                                    + intra_connections[\"target\"] + \"/\"\n",
    "                                    + intra_connections[\"gene_B\"])\n",
    "  #print(\"intra_connections\", intra_connections)\n",
    "  intra_connections = intra_connections.drop_duplicates(subset=[\"all_pair\"])\n",
    "  intra_connections.drop(columns=[\"all_pair\"], inplace=True)\n",
    "\n",
    "  complete_interactions = pd.concat([intra_connections, lr_table])\n",
    "  \n",
    "  if add_nodetype:\n",
    "    complete_interactions = add_node_type(complete_interactions)\n",
    "      \n",
    "  complete_interactions.to_csv((out_path + \"CrossTalkeR_input_\" + condition + \".csv\"), index=False) #quoting= csv.QUOTE_NONNUMERIC)\n",
    "  return(complete_interactions)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "metadata": {},
   "outputs": [],
   "source": [
    "#WINDOWS\n",
    "table_ctr = pd.read_csv(\"LR2TF_test_run\\\\CTR_LR.csv\" )\n",
    "table_exp = pd.read_csv(\"LR2TF_test_run\\\\EXP_LR.csv\")\n",
    "table_ctr.drop('Unnamed: 0', axis=1, inplace=True)\n",
    "table_exp.drop('Unnamed: 0', axis=1, inplace=True)\n",
    "\n",
    "\n",
    "ctr_input = combine_LR_and_TF_complexes(result.CTR_input_condition[\"control\"], table_ctr, \"script_test/\", \"control\")\n",
    "exp_input = combine_LR_and_TF_complexes(result.CTR_input_condition[\"PMF,MF2\"], table_exp, \"script_test/\", \"PMF_MF2\")\n",
    "\n",
    "\n",
    "ctr_input_cluster = combine_LR_and_TF_complexes(result.CTR_input_cluster[\"control\"], table_ctr, \"script_test/\", \"control_cluster\")\n",
    "exp_input_cluster = combine_LR_and_TF_complexes(result.CTR_input_cluster[\"PMF,MF2\"], table_exp, \"script_test/\", \"PMF_MF2_cluster\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "#LINUX\n",
    "table_ctr = pd.read_csv(\"/home/larissa/Documents/LR2TF_HiWi/LR2TF_test_run/CTR_LR.csv\", index_col=False)\n",
    "table_exp = pd.read_csv(\"/home/larissa/Documents/LR2TF_HiWi/LR2TF_test_run/EXP_LR.csv\", index_col= False)\n",
    "table_ctr.drop('Unnamed: 0', axis=1, inplace=True)\n",
    "table_exp.drop('Unnamed: 0', axis=1, inplace=True)\n",
    "\n",
    "ctr_input = combine_LR_and_TF_complexes(result.CTR_input_condition[\"control\"], table_ctr, \"script_test/\", \"control\")\n",
    "exp_input = combine_LR_and_TF_complexes(result.CTR_input_condition[\"PMF,MF2\"], table_exp, \"script_test/\", \"PMF_MF2\")\n",
    "\n",
    "ctr_input_cluster = combine_LR_and_TF_complexes(result.CTR_input_cluster[\"control\"], table_ctr, \"script_test/\", \"control_cluster\")\n",
    "exp_input_cluster = combine_LR_and_TF_complexes(result.CTR_input_cluster[\"PMF,MF2\"], table_exp, \"script_test/\", \"PMF_MF2_cluster\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "#LINUX MOUSE\n",
    "table_ctr = pd.read_csv(\"Il1rn_KO_Maus_Data/WT_lr_ready.csv\", index_col=False)\n",
    "table_exp = pd.read_csv(\"Il1rn_KO_Maus_Data/KO_lr_ready.csv\", index_col= False)\n",
    "table_ctr.drop('Unnamed: 0', axis=1, inplace=True)\n",
    "table_exp.drop('Unnamed: 0', axis=1, inplace=True)\n",
    "\n",
    "ctr_input = combine_LR_and_TF_complexes(mouse_result.CTR_input_condition[\"WT\"], table_ctr, \"Il1rn_KO_Maus_Data/test/\", \"WT\")\n",
    "exp_input = combine_LR_and_TF_complexes(mouse_result.CTR_input_condition[\"KO\"], table_exp, \"Il1rn_KO_Maus_Data/test/\", \"KO\")\n",
    "\n",
    "ctr_input_cluster = combine_LR_and_TF_complexes(mouse_result.CTR_input_cluster[\"WT\"], table_ctr, \"Il1rn_KO_Maus_Data/test/\", \"WT_cluster\")\n",
    "exp_input_cluster = combine_LR_and_TF_complexes(mouse_result.CTR_input_cluster[\"KO\"], table_exp, \"Il1rn_KO_Maus_Data/test/\", \"KO_cluster\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "testpy",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
