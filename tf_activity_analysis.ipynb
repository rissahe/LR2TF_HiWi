{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import anndata as ad\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import scanpy as sc\n",
    "import decoupler as dc\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def validate_input_arguments (arguments_list):\n",
    "    if arguments_list[\"out_path\"] is None:\n",
    "        print(\"Please provide an output path\")\n",
    "    elif arguments_list[\"out_path\"][-1] != \"/\":\n",
    "        arguments_list[\"out_path\"] = arguments_list[\"out_path\"] + \"/\"\n",
    "\n",
    "    if arguments_list[\"celltype\"] is None:\n",
    "        print(\"Please provide the name of the metadata field containing cell type annotations\")\n",
    "\n",
    "    if arguments_list[\"condition\"] is None:\n",
    "        print(\"Please provide the name of the metadata field containing condition annotations\")\n",
    "\n",
    "    if arguments_list[\"organism\"] is None:\n",
    "        arguments_list[\"organism\"] = \"human\"\n",
    "\n",
    "    if arguments_list[\"comparison_list\"] is None:\n",
    "        arguments_list[\"comparison_list\"] = np.nan\n",
    "\n",
    "    if arguments_list[\"logfc\"] is None:\n",
    "        arguments_list[\"logfc\"] = 0.0\n",
    "\n",
    "    if arguments_list [\"pval\"] is None:\n",
    "        arguments_list[\"pval\"] = 0.05\n",
    "\n",
    "    if arguments_list[\"reg\"] is None:\n",
    "        arguments_list[\"reg\"] = load_dorothea_regulon(arguments_list[\"organism\"])\n",
    "\n",
    "    elif isinstance(arguments_list[\"reg\"], str):\n",
    "        arguments_list[\"reg\"] = pd.read_csv(arguments_list[\"reg\"], index_col=0)\n",
    "        arguments_list[\"reg\"] = pd.DataFrame.rename(arguments_list[\"reg\"], columns={\"source\" : \"tf\"})\n",
    "\n",
    "    if not \"tf\" in arguments_list[\"reg\"] and \"target\" in arguments_list[\"reg\"] and \"weight\"in arguments_list[\"reg\"]:\n",
    "        raise Exception(\"Not all necessary columns found in regulon table! Please make sure that the regulon has the columns source, target and weight!\")\n",
    "    \n",
    " \n",
    "   \n",
    "    return(arguments_list)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def AverageExpression(sub_object, celltype = None, name_iterable = None, outpath = None):\n",
    "    gene_ids = sub_object.var.index.values\n",
    "    #cluster line even necessary if not returned?\n",
    "    #clusters = anndataobject.obs[celltype].cat.categories\n",
    "    obs = sub_object[:,gene_ids].X.toarray()\n",
    "    obs = np.expm1(obs)\n",
    "    avg_df = pd.DataFrame(obs,columns=gene_ids,index= sub_object.obs[celltype])\n",
    "    avg_df = avg_df.groupby(level=0, observed=False).mean()\n",
    "    avg_df.T.to_csv(outpath + name_iterable + \"_average_gene_expression_by_cluster_exp.csv\")\n",
    "\n",
    "    return avg_df.T\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gene_ids = sub_object.var.index.values\n",
    "    #cluster line even necessary if not returned?\n",
    "    #clusters = anndataobject.obs[celltype].cat.categories\n",
    "obs = sub_object[:,gene_ids].X.toarray()\n",
    "obs = np.expm1(obs)\n",
    "sub_object = pd.DataFrame(obs,columns=gene_ids,index= sub_object.obs[\"new_annotation\"])\n",
    "sub_object = sub_object.groupby(level=0, observed=False).mean()\n",
    "#sub_object.T.to_csv(outpath + name + \"average_gene_expression_by_cluster_exp.csv\")\n",
    "\n",
    "sub_object.T\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#not per cluster but cluster and pval etc need to be added to csv (check against specific marker csv from lr2tf test run in R)\n",
    "\n",
    "def get_significant_tfs_single(tf_activities_sub, celltype, condition, out_path, pval, logfc, name):\n",
    "    \n",
    "    #does not work if condition is None\n",
    "    single_result_path = out_path + condition \n",
    "    if not os.path.isdir(single_result_path):\n",
    "        os.mkdir(single_result_path)\n",
    "    \n",
    "    #tf_activities_scaled = sc.pp.scale(tf_activities_sub, copy=True, max_value=10)\n",
    "    #or sc.pp.normalize_total(anndataobject)\n",
    "    #sc.pp.log1p(tf_activities) \n",
    "    # \"warning: seems to be already log transformed\"\n",
    "\n",
    "    number_of_clusters = len(tf_activities_sub.obs[\"new_annotation\"].cat.categories) \n",
    "    \n",
    "    #//TODO: \n",
    "\n",
    "    sc.tl.rank_genes_groups(tf_activities_sub, groupby= \"new_annotation\", reference=\"rest\", method=\"wilcoxon\", key_added=\"wilcoxon_markers\", corr_method= \"bonferroni\")\n",
    "    #sc.tl.filter_rank_genes_groups(anndataobject, min_in_group_fraction=0, key=\"wilcoxon_markers\", key_added= \"wilcoxon_markers_filtered\")\n",
    "    \n",
    "\n",
    "    sc.tl.rank_genes_groups(tf_activities_sub, groupby= \"new_annotation\", reference=\"rest\", method=\"t-test_overestim_var\", key_added=\"t_test_overestim_var_markers\")\n",
    "    #sc.tl.filter_rank_genes_groups(anndataobject, min_in_group_fraction=0, key=\"t_test_overestim_var_markers\", key_added=\"t_test_overestim_filtered\")\n",
    "\n",
    "    #FindAllMarkers(seuratobject, only.pos = TRUE, min.pct = 0, logfc.threshold = 0, verbose = FALSE)\n",
    "\n",
    "    result1 = tf_activities_sub.uns['wilcoxon_markers']\n",
    "    groups = result1['names'].dtype.names\n",
    "    anndataobject_markers = pd.DataFrame(\n",
    "    {group + '_' + key[:1]: result1[key][group]\n",
    "    for group in groups for key in ['names','logfoldchanges','pvals','pvals_adj']})\n",
    "\n",
    "    result2 = tf_activities_sub.uns['t_test_overestim_var_markers']\n",
    "    groups = result2['names'].dtype.names\n",
    "    anndataobject_markers = pd.DataFrame(\n",
    "    {group + '_' + key[:1]: result2[key][group]\n",
    "    for group in groups for key in ['names','logfoldchanges','pvals','pvals_adj']})\n",
    "\n",
    "    anndataobject_markers_wilcoxon = sc.get.rank_genes_groups_df(tf_activities_sub, group = None, log2fc_min=0, key=\"wilcoxon_markers\")\n",
    "    anndataobject_markers_wilcoxon.to_csv(single_result_path + \"/\" + name + \"_specific_markers_wilcoxon_test.csv\",index=0)\n",
    "\n",
    "    anndataobject_markers_t_over = sc.get.rank_genes_groups_df(tf_activities_sub, group = None, log2fc_min=0, key=\"t_test_overestim_var_markers\")\n",
    "    anndataobject_markers_t_over.to_csv(single_result_path + \"/\" + name + \"_specific_markers_t_test_overestim_test.csv\",index=0)\n",
    "\n",
    "    \n",
    "\n",
    "    res = list()\n",
    "\n",
    "    return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "anndataobject = ad.read_h5ad(\"LR2TF_test_run/anndata_object.h5ad\")\n",
    "\n",
    "\n",
    "tf_activities = ad.read_csv(\"decoupler_results.csv\")\n",
    "anndataobject.obsm['ulm_estimate'] = tf_activities\n",
    "print(anndataobject.obsm[\"ulm_estimate\"].X)\n",
    "for name in anndataobject.obs.protocol.unique():\n",
    "##    subobject = anndataobject[anndataobject.obs.protocol == name]\n",
    "#print(type(subobject)) \n",
    "#print(type(anndataobject))  \n",
    "#print(subobject.X)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf_activities = ad.read_csv(\"decoupler_results.csv\")\n",
    "tf_activities.obsm = anndataobject.obsm\n",
    "tf_activities.uns = anndataobject.uns\n",
    "tf_activities.obs = anndataobject.obs\n",
    "tf_activities = tf_activities[tf_activities.obs.protocol == \"control\"]\n",
    "tf_activities.obs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "anndataobject = ad.read_h5ad(\"LR2TF_test_run/anndata_object.h5ad\")\n",
    "      #  anndataobject.rename_categories(\"protocol\", [\"PMFMF2\", \"control\"])\n",
    "\n",
    "tf_activities = ad.read_csv(\"decoupler_results.csv\")\n",
    "tf_activities.obsm = anndataobject.obsm\n",
    "tf_activities.uns = anndataobject.uns\n",
    "tf_activities.obs = anndataobject.obs\n",
    "\n",
    "tf_activities_sub = tf_activities[anndataobject.obs.protocol == \"PMF,MF2\"]\n",
    "print(tf_activities_sub)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#ignore extra tfs from decoupler while writing script \n",
    "\n",
    "def tf_activity_analysis (anndataobject, arguments_list = None):\n",
    "    \n",
    "    if (isinstance(anndataobject, str)):\n",
    "        anndataobject = ad.read_h5ad(anndataobject)\n",
    "\n",
    "    arguments_list = validate_input_arguments(arguments_list)\n",
    "\n",
    "    if not os.path.isdir(arguments_list[\"out_path\"]):\n",
    "        os.mkdir(arguments_list[\"out_path\"])\n",
    "        tf_path = arguments_list[\"out_path\"] + \"TF_results/\"\n",
    "        os.mkdir(tf_path)\n",
    "    else:\n",
    "        tf_path = arguments_list[\"out_path\"] + \"TF_results/\"\n",
    "\n",
    "    #rename the arguments inserted into argument list (eg protocol to condition)\n",
    "    condition = anndataobject.obs[arguments_list[\"condition\"]]\n",
    "\n",
    "    #checks for tf activity csv, if nothing there, runs decoupler\n",
    "    if isinstance(arguments_list[\"tf_activities\"], str):\n",
    "         tf_activities = ad.read_csv(arguments_list[\"tf_activities\"])\n",
    "         tf_activities.obsm = anndataobject.obsm\n",
    "         tf_activities.uns = anndataobject.uns\n",
    "         tf_activities.obs = anndataobject.obs\n",
    "    elif arguments_list[\"tf_activities\"] is None:\n",
    "         dc.run_ulm(mat = anndataobject, net = \"reg\", source ='source', target ='target', weight ='weight', verbose = True, use_raw = False)\n",
    "         tf_activities = anndataobject.obsm['ulm_estimate']\n",
    "         tf_activities.to_csv(\"decoupler_results.csv\")\n",
    "\n",
    "\n",
    "    #sets the stage for decision if single condition or comparison analysis is done\n",
    "\n",
    "    if not np.isnan(arguments_list[\"comparison_list\"]):\n",
    "        if len(arguments_list[\"comparison_list\"]) > 0 & len(anndataobject.obs[\"comparison_list\"]) < 2:\n",
    "            arguments_list[\"comparison_list\"] <- np.nan\n",
    "            print(\"Only one condition was found in the data, although a list of comparisons was provided. The analyses are performed only for the present condition!\")\n",
    "\n",
    "    #code for single condition  analysis\n",
    "\n",
    "    if np.isnan(arguments_list[\"comparison_list\"]):\n",
    "        result_list = []\n",
    "        gene_expression_list = []\n",
    "        CTR_cluster_list = []\n",
    "        intranet_cluster_list = []\n",
    "\n",
    "        #creates loop until after tf activity score\n",
    "        \n",
    "        for name_iterable in anndataobject.obs.protocol.unique():\n",
    "            sub_object = anndataobject[anndataobject.obs.protocol == name_iterable]\n",
    "            tf_activities_sub = tf_activities[tf_activities.obs.protocol == name_iterable]\n",
    "\n",
    "            #name <- str_replace_all(name, \"[,;.:-]\", \"_\")\n",
    "            sub_object_avg = AverageExpression(sub_object, name_iterable= name_iterable, celltype = arguments_list[\"celltype\"], outpath= arguments_list[\"out_path\"])\n",
    "            #check if its fine to only have the average expression as a dataframe and not as part of an anndata object\n",
    "\n",
    "            #check how sub object is returned by average expression (subobject.T) or rename return?\n",
    "            tf_activity_scores = get_significant_tfs_single(tf_activities_sub, celltype = arguments_list[\"celltype\"],condition = name_iterable, out_path= tf_path, pval = arguments_list[\"pval\"], logfc = arguments_list[\"logfc\"], name = name_iterable)\n",
    "            \n",
    "            #result_list[\"name\"] = tf_activity_scores\n",
    "            #gene_expression_list[name + \"_average_expression\"] = sub_object.layers[\"cell_type\"]\n",
    "            #if (arguments_list[\"organism\"] == \"human\"):\n",
    "            #CTR_cluster_list[\"name\"] = generate_CrossTalkeR_input(tf_activity_scores[\n",
    "            # intranet_cluster_list[[name]] \n",
    "        #return(sub_object) #return tf when finished"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result = tf_activity_analysis(anndataobject= \"LR2TF_test_run/anndata_object.h5ad\", arguments_list= {\"out_path\" : \"script_test\", \"celltype\" : \"new_annotation\", \"condition\" : \"protocol\", \"organism\" : None, \"comparison_list\" : None, \"logfc\" : None, \"pval\" : None, \"reg\" : \"filterd_regulon.csv\", \"tf_activities\" : \"decoupler_results.csv\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "testpy",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
