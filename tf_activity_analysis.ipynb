{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "import anndata as ad\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import scanpy as sc\n",
    "import decoupler as dc\n",
    "import os\n",
    "import re\n",
    "#import pyreadr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def validate_input_arguments (arguments_list):\n",
    "    if arguments_list[\"out_path\"] is None:\n",
    "        print(\"Please provide an output path\")\n",
    "    elif arguments_list[\"out_path\"][-1] != \"/\":\n",
    "        arguments_list[\"out_path\"] = arguments_list[\"out_path\"] + \"/\"\n",
    "\n",
    "    if arguments_list[\"celltype\"] is None:\n",
    "        print(\"Please provide the name of the metadata field containing cell type annotations\")\n",
    "\n",
    "    if arguments_list[\"condition\"] is None:\n",
    "        print(\"Please provide the name of the metadata field containing condition annotations\")\n",
    "\n",
    "    if arguments_list[\"organism\"] is None:\n",
    "        arguments_list[\"organism\"] = \"human\"\n",
    "\n",
    "    if arguments_list[\"comparison_list\"] is None:\n",
    "        arguments_list[\"comparison_list\"] = np.nan\n",
    "\n",
    "    if arguments_list[\"logfc\"] is None:\n",
    "        arguments_list[\"logfc\"] = 0.0\n",
    "\n",
    "    if arguments_list [\"pval\"] is None:\n",
    "        arguments_list[\"pval\"] = 0.05\n",
    "\n",
    "    if arguments_list[\"reg\"] is None:\n",
    "        arguments_list[\"reg\"] = load_dorothea_regulon(arguments_list[\"organism\"])\n",
    "\n",
    "    elif isinstance(arguments_list[\"reg\"], str):\n",
    "        arguments_list[\"reg\"] = pd.read_csv(arguments_list[\"reg\"], index_col=0)\n",
    "        arguments_list[\"reg\"] = pd.DataFrame.rename(arguments_list[\"reg\"], columns={\"source\" : \"tf\"})\n",
    "\n",
    "    if not \"tf\" in arguments_list[\"reg\"] and \"target\" in arguments_list[\"reg\"] and \"weight\"in arguments_list[\"reg\"]:\n",
    "        raise Exception(\"Not all necessary columns found in regulon table! Please make sure that the regulon has the columns source, target and weight!\")\n",
    "    \n",
    " \n",
    "   \n",
    "    return(arguments_list)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def AverageExpression(sub_object, celltype = None, name_iterable = None, outpath = None):\n",
    "    gene_ids = sub_object.var.index.values\n",
    "    #cluster line even necessary if not returned?\n",
    "    #clusters = anndataobject.obs[celltype].cat.categories\n",
    "    obs = sub_object[:,gene_ids].X.toarray()\n",
    "    obs = np.expm1(obs)\n",
    "    avg_df = pd.DataFrame(obs,columns=gene_ids,index= sub_object.obs[celltype])\n",
    "    avg_df = avg_df.groupby(level=0, observed=False).mean()\n",
    "    avg_df.T.to_csv(outpath + name_iterable + \"_average_gene_expression_by_cluster_exp.csv\")\n",
    "\n",
    "    return avg_df.T\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def eval_pval(p_val):\n",
    "    p_val = float(p_val)\n",
    "    if p_val < 0.001: \n",
    "      txt = \"***\"\n",
    "    elif p_val < 0.01: \n",
    "      txt = \"**\"\n",
    "    elif p_val < 0.05: \n",
    "      txt = \"*\"\n",
    "    else:\n",
    "      txt = \"ns\"\n",
    "    return(txt)\n",
    "\n",
    "\n",
    "def eval_log_fc_tag(log_fc):\n",
    "    if log_fc >= 1.0: \n",
    "      txt = \"***\"\n",
    "    elif log_fc > 0.5: \n",
    "      txt = \"**\"\n",
    "    elif log_fc > 0.0: \n",
    "      txt = \"*\"\n",
    "    else:\n",
    "      txt = \"ns\"\n",
    "    return(txt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_unfiltered_tf_scores(tf_scores_df, condition, celltype, out_path):   \n",
    "    summarized_tf_scores_df = tf_scores_df.groupby(celltype, observed = False).mean().T\n",
    "    summarized_tf_scores_df.to_csv(out_path + '/unfiltered_tf_scores_' + condition + '.csv')\n",
    "    return summarized_tf_scores_df\n",
    "\n",
    "#def save_variable_tf_score(filtered_summarized_tf_scores_df, condition, single_result_path):\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "#def map_z_value_filtered(filtered_summarized_tf_scores_df, anndataobject_markers):\n",
    " #   z_score = []\n",
    " #   for gene in anndataobject_markers[\"gene\"]:\n",
    " #       if gene in filtered_summarized_tf_scores_df.index:\n",
    " #           z_score.append(filtered_summarized_tf_scores_df.loc[gene, anndataobject_markers[\"cluster\"]])\n",
    " #   return z_score\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "def map_z_value_filtered(filtered_summarized_tf_scores_df, anndataobject_markers):\n",
    "    z_scores = []  # Initialize an empty list to store the z-scores\n",
    "\n",
    "    # Iterate over each row in anndataobject_markers\n",
    "    for idx, row in anndataobject_markers.iterrows():\n",
    "        gene = row[\"gene\"]  # Get the gene name\n",
    "        cluster = row[\"cluster\"]  # Get the corresponding cluster\n",
    "\n",
    "        # Check if the gene exists in the filtered dataframe\n",
    "        if gene in filtered_summarized_tf_scores_df.index:\n",
    "            # Check if the cluster exists as a column in filtered_summarized_tf_scores_df\n",
    "            if cluster in filtered_summarized_tf_scores_df.columns:\n",
    "                # Append the z-score for the gene and cluster\n",
    "                z_scores.append(filtered_summarized_tf_scores_df.loc[gene, cluster])\n",
    "            else:\n",
    "                # If the cluster is not found, append a placeholder value (e.g., None or np.nan)\n",
    "                z_scores.append(None)\n",
    "        else:\n",
    "            # If the gene is not found, append a placeholder value (e.g., None or np.nan)\n",
    "            z_scores.append(None)\n",
    "\n",
    "    # Return the full list of z-scores\n",
    "    return z_scores\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "#not per cluster but cluster and pval etc need to be added to csv (check against specific marker csv from lr2tf test run in R)\n",
    "\n",
    "def get_significant_tfs_single(tf_activities_sub, celltype, condition, out_path, pval, logfc, name):\n",
    "    \n",
    "    #does not work if condition is None\n",
    "    renamed_condition = condition.replace(\",\", \"_\")\n",
    "    name = name.replace(\",\", \"_\")\n",
    "\n",
    "    single_result_path = out_path + renamed_condition \n",
    "    if not os.path.isdir(single_result_path):\n",
    "        os.mkdir(single_result_path)\n",
    "    \n",
    "    \n",
    "    #tf_activities_scaled = sc.pp.scale(tf_activities_sub, copy=True, max_value=10)\n",
    "    #or sc.pp.normalize_total(anndataobject)\n",
    "    #sc.pp.log1p(tf_activities) \n",
    "    # \"warning: seems to be already log transformed\"\n",
    "\n",
    "    number_of_clusters = len(tf_activities_sub.obs[\"new_annotation\"].cat.categories) \n",
    "    \n",
    "    \n",
    "\n",
    "    sc.tl.rank_genes_groups(tf_activities_sub, groupby= \"new_annotation\", reference=\"rest\", method=\"wilcoxon\", key_added=\"wilcoxon_markers\", corr_method= \"bonferroni\")\n",
    "    #sc.tl.filter_rank_genes_groups(anndataobject, min_in_group_fraction=0, key=\"wilcoxon_markers\", key_added= \"wilcoxon_markers_filtered\")\n",
    "    \n",
    "\n",
    "    sc.tl.rank_genes_groups(tf_activities_sub, groupby= \"new_annotation\", reference=\"rest\", method=\"t-test_overestim_var\", key_added=\"t_test_overestim_var_markers\", corr_method= \"bonferroni\" )\n",
    "    #sc.tl.filter_rank_genes_groups(anndataobject, min_in_group_fraction=0, key=\"t_test_overestim_var_markers\", key_added=\"t_test_overestim_filtered\")\n",
    "\n",
    "    #FindAllMarkers(seuratobject, only.pos = TRUE, min.pct = 0, logfc.threshold = 0, verbose = FALSE)\n",
    "\n",
    "    result1 = tf_activities_sub.uns['wilcoxon_markers']\n",
    "    groups = result1['names'].dtype.names\n",
    "    anndataobject_markers = pd.DataFrame(\n",
    "    {group + '_' + key[:1]: result1[key][group]\n",
    "    for group in groups for key in ['names','logfoldchanges','pvals','pvals_adj']})\n",
    "\n",
    "    result2 = tf_activities_sub.uns['t_test_overestim_var_markers']\n",
    "    groups = result2['names'].dtype.names\n",
    "    anndataobject_markers = pd.DataFrame(\n",
    "    {group + '_' + key[:1]: result2[key][group]\n",
    "    for group in groups for key in ['names','logfoldchanges','pvals','pvals_adj']})\n",
    "\n",
    "    anndataobject_markers_wilcoxon = sc.get.rank_genes_groups_df(tf_activities_sub, group = None, log2fc_min=0, key=\"wilcoxon_markers\")\n",
    "    \n",
    "    anndataobject_markers_wilcoxon.rename(columns={\"names\":\"gene\", \"group\": \"cluster\"}, inplace=True)\n",
    "    \n",
    "    #documentation says this won't update the main dataframe but will only overwrite a copy in future pandas versions (after v3)\n",
    "    anndataobject_markers_wilcoxon[\"tag\"] = None\n",
    "    anndataobject_markers_wilcoxon[\"log_fc_tag\"] = None\n",
    "    for i in range(len(anndataobject_markers_wilcoxon[\"pvals_adj\"])):\n",
    "         anndataobject_markers_wilcoxon[\"tag\"].iloc[i,] = eval_pval(anndataobject_markers_wilcoxon[\"pvals_adj\"].iloc[i,])\n",
    "         anndataobject_markers_wilcoxon[\"log_fc_tag\"].iloc[i,] = eval_log_fc_tag(anndataobject_markers_wilcoxon[\"logfoldchanges\"].iloc[i,])\n",
    "     \n",
    "\n",
    "    anndataobject_markers_wilcoxon.to_csv(single_result_path + \"/\" + name + \"_specific_markers_wilcoxon_test.csv\",index=0)\n",
    "\n",
    "    anndataobject_markers_t_over = sc.get.rank_genes_groups_df(tf_activities_sub, group = None, log2fc_min=0, key=\"t_test_overestim_var_markers\")\n",
    " \n",
    "    anndataobject_markers_t_over.rename(columns={\"names\":\"gene\", \"group\": \"cluster\"}, inplace=True)\n",
    "\n",
    "    anndataobject_markers_t_over[\"tag\"] = None\n",
    "    anndataobject_markers_t_over[\"log_fc_tag\"] = None\n",
    "    for i in range(len(anndataobject_markers_t_over[\"pvals_adj\"])):\n",
    "         anndataobject_markers_t_over[\"tag\"].iloc[i,] = eval_pval(anndataobject_markers_t_over[\"pvals_adj\"].iloc[i,])\n",
    "         anndataobject_markers_t_over[\"log_fc_tag\"].iloc[i,] = eval_pval(anndataobject_markers_t_over[\"logfoldchanges\"].iloc[i,])\n",
    "\n",
    "    anndataobject_markers_t_over.to_csv(single_result_path + \"/\" + name + \"_specific_markers_t_test_overestim_test.csv\",index=0)\n",
    "\n",
    "   #tag mapping wilcoxon\n",
    "    tag_mapping_wilcox = anndataobject_markers_wilcoxon[[\"gene\", \"tag\", \"log_fc_tag\", \"cluster\", \"pvals_adj\", \"logfoldchanges\"]]\n",
    "\n",
    "    tag_mapping_wilcox = tag_mapping_wilcox[(tag_mapping_wilcox[\"pvals_adj\"] < float(pval)) & \n",
    "                              ((tag_mapping_wilcox[\"logfoldchanges\"] > float(logfc)) | \n",
    "                              (tag_mapping_wilcox[\"logfoldchanges\"] < -float(logfc)))]\n",
    "\n",
    "     # Pivot the DataFrame to create a wide format similar to `dcast` in R\n",
    "    tag_mapping_wilcox = tag_mapping_wilcox.pivot(index=\"gene\", columns=\"cluster\", values=\"tag\")\n",
    "    tag_mapping_wilcox.fillna(\"ns\", inplace=True)\n",
    "\n",
    "     # Assuming `log_fc_tag` is no longer needed as in the R code (removing it has no effect after the pivot)\n",
    "    tf_activities_sub.obs_names = tf_activities_sub.obs[celltype]\n",
    "    tf_scores_df = tf_activities_sub.to_df()\n",
    "    unfiltered_tf_scores = create_unfiltered_tf_scores(tf_scores_df, condition, celltype, single_result_path)\n",
    "\n",
    "    #Filter to only include tfs that match the tag_mapping/are markers\n",
    "    col_num = tf_scores_df.columns.isin(tag_mapping_wilcox.index)  \n",
    "    filtered_tf_scores_df = tf_scores_df.loc[:, col_num] \n",
    "    \n",
    "    filtered_summarized_tf_scores_df = filtered_tf_scores_df.groupby(celltype, observed = False).mean().T\n",
    "    filtered_summarized_tf_scores_df.to_csv(f'{single_result_path}/tf_scores_{condition}.csv')\n",
    "    print(filtered_summarized_tf_scores_df.index)\n",
    "    #tf_scores_variable_table = save_variable_tf_scores(filtered_summarized_tf_scores_df, condition, single_result_path)\n",
    "\n",
    "    #filtered_summarized_tf_scores_df.rownames = re.sub((\".,\"), \"_\", filtered_summarized_tf_scores_df.rownames)\n",
    "\n",
    "    \n",
    "    anndataobject_markers_wilcoxon[\"z_score\"] = map_z_value_filtered(filtered_summarized_tf_scores_df, anndataobject_markers_wilcoxon)\n",
    "    #anndataobject_markers_t_over[\"z_score\"] = map_z_value_filtered(filtered_summarized_tf_scores_df, anndataobject_markers_t_over)\n",
    "    \n",
    "    #res needs to contain gene, pval tag, cluster and z score\n",
    "    #drop doubles??\n",
    "    res_wilcoxon = anndataobject_markers_wilcoxon[[\"gene\",\"tag\", \"cluster\", \"z_score\"]]\n",
    "    #res_t_test = anndataobject_markers_t_over[[\"gene\",\"tag\", \"cluster\", \"z_score\"]]\n",
    "\n",
    "    \n",
    "\n",
    "     #//TODO: \n",
    "    #delete one variant and put test type as a variable\n",
    "\n",
    "    return res_wilcoxon #, res_t_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#check if it's okay to not pre set the column type as string or float (maybe no problem in python but was problem in r)\n",
    "\n",
    "def create_empty_CTR_dataframe():\n",
    "  \n",
    "  empty_df = pd.DataFrame(\n",
    "    columns=[\n",
    "    \"source\",\n",
    "    \"target\",\n",
    "    \"gene_A\",\n",
    "    \"gene_B\",\n",
    "    \"type_gene_A\",\n",
    "    \"type_gene_B\",\n",
    "    \"MeanLR\"\n",
    "    ])\n",
    "  \n",
    "  return(empty_df)\n",
    "\n",
    "\n",
    "def add_entry_to_CTR_dataframe(source, target, gene_A, gene_B, type_gene_A, type_gene_B, MeanLR):\n",
    "  df = pd.DataFrame(\n",
    "      source,\n",
    "      target,\n",
    "      gene_A,\n",
    "      gene_B,\n",
    "      type_gene_A,\n",
    "      type_gene_B,\n",
    "      MeanLR)\n",
    "\n",
    "  return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#def generate_CrossTalkeR_input(tf_activities, gene_expression, regulon = None):\n",
    "\n",
    "tf_activities =  pd.read_csv(\"tf_activities_test_wilcox.csv\")  \n",
    "#tf_activities[\"cluster\"] = \"Neural\"\n",
    "gene_expression = pd.read_csv(\"script_test/control_average_gene_expression_by_cluster_exp.csv\", index_col = 0)\n",
    "print(gene_expression)\n",
    "regulon = pd.read_csv(\"filterd_regulon.csv\", index_col = 0)  \n",
    "regulon = regulon.rename(columns={\"source\" : \"tf\"})\n",
    "\n",
    "\n",
    "\n",
    "ligands_readin = pyreadr.read_r(\"ligands_human.rda\")\n",
    "ligands = ligands_readin[\"ligands_human\"]\n",
    "\n",
    "rtf_readin = pyreadr.read_r(\"RTF_DB_2.rda\") \n",
    "rtf_db = rtf_readin[\"RTF_DB_2\"]\n",
    "\n",
    "#put tf as index column/rownames and receptors as column 1\n",
    "\n",
    "R2TF = rtf_db.set_index(\"tf\")\n",
    "\n",
    "sorted_regulon = regulon[[\"tf\", \"target\"]]\n",
    "sorted_regulon.rename(columns={\"target\" : \"targets\"})\n",
    "sorted_regulon = sorted_regulon.set_index(\"tf\")\n",
    "\n",
    "output_df = create_empty_CTR_dataframe()\n",
    "\n",
    "for row in range(len((tf_activities))):\n",
    "\n",
    "  #r_tf = create_empty_CTR_dataframe()\n",
    "  #tf_l = create_empty_CTR_dataframe()\n",
    "\n",
    "  #if (tf_activities[\"z_score\"].iloc[row] == 0):\n",
    "  tf_var = str(tf_activities[\"gene\"].iloc[row])\n",
    "  if tf_var in sorted_regulon.index:\n",
    "    targets = sorted_regulon.loc[tf_var]\n",
    "  if tf_var in R2TF.index:\n",
    "    receptors = R2TF.loc[tf_var]\n",
    "  tf_ligands = np.intersect1d(targets, ligands)\n",
    "  \n",
    "\n",
    "      expressed = False\n",
    "    if ligand in gene_expression.index:\n",
    "      ex_value = gene_expression.loc[ligand, \"Neural\"]\n",
    "      if (ex_value != 0):\n",
    "        expressed = True\n",
    "        \n",
    "    #print(tf_activities.iloc[row[]])\n",
    "    if (expressed == True):\n",
    "      df_list_l = list[tf_activities.iloc[row, 2],\n",
    "                                             tf_activities.iloc[row, 2],\n",
    "                                             tf_activities.iloc[row, 0],\n",
    "                                             ligand,\n",
    "                                             \"Transcription Factor\",\n",
    "                                             \"Ligand\",\n",
    "                                             tf_activities.iloc[row, 3]]\n",
    "      \n",
    "    if (len(receptors) > 0):\n",
    "       for receptor in receptors:\n",
    "         df_list_r = list[tf_activities.iloc[row, 2],\n",
    "                                         tf_activities.iloc[row, 2],\n",
    "                                         receptor,\n",
    "                                         tf_activities.iloc[row, 0],\n",
    "                                         'Receptor',\n",
    "                                         'Transcription Factor',\n",
    "                                         tf_activities.iloc[row, 3]]\n",
    "   \n",
    "tf_l = pd.DataFrame(df_list_l, columns=[\"source\", \"target\", \"gene_A\", \"gene_B\", \"type_gene_A\", \"type_gene_B\", \"MeanLR\"])\n",
    "print(tf_l)\n",
    "r_tf = pd.DataFrame(df_list_r)\n",
    "      \n",
    "  #    r_tf[\"gene_A\"] <- gsub(\"_\", \"+\", r_tf$gene_A, fixed = TRUE)\n",
    "   #   r_tf[\"gene_B\"] <- gsub(\"_\", \"+\", r_tf$gene_B, fixed = TRUE)\n",
    "   #   tf_l[\"gene_A\"] <- gsub(\"_\", \"+\", tf_l$gene_A, fixed = TRUE)\n",
    "   #   tf_l[\"gene_B\"] <- gsub(\"_\", \"+\", tf_l$gene_B, fixed = TRUE)\n",
    "\n",
    "   #   output_df = pd.concat(output_df, r_tf)\n",
    "   #   output_df = pd.concat(output_df, tf_l)\n",
    "\n",
    "  #return output_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#ignore extra tfs from decoupler while writing script \n",
    "\n",
    "def tf_activity_analysis (anndataobject, arguments_list = None):\n",
    "    \n",
    "    if (isinstance(anndataobject, str)):\n",
    "        anndataobject = ad.read_h5ad(anndataobject)\n",
    "\n",
    "    arguments_list = validate_input_arguments(arguments_list)\n",
    "\n",
    "    if not os.path.isdir(arguments_list[\"out_path\"]):\n",
    "        os.mkdir(arguments_list[\"out_path\"])\n",
    "        tf_path = arguments_list[\"out_path\"] + \"TF_results/\"\n",
    "        os.mkdir(tf_path)\n",
    "    else:\n",
    "        tf_path = arguments_list[\"out_path\"] + \"TF_results/\"\n",
    "\n",
    "    #rename the arguments inserted into argument list (eg protocol to condition)\n",
    "    condition = anndataobject.obs[arguments_list[\"condition\"]]\n",
    "\n",
    "    #checks for tf activity csv, if nothing there, runs decoupler\n",
    "    if isinstance(arguments_list[\"tf_activities\"], str):\n",
    "         tf_activities = ad.read_csv(arguments_list[\"tf_activities\"])\n",
    "         tf_activities.obsm = anndataobject.obsm\n",
    "         tf_activities.uns = anndataobject.uns\n",
    "         tf_activities.obs = anndataobject.obs\n",
    "    elif arguments_list[\"tf_activities\"] is None:\n",
    "         dc.run_ulm(mat = anndataobject, net = \"reg\", source ='source', target ='target', weight ='weight', verbose = True, use_raw = False)\n",
    "         tf_activities = anndataobject.obsm['ulm_estimate']\n",
    "         tf_activities.to_csv(\"decoupler_results.csv\")\n",
    "\n",
    "\n",
    "    #sets the stage for decision if single condition or comparison analysis is done\n",
    "\n",
    "    if not np.isnan(arguments_list[\"comparison_list\"]):\n",
    "        if len(arguments_list[\"comparison_list\"]) > 0 & len(anndataobject.obs[\"comparison_list\"]) < 2:\n",
    "            arguments_list[\"comparison_list\"] <- np.nan\n",
    "            print(\"Only one condition was found in the data, although a list of comparisons was provided. The analyses are performed only for the present condition!\")\n",
    "\n",
    "    #code for single condition  analysis\n",
    "\n",
    "    if np.isnan(arguments_list[\"comparison_list\"]):\n",
    "        result_list = []\n",
    "        gene_expression_list = []\n",
    "        CTR_cluster_list = []\n",
    "        intranet_cluster_list = []\n",
    "\n",
    "        #creates loop until after tf activity score\n",
    "        \n",
    "        for name_iterable in anndataobject.obs.protocol.unique():\n",
    "            sub_object = anndataobject[anndataobject.obs.protocol == name_iterable]\n",
    "            tf_activities_sub = tf_activities[tf_activities.obs.protocol == name_iterable]\n",
    "\n",
    "            sub_object_avg = AverageExpression(sub_object, name_iterable= name_iterable, celltype = arguments_list[\"celltype\"], outpath= arguments_list[\"out_path\"])\n",
    "            #check if its fine to only have the average expression as a dataframe and not as part of an anndata object\n",
    "\n",
    "            #check how sub object is returned by average expression (subobject.T) or rename return?\n",
    "            tf_activity_scores = get_significant_tfs_single(tf_activities_sub, celltype = arguments_list[\"celltype\"],condition = name_iterable, out_path= tf_path, pval = arguments_list[\"pval\"], logfc = arguments_list[\"logfc\"], name = name_iterable)\n",
    "           \n",
    "            tf_activity_scores[0].to_csv(\"tf_activities_test_wilcox.csv\", index = 0)\n",
    "            tf_activity_scores[1].to_csv(\"tf_activities_test_t_test.csv\", index = 0)\n",
    "\n",
    "            #result_list[[name_iterable]] = tf_activity_scores\n",
    "            #gene_expression_list[[name_iterable + \"_average_expression\"]] = sub_object_avg\n",
    "            \n",
    "            #if (arguments_list[\"organism\"] == \"human\"):\n",
    "            #    CTR_cluster_list[name_iterable] = generate_CrossTalkeR_input(tf_activity_scores[[\"cluster\"]],\n",
    "            #                                                                     gene_expression_list[[(name_iterable + \"_average_expression\")]],\n",
    "            #                                                                     arguments_list[\"reg\"])\n",
    "            #else:\n",
    "            #  CTR_cluster_list[[name_iterable]] = generate_CrossTalkeR_input_mouse(tf_activity_scores[[\"cluster\"]],\n",
    "            #                                                                     gene_expression_list[[(name_iterable + \"_average_expression\")]],\n",
    "            #                                                                     arguments_list[\"reg\"])\n",
    "              \n",
    "            #intranet_cluster_list[[name_iterable]] = generate_intracellular_network(tf_activity_scores[[\"cluster\"]],\n",
    "            #                                                          gene_expression_list[[paste0(name, \"_average_expression\")]],\n",
    "            #                                                          arguments_list$reg,\n",
    "            #                                                          arguments_list$organism)\n",
    "        #return(sub_object) #return tf when finished"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\studium\\LR2TF_HiWi\\.venv\\Lib\\site-packages\\scanpy\\tools\\_rank_genes_groups.py:640: ImplicitModificationWarning: Trying to modify attribute `._uns` of view, initializing view as actual.\n",
      "  adata.uns[key_added] = {}\n",
      "d:\\studium\\LR2TF_HiWi\\.venv\\Lib\\site-packages\\scanpy\\tools\\_rank_genes_groups.py:455: RuntimeWarning: invalid value encountered in log2\n",
      "  self.stats[group_name, \"logfoldchanges\"] = np.log2(\n",
      "d:\\studium\\LR2TF_HiWi\\.venv\\Lib\\site-packages\\scanpy\\tools\\_rank_genes_groups.py:455: RuntimeWarning: invalid value encountered in log2\n",
      "  self.stats[group_name, \"logfoldchanges\"] = np.log2(\n",
      "d:\\studium\\LR2TF_HiWi\\.venv\\Lib\\site-packages\\scanpy\\tools\\_rank_genes_groups.py:455: RuntimeWarning: invalid value encountered in log2\n",
      "  self.stats[group_name, \"logfoldchanges\"] = np.log2(\n",
      "d:\\studium\\LR2TF_HiWi\\.venv\\Lib\\site-packages\\scanpy\\tools\\_rank_genes_groups.py:455: RuntimeWarning: invalid value encountered in log2\n",
      "  self.stats[group_name, \"logfoldchanges\"] = np.log2(\n",
      "d:\\studium\\LR2TF_HiWi\\.venv\\Lib\\site-packages\\scanpy\\tools\\_rank_genes_groups.py:455: RuntimeWarning: invalid value encountered in log2\n",
      "  self.stats[group_name, \"logfoldchanges\"] = np.log2(\n",
      "d:\\studium\\LR2TF_HiWi\\.venv\\Lib\\site-packages\\scanpy\\tools\\_rank_genes_groups.py:455: RuntimeWarning: invalid value encountered in log2\n",
      "  self.stats[group_name, \"logfoldchanges\"] = np.log2(\n",
      "d:\\studium\\LR2TF_HiWi\\.venv\\Lib\\site-packages\\scanpy\\tools\\_rank_genes_groups.py:455: RuntimeWarning: invalid value encountered in log2\n",
      "  self.stats[group_name, \"logfoldchanges\"] = np.log2(\n",
      "d:\\studium\\LR2TF_HiWi\\.venv\\Lib\\site-packages\\scanpy\\tools\\_rank_genes_groups.py:455: RuntimeWarning: invalid value encountered in log2\n",
      "  self.stats[group_name, \"logfoldchanges\"] = np.log2(\n",
      "d:\\studium\\LR2TF_HiWi\\.venv\\Lib\\site-packages\\scanpy\\tools\\_rank_genes_groups.py:455: RuntimeWarning: invalid value encountered in log2\n",
      "  self.stats[group_name, \"logfoldchanges\"] = np.log2(\n",
      "d:\\studium\\LR2TF_HiWi\\.venv\\Lib\\site-packages\\scanpy\\tools\\_rank_genes_groups.py:455: RuntimeWarning: invalid value encountered in log2\n",
      "  self.stats[group_name, \"logfoldchanges\"] = np.log2(\n",
      "C:\\Users\\Larissa\\AppData\\Local\\Temp\\ipykernel_21788\\598824359.py:52: FutureWarning: ChainedAssignmentError: behaviour will change in pandas 3.0!\n",
      "You are setting values through chained assignment. Currently this works in certain cases, but when using Copy-on-Write (which will become the default behaviour in pandas 3.0) this will never work to update the original DataFrame or Series, because the intermediate object on which we are setting values will behave as a copy.\n",
      "A typical example is when you are setting values in a column of a DataFrame, like:\n",
      "\n",
      "df[\"col\"][row_indexer] = value\n",
      "\n",
      "Use `df.loc[row_indexer, \"col\"] = values` instead, to perform the assignment in a single step and ensure this keeps updating the original `df`.\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "\n",
      "  anndataobject_markers_wilcoxon[\"tag\"].iloc[i,] = eval_pval(anndataobject_markers_wilcoxon[\"pvals_adj\"].iloc[i,])\n",
      "C:\\Users\\Larissa\\AppData\\Local\\Temp\\ipykernel_21788\\598824359.py:52: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  anndataobject_markers_wilcoxon[\"tag\"].iloc[i,] = eval_pval(anndataobject_markers_wilcoxon[\"pvals_adj\"].iloc[i,])\n",
      "C:\\Users\\Larissa\\AppData\\Local\\Temp\\ipykernel_21788\\598824359.py:53: FutureWarning: ChainedAssignmentError: behaviour will change in pandas 3.0!\n",
      "You are setting values through chained assignment. Currently this works in certain cases, but when using Copy-on-Write (which will become the default behaviour in pandas 3.0) this will never work to update the original DataFrame or Series, because the intermediate object on which we are setting values will behave as a copy.\n",
      "A typical example is when you are setting values in a column of a DataFrame, like:\n",
      "\n",
      "df[\"col\"][row_indexer] = value\n",
      "\n",
      "Use `df.loc[row_indexer, \"col\"] = values` instead, to perform the assignment in a single step and ensure this keeps updating the original `df`.\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "\n",
      "  anndataobject_markers_wilcoxon[\"log_fc_tag\"].iloc[i,] = eval_log_fc_tag(anndataobject_markers_wilcoxon[\"logfoldchanges\"].iloc[i,])\n",
      "C:\\Users\\Larissa\\AppData\\Local\\Temp\\ipykernel_21788\\598824359.py:53: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  anndataobject_markers_wilcoxon[\"log_fc_tag\"].iloc[i,] = eval_log_fc_tag(anndataobject_markers_wilcoxon[\"logfoldchanges\"].iloc[i,])\n",
      "C:\\Users\\Larissa\\AppData\\Local\\Temp\\ipykernel_21788\\598824359.py:65: FutureWarning: ChainedAssignmentError: behaviour will change in pandas 3.0!\n",
      "You are setting values through chained assignment. Currently this works in certain cases, but when using Copy-on-Write (which will become the default behaviour in pandas 3.0) this will never work to update the original DataFrame or Series, because the intermediate object on which we are setting values will behave as a copy.\n",
      "A typical example is when you are setting values in a column of a DataFrame, like:\n",
      "\n",
      "df[\"col\"][row_indexer] = value\n",
      "\n",
      "Use `df.loc[row_indexer, \"col\"] = values` instead, to perform the assignment in a single step and ensure this keeps updating the original `df`.\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "\n",
      "  anndataobject_markers_t_over[\"tag\"].iloc[i,] = eval_pval(anndataobject_markers_t_over[\"pvals_adj\"].iloc[i,])\n",
      "C:\\Users\\Larissa\\AppData\\Local\\Temp\\ipykernel_21788\\598824359.py:65: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  anndataobject_markers_t_over[\"tag\"].iloc[i,] = eval_pval(anndataobject_markers_t_over[\"pvals_adj\"].iloc[i,])\n",
      "C:\\Users\\Larissa\\AppData\\Local\\Temp\\ipykernel_21788\\598824359.py:66: FutureWarning: ChainedAssignmentError: behaviour will change in pandas 3.0!\n",
      "You are setting values through chained assignment. Currently this works in certain cases, but when using Copy-on-Write (which will become the default behaviour in pandas 3.0) this will never work to update the original DataFrame or Series, because the intermediate object on which we are setting values will behave as a copy.\n",
      "A typical example is when you are setting values in a column of a DataFrame, like:\n",
      "\n",
      "df[\"col\"][row_indexer] = value\n",
      "\n",
      "Use `df.loc[row_indexer, \"col\"] = values` instead, to perform the assignment in a single step and ensure this keeps updating the original `df`.\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "\n",
      "  anndataobject_markers_t_over[\"log_fc_tag\"].iloc[i,] = eval_pval(anndataobject_markers_t_over[\"logfoldchanges\"].iloc[i,])\n",
      "C:\\Users\\Larissa\\AppData\\Local\\Temp\\ipykernel_21788\\598824359.py:66: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  anndataobject_markers_t_over[\"log_fc_tag\"].iloc[i,] = eval_pval(anndataobject_markers_t_over[\"logfoldchanges\"].iloc[i,])\n",
      "d:\\studium\\LR2TF_HiWi\\.venv\\Lib\\site-packages\\anndata\\_core\\anndata.py:841: UserWarning: \n",
      "AnnData expects .obs.index to contain strings, but got values like:\n",
      "    ['Megakaryocyte', 'Fibroblast', 'MSC', 'Megakaryocyte', 'Megakaryocyte']\n",
      "\n",
      "    Inferred to be: categorical\n",
      "\n",
      "  names = self._prep_dim_index(names, \"obs\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['AR', 'ARID2', 'ASCL1', 'ATF1', 'ATF2', 'ATF3', 'ATF4', 'BMAL1', 'CBX2',\n",
      "       'CDX1',\n",
      "       ...\n",
      "       'ZNF143', 'ZNF165', 'ZNF207', 'ZNF274', 'ZNF318', 'ZNF382', 'ZNF589',\n",
      "       'ZNF740', 'ZNF750', 'ZNF92'],\n",
      "      dtype='object', length=188)\n"
     ]
    },
    {
     "ename": "KeyError",
     "evalue": "0",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "File \u001b[1;32md:\\studium\\LR2TF_HiWi\\.venv\\Lib\\site-packages\\pandas\\core\\indexes\\base.py:3805\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   3804\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m-> 3805\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_engine\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_loc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcasted_key\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   3806\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m err:\n",
      "File \u001b[1;32mindex.pyx:167\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mindex.pyx:196\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mpandas\\\\_libs\\\\hashtable_class_helper.pxi:7081\u001b[0m, in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mpandas\\\\_libs\\\\hashtable_class_helper.pxi:7089\u001b[0m, in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mKeyError\u001b[0m: 0",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[97], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[43mtf_activity_analysis\u001b[49m\u001b[43m(\u001b[49m\u001b[43manndataobject\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mLR2TF_test_run/anndata_object.h5ad\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43marguments_list\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43m{\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mout_path\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m \u001b[49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mscript_test\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcelltype\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m \u001b[49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mnew_annotation\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcondition\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m \u001b[49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mprotocol\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43morganism\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m \u001b[49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcomparison_list\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m \u001b[49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mlogfc\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m \u001b[49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m0.5\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mpval\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m \u001b[49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mreg\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m \u001b[49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mfilterd_regulon.csv\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mtf_activities\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m \u001b[49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mdecoupler_results.csv\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m}\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[1;32mIn[9], line 59\u001b[0m, in \u001b[0;36mtf_activity_analysis\u001b[1;34m(anndataobject, arguments_list)\u001b[0m\n\u001b[0;32m     54\u001b[0m \u001b[38;5;66;03m#check if its fine to only have the average expression as a dataframe and not as part of an anndata object\u001b[39;00m\n\u001b[0;32m     55\u001b[0m \n\u001b[0;32m     56\u001b[0m \u001b[38;5;66;03m#check how sub object is returned by average expression (subobject.T) or rename return?\u001b[39;00m\n\u001b[0;32m     57\u001b[0m tf_activity_scores \u001b[38;5;241m=\u001b[39m get_significant_tfs_single(tf_activities_sub, celltype \u001b[38;5;241m=\u001b[39m arguments_list[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcelltype\u001b[39m\u001b[38;5;124m\"\u001b[39m],condition \u001b[38;5;241m=\u001b[39m name_iterable, out_path\u001b[38;5;241m=\u001b[39m tf_path, pval \u001b[38;5;241m=\u001b[39m arguments_list[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpval\u001b[39m\u001b[38;5;124m\"\u001b[39m], logfc \u001b[38;5;241m=\u001b[39m arguments_list[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mlogfc\u001b[39m\u001b[38;5;124m\"\u001b[39m], name \u001b[38;5;241m=\u001b[39m name_iterable)\n\u001b[1;32m---> 59\u001b[0m \u001b[43mtf_activity_scores\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[38;5;241m.\u001b[39mto_csv(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtf_activities_test_wilcox.csv\u001b[39m\u001b[38;5;124m\"\u001b[39m, index \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m)\n\u001b[0;32m     60\u001b[0m tf_activity_scores[\u001b[38;5;241m1\u001b[39m]\u001b[38;5;241m.\u001b[39mto_csv(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtf_activities_test_t_test.csv\u001b[39m\u001b[38;5;124m\"\u001b[39m, index \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m)\n",
      "File \u001b[1;32md:\\studium\\LR2TF_HiWi\\.venv\\Lib\\site-packages\\pandas\\core\\frame.py:4102\u001b[0m, in \u001b[0;36mDataFrame.__getitem__\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   4100\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcolumns\u001b[38;5;241m.\u001b[39mnlevels \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[0;32m   4101\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_getitem_multilevel(key)\n\u001b[1;32m-> 4102\u001b[0m indexer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcolumns\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_loc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   4103\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m is_integer(indexer):\n\u001b[0;32m   4104\u001b[0m     indexer \u001b[38;5;241m=\u001b[39m [indexer]\n",
      "File \u001b[1;32md:\\studium\\LR2TF_HiWi\\.venv\\Lib\\site-packages\\pandas\\core\\indexes\\base.py:3812\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   3807\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(casted_key, \u001b[38;5;28mslice\u001b[39m) \u001b[38;5;129;01mor\u001b[39;00m (\n\u001b[0;32m   3808\u001b[0m         \u001b[38;5;28misinstance\u001b[39m(casted_key, abc\u001b[38;5;241m.\u001b[39mIterable)\n\u001b[0;32m   3809\u001b[0m         \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28many\u001b[39m(\u001b[38;5;28misinstance\u001b[39m(x, \u001b[38;5;28mslice\u001b[39m) \u001b[38;5;28;01mfor\u001b[39;00m x \u001b[38;5;129;01min\u001b[39;00m casted_key)\n\u001b[0;32m   3810\u001b[0m     ):\n\u001b[0;32m   3811\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m InvalidIndexError(key)\n\u001b[1;32m-> 3812\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(key) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01merr\u001b[39;00m\n\u001b[0;32m   3813\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m:\n\u001b[0;32m   3814\u001b[0m     \u001b[38;5;66;03m# If we have a listlike key, _check_indexing_error will raise\u001b[39;00m\n\u001b[0;32m   3815\u001b[0m     \u001b[38;5;66;03m#  InvalidIndexError. Otherwise we fall through and re-raise\u001b[39;00m\n\u001b[0;32m   3816\u001b[0m     \u001b[38;5;66;03m#  the TypeError.\u001b[39;00m\n\u001b[0;32m   3817\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_check_indexing_error(key)\n",
      "\u001b[1;31mKeyError\u001b[0m: 0"
     ]
    }
   ],
   "source": [
    "result = tf_activity_analysis(anndataobject= \"LR2TF_test_run/anndata_object.h5ad\", arguments_list= {\"out_path\" : \"script_test\", \"celltype\" : \"new_annotation\", \"condition\" : \"protocol\", \"organism\" : None, \"comparison_list\" : None, \"logfc\" : \"0.5\", \"pval\" : None, \"reg\" : \"filterd_regulon.csv\", \"tf_activities\" : \"decoupler_results.csv\"})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def csv_comparison (result_1, result_2, outpath, suffixes_df=(\"_py\", \"_r\")):\n",
    "    result1 = pd.read_csv(result_1)\n",
    "    result2 = pd.read_csv(result_2)\n",
    "\n",
    "\n",
    "    result1 = result1[result1[\"pvals_adj\"] < 0.05]\n",
    "    if \"p_val_adj\" in result2.columns:\n",
    "        result2 = result2[result2[\"p_val_adj\"] < 0.05]\n",
    "    else:\n",
    "        result2 = result2[result2[\"pvals_adj\"] < 0.05]\n",
    "\n",
    "    result1 = result1.rename(columns={\"names\": \"gene\", \"group\": \"cluster\"})\n",
    "    result2 = result2.rename(columns={\"names\": \"gene\", \"group\": \"cluster\"})\n",
    "\n",
    "\n",
    "    df_output_1 = pd.DataFrame()\n",
    "\n",
    "    for i in range(len(result1)):\n",
    "        a = result1[\"gene\"].iloc[i]\n",
    "        for j in range(len(result2)):\n",
    "            b = result2[\"gene\"].iloc[j]\n",
    "            if a == b:\n",
    "                df_output_1[i] = result1.iloc[i]\n",
    "            \n",
    "\n",
    "    df_output_1 = df_output_1.T\n",
    "\n",
    "    df_output_2 = pd.DataFrame()\n",
    "    for i in range(len(result2)):\n",
    "        a = result2[\"gene\"].iloc[i]\n",
    "        for j in range(len(result1)):\n",
    "            b = result1[\"gene\"].iloc[j]\n",
    "            if a == b:\n",
    "                df_output_2[i] = result2.iloc[i]\n",
    "\n",
    "\n",
    "    df_output_2 = df_output_2.T\n",
    "\n",
    "\n",
    "    df_output = pd.merge(df_output_1, df_output_2, on=\"gene\", suffixes=suffixes_df)\n",
    "\n",
    "    df_output_3 = pd.DataFrame()\n",
    "    for i in range(len(result1)):\n",
    "        a = result1[\"gene\"].iloc[i]\n",
    "        b = list(result2[\"gene\"])\n",
    "        if a not in b:\n",
    "            df_output_3[i] = result1.iloc[i]\n",
    "            \n",
    "    df_output_3 = df_output_3.T\n",
    "    df_output.rename(columns={\"Unnamed: 0\": \"gene_r\"}, inplace=True)\n",
    "    df_output_3.rename(columns={\"cluster\": \"cluster\" + suffixes_df[0]}, inplace=True)\n",
    "    if suffixes_df[0] == \"_py_wilcox\":\n",
    "        df_output_3.rename(columns={\"scores\": \"scores\" + suffixes_df[0], \"logfoldchanges\": \"logfoldchanges\" + suffixes_df[0], \"pvals\": \"pvals\" + suffixes_df[0], \"pvals_adj\": \"pvals_adj\" + suffixes_df[0]}, inplace=True)\n",
    "        df_output_4 = pd.DataFrame()\n",
    "        for i in range(len(result2)):\n",
    "            a = result2[\"gene\"].iloc[i]\n",
    "            b = list(result1[\"gene\"])\n",
    "            if a not in b:\n",
    "                df_output_4[i] = result2.iloc[i]\n",
    "        df_output_4 = df_output_4.T\n",
    "        df_output_4.rename(columns={\"cluster\": \"cluster\" + suffixes_df[1], \"scores\": \"scores\" + suffixes_df[1], \"logfoldchanges\": \"logfoldchanges\" + suffixes_df[1], \"pvals\": \"pvals\" + suffixes_df[1], \"pvals_adj\": \"pvals_adj\" + suffixes_df[1]}, inplace=True)\n",
    "        df_output_3 = pd.concat([df_output_3, df_output_4])\n",
    "        \n",
    "\n",
    "    df_output = pd.concat([df_output, df_output_3])\n",
    "\n",
    "    df_output.to_csv(outpath, index=0)\n",
    "    print(df_output_3.columns)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#WINDOWS VERSION\n",
    "\n",
    "#CONTROL\n",
    "#comparison python wilcoxon and r wilcoxon control\n",
    "csv_comparison(\"script_test\\\\TF_results\\\\control\\\\control_specific_markers_wilcoxon_test.csv\", \"LR2TF_test_run\\\\results\\\\TF_results\\\\control\\\\all_specificmarker__control.csv\",\n",
    "                \"tf_comparison_r_py\\\\py_wilcoxon_r_same_genes_control_filtered.csv\", suffixes_df=(\"_py\", \"_r\"))\n",
    "\n",
    "#comparison python t test and r wilcoxon control\n",
    "csv_comparison(\"script_test\\\\TF_results\\\\control\\\\control_specific_markers_t_test_overestim_test.csv\", \"LR2TF_test_run\\\\results\\\\TF_results\\\\control\\\\all_specificmarker__control.csv\",\n",
    "                \"tf_comparison_r_py\\\\py_t_test_r_same_genes_control_filtered.csv\", suffixes_df=(\"_py\", \"_r\"))\n",
    "\n",
    "# py wilcox vs py t test control\n",
    "\n",
    "csv_comparison(\"script_test\\\\TF_results\\\\control\\\\control_specific_markers_wilcoxon_test.csv\", \"script_test\\\\TF_results\\\\control\\\\control_specific_markers_t_test_overestim_test.csv\",\n",
    "                \"tf_comparison_r_py\\\\py_wilcox_py_t_test_same_genes_control_filtered.csv\", suffixes_df=(\"_py_wilcox\", \"_py_t_test\"))\n",
    "################################################################################################################################################################################################\n",
    "#PMF MF2\n",
    "#python wilcox vs r wilcox PMF MF2\n",
    "csv_comparison(\"script_test\\\\TF_results\\\\PMF_MF2\\\\PMF_MF2_specific_markers_wilcoxon_test.csv\", \"LR2TF_test_run\\\\results\\\\TF_results\\\\PMF_MF2\\\\all_specificmarker__PMF_MF2.csv\",\n",
    "                \"tf_comparison_r_py\\\\py_wilcoxon_r_same_genes_PMF_MF2_filtered.csv\", suffixes_df=(\"_py\", \"_r\"))\n",
    "\n",
    "#comparison python t test and r wilcoxon PMF MF2\n",
    "csv_comparison(\"script_test\\\\TF_results\\\\PMF_MF2\\\\PMF_MF2_specific_markers_t_test_overestim_test.csv\", \"LR2TF_test_run\\\\results\\\\TF_results\\\\PMF_MF2\\\\all_specificmarker__PMF_MF2.csv\",\n",
    "                \"tf_comparison_r_py\\\\py_t_test_r_same_genes_PMF_MF2_filtered.csv\", suffixes_df=(\"_py\", \"_r\"))\n",
    "\n",
    "csv_comparison(\"script_test\\\\TF_results\\\\PMF_MF2\\\\PMF_MF2_specific_markers_wilcoxon_test.csv\", \"script_test\\\\TF_results\\\\PMF_MF2\\\\PMF_MF2_specific_markers_t_test_overestim_test.csv\",\n",
    "                \"tf_comparison_r_py\\\\py_wilcox_py_t_test_same_genes_PMF_MF2_filtered.csv\", suffixes_df=(\"_py_wilcox\", \"_py_t_test\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#LINUX VERSION\n",
    "\n",
    "#CONTROL\n",
    "#comparison python wilcoxon and r wilcoxon control\n",
    "csv_comparison(\"script_test/TF_results/control/control_specific_markers_wilcoxon_test.csv\", \"LR2TF_test_run/results/TF_results/control/all_specificmarker__control.csv\",\n",
    "                \"tf_comparison_r_py//py_wilcoxon_r_same_genes_control_filtered.csv\", suffixes_df=(\"_py\", \"_r\"))\n",
    "\n",
    "#comparison python t test and r wilcoxon control\n",
    "csv_comparison(\"script_test/TF_results/control/control_specific_markers_t_test_overestim_test.csv\", \"LR2TF_test_run/results/TF_results/control/all_specificmarker__control.csv\",\n",
    "                \"tf_comparison_r_py/py_t_test_r_same_genes_control_filtered.csv\", suffixes_df=(\"_py\", \"_r\"))\n",
    "\n",
    "# py wilcox vs py t test control\n",
    "\n",
    "csv_comparison(\"script_test/TF_results/control/control_specific_markers_wilcoxon_test.csv\", \"script_test/TF_results/control/control_specific_markers_t_test_overestim_test.csv\",\n",
    "                \"tf_comparison_r_py/py_wilcox_py_t_test_same_genes_control_filtered.csv\", suffixes_df=(\"_py_wilcox\", \"_py_t_test\"))\n",
    "################################################################################################################################################################################################\n",
    "#PMF MF2\n",
    "#python wilcox vs r wilcox PMF MF2\n",
    "csv_comparison(\"script_test/TF_results/PMF_MF2/PMF_MF2_specific_markers_wilcoxon_test.csv\", \"LR2TF_test_run/results/TF_results/PMF_MF2/all_specificmarker__PMF_MF2.csv\",\n",
    "                \"tf_comparison_r_py/py_wilcoxon_r_same_genes_PMF_MF2_filtered.csv\", suffixes_df=(\"_py\", \"_r\"))\n",
    "\n",
    "#comparison python t test and r wilcoxon PMF MF2\n",
    "csv_comparison(\"script_test/TF_results/PMF_MF2/PMF_MF2_specific_markers_t_test_overestim_test.csv\", \"LR2TF_test_run/results/TF_results/PMF_MF2/all_specificmarker__PMF_MF2.csv\",\n",
    "                \"tf_comparison_r_py/py_t_test_r_same_genes_PMF_MF2_filtered.csv\", suffixes_df=(\"_py\", \"_r\"))\n",
    "\n",
    "csv_comparison(\"script_test/TF_results/PMF_MF2/PMF_MF2_specific_markers_wilcoxon_test.csv\", \"script_test/TF_results/PMF_MF2/PMF_MF2_specific_markers_t_test_overestim_test.csv\",\n",
    "                \"tf_comparison_r_py/py_wilcox_py_t_test_same_genes_PMF_MF2_filtered.csv\", suffixes_df=(\"_py_wilcox\", \"_py_t_test\"))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
