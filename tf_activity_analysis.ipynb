{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {},
   "outputs": [],
   "source": [
    "import anndata as ad\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import scanpy as sc\n",
    "#import decoupler as dc\n",
    "import os\n",
    "import statistics\n",
    "import seaborn as sns\n",
    "from scipy.stats import wilcoxon\n",
    "from scipy.spatial.distance import pdist\n",
    "from scipy.cluster.hierarchy import linkage\n",
    "import matplotlib.pyplot as plt\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {},
   "outputs": [],
   "source": [
    "def validate_input_arguments (arguments_list):\n",
    "    if arguments_list[\"out_path\"] is None:\n",
    "        print(\"Please provide an output path\")\n",
    "    elif arguments_list[\"out_path\"][-1] != \"/\":\n",
    "        arguments_list[\"out_path\"] = arguments_list[\"out_path\"] + \"/\"\n",
    "\n",
    "    if arguments_list[\"celltype\"] is None:\n",
    "        print(\"Please provide the name of the metadata field containing cell type annotations\")\n",
    "\n",
    "    if arguments_list[\"condition\"] is None:\n",
    "        print(\"Please provide the name of the metadata field containing condition annotations\")\n",
    "\n",
    "    if arguments_list[\"organism\"] is None:\n",
    "        arguments_list[\"organism\"] = \"human\"\n",
    "\n",
    "    if arguments_list[\"comparison_list\"] is None:\n",
    "        arguments_list[\"comparison_list\"] = np.nan\n",
    "\n",
    "    if arguments_list[\"logfc\"] is None:\n",
    "        arguments_list[\"logfc\"] = 0.0\n",
    "\n",
    "    if arguments_list [\"pval\"] is None:\n",
    "        arguments_list[\"pval\"] = 0.05\n",
    "\n",
    "    if arguments_list [\"num_cell_filter\"] is None:\n",
    "        arguments_list[\"num_cell_filter\"] = 0\n",
    "\n",
    "    if arguments_list[\"reg\"] is None:\n",
    "        arguments_list[\"reg\"] = load_dorothea_regulon(arguments_list[\"organism\"])\n",
    "\n",
    "    elif isinstance(arguments_list[\"reg\"], str):\n",
    "        arguments_list[\"reg\"] = pd.read_csv(arguments_list[\"reg\"], index_col=0)\n",
    "        arguments_list[\"reg\"] = pd.DataFrame.rename(arguments_list[\"reg\"], columns={\"source\" : \"tf\"})\n",
    "\n",
    "    #is the naming of tf fine like this?\n",
    "    if not \"tf\" in arguments_list[\"reg\"] and \"target\" in arguments_list[\"reg\"] and \"weight\" in arguments_list[\"reg\"]:\n",
    "        raise NameException(\"Not all necessary columns found in regulon table! Please make sure that the regulon has the columns 'source', 'target' and 'weight'!\")\n",
    "    \n",
    "    if arguments_list[\"plot\"] is None:\n",
    "        arguments_list[\"plot\"] = True\n",
    "    elif not isinstance(arguments_list[\"plot\"], (bool)):\n",
    "        raise ValueError(\"lot argument must be a boolean value.\")\n",
    "        \n",
    "   \n",
    "    return(arguments_list)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TFObj:\n",
    "    def __init__(self,\n",
    "    tf_activities_condition : list,\n",
    "    tf_activities_cluster : list,\n",
    "    average_gene_expression : list,\n",
    "    regulon : pd.DataFrame,\n",
    "    CTR_input_condition : list,\n",
    "    CTR_input_cluster : list,\n",
    "    intracellular_network_condition : list,\n",
    "    intracellular_network_cluster : list):\n",
    "\n",
    "        self.tf_activities_condition = tf_activities_condition\n",
    "        self.tf_activities_cluster = tf_activities_cluster\n",
    "        self.average_gene_expression = average_gene_expression\n",
    "        self.regulon = regulon\n",
    "        self.CTR_input_condition = CTR_input_condition\n",
    "        self.CTR_input_cluster = CTR_input_cluster\n",
    "        self.intracellular_network_condition = intracellular_network_condition\n",
    "        self.intracellular_network_cluster = intracellular_network_cluster\n",
    "\n",
    "def make_TFOBj(tf_activities_condition : list,\n",
    "    tf_activities_cluster : list,\n",
    "    average_gene_expression : list,\n",
    "    regulon : pd.DataFrame,\n",
    "    CTR_input_condition : list,\n",
    "    CTR_input_cluster : list,\n",
    "    intracellular_network_condition : list,\n",
    "    intracellular_network_cluster : list):\n",
    "\n",
    "        tf = TFObj(tf_activities_condition,\n",
    "            tf_activities_cluster,\n",
    "            average_gene_expression,\n",
    "            regulon,\n",
    "            CTR_input_condition,\n",
    "            CTR_input_cluster,\n",
    "            intracellular_network_condition,\n",
    "            intracellular_network_cluster)\n",
    "\n",
    "        return tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {},
   "outputs": [],
   "source": [
    "def AverageExpression(sub_object, celltype = None, name_iterable = None, outpath = None):\n",
    "    gene_ids = sub_object.var.index.values\n",
    "    #cluster line even necessary if not returned?\n",
    "    #clusters = anndataobject.obs[celltype].cat.categories\n",
    "    obs = sub_object[:,gene_ids].X.toarray()\n",
    "    obs = np.expm1(obs)\n",
    "    avg_df = pd.DataFrame(obs,columns=gene_ids,index= sub_object.obs[celltype])\n",
    "    avg_df = avg_df.groupby(level=0, observed=False).mean()\n",
    "    #avg_df.T.to_csv(outpath + name_iterable + \"_average_gene_expression_by_cluster_exp.csv\")\n",
    "\n",
    "    return avg_df.T\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {},
   "outputs": [],
   "source": [
    "def eval_pval(p_val):\n",
    "    p_val = float(p_val)\n",
    "    if p_val < 0.001: \n",
    "      txt = \"***\"\n",
    "    elif p_val < 0.01: \n",
    "      txt = \"**\"\n",
    "    elif p_val < 0.05: \n",
    "      txt = \"*\"\n",
    "    else:\n",
    "      txt = \"ns\"\n",
    "    return(txt)\n",
    "\n",
    "\n",
    "def eval_log_fc_tag(log_fc):\n",
    "    if log_fc >= 1.0: \n",
    "      txt = \"***\"\n",
    "    elif log_fc > 0.5: \n",
    "      txt = \"**\"\n",
    "    elif log_fc > 0.0: \n",
    "      txt = \"*\"\n",
    "    else:\n",
    "      txt = \"ns\"\n",
    "    return(txt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_unfiltered_tf_scores(tf_scores_df, condition, celltype, out_path):   \n",
    "    summarized_tf_scores_df = tf_scores_df.groupby(celltype, observed = True).mean().T\n",
    "    #tf_scores_df.groupby(celltype, observed = True).apply(display)\n",
    "    #agg([\"mean\", \"var\"])\n",
    "    summarized_tf_scores_df.to_csv(out_path + \"/unfiltered_tf_scores_\" + condition + \".csv\")\n",
    "    return summarized_tf_scores_df\n",
    "\n",
    "#np.var() returns a value that is different from R's var(), whereas statistics.variance() is the same as R's var()\n",
    "def save_variable_tf_score(filtered_summarized_tf_scores_df, condition, out_path, plot):\n",
    "    filtered_summarized_tf_scores_df[\"var\"] = filtered_summarized_tf_scores_df.apply(statistics.variance, axis=1).unique()\n",
    "    filtered_summarized_tf_scores_df.to_csv(out_path + \"/variable_tf_scores_\" + condition + \".csv\")\n",
    "\n",
    "    if plot:\n",
    "        top_variable_tfs = filtered_summarized_tf_scores_df.sort_values(\"var\", ascending=False).head(n=20).drop(columns=\"var\")\n",
    "        fig, ax = plt.subplots(figsize=(8,7))   \n",
    "        ax = sns.heatmap(top_variable_tfs, cmap=\"vlag\", center=0, vmin=top_variable_tfs.min(axis=None), cbar_kws={\"label\": \"z-score\"})\n",
    "        ax.set(xlabel=\"Cell Type\", ylabel=\"Transcription Factor\")\n",
    "        ax.get_figure()\n",
    "        plt.savefig(out_path + \"/tf_activity_top20_variable_\" + condition + \".pdf\")\n",
    "        plt.close()\n",
    "\n",
    "    filtered_summarized_tf_scores_df_var = filtered_summarized_tf_scores_df\n",
    "    return filtered_summarized_tf_scores_df_var\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_tf_activity(filtered_summarized_tf_scores_df, tag_mapping, condition, out_path):\n",
    "    filtered_summarized_tf_scores_df = filtered_summarized_tf_scores_df.drop(columns=\"var\")\n",
    "    sns.clustermap(filtered_summarized_tf_scores_df, cbar_kws={\"label\": \"z-score\"}, figsize=(8,7), cmap=\"vlag\", center=0, yticklabels=False)\n",
    "    plt.savefig(out_path + \"/tf_activity_compressed_\" + condition + \".pdf\")\n",
    "    plt.close()\n",
    "\n",
    "    sns.clustermap(filtered_summarized_tf_scores_df, cbar_kws={\"label\": \"z-score\"}, figsize=(8,50), cmap=\"vlag\", center=0, annot= tag_mapping, fmt=\"\")\n",
    "    plt.savefig(out_path + \"/tf_activity_\" + condition + \".pdf\")\n",
    "    plt.close()\n",
    "\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {},
   "outputs": [],
   "source": [
    "def h_clust(data):\n",
    "            dist_matrix = pdist(data.T)\n",
    "            linkage_matrix = linkage(dist_matrix, method = \"average\")   \n",
    "            return linkage_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 220,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_condition_tf_activities(tf_activity_tables, out_path):\n",
    "       \n",
    "   for _, df in tf_activity_tables.items():\n",
    "        name_df = pd.DataFrame(df)\n",
    "        significant_res = name_df[name_df[\"tag\"] == \"***\"]\n",
    "        significant_genes = np.unique(significant_res[\"tf\"])\n",
    "        name_df = name_df[name_df['tf'].isin(significant_genes)]\n",
    "        \n",
    "\n",
    "        tag_mapping = name_df[[\"tf\", \"tag\", \"CellType\"]]\n",
    "        print(tag_mapping)\n",
    "        tag_mapping = tag_mapping.pivot(index=\"tf\", columns=\"CellType\", values=\"tag\")\n",
    "    \n",
    "        name_df_r = name_df[[\"r\", \"tf\", \"CellType\"]]\n",
    "        name_df_cluster = name_df_r.pivot_table(index = \"tf\", columns = \"CellType\", values = \"r\", aggfunc = \"mean\")\n",
    "        name_df_cluster.fillna(0, inplace=True) \n",
    "\n",
    "        h_clust_matrix = h_clust(name_df_cluster)\n",
    "\n",
    "        cluster_map = sns.clustermap(name_df_cluster, cbar_kws={\"label\": \"r\"}, figsize=(8,40), cmap=\"vlag\", center=0, annot= tag_mapping,\n",
    "                      col_linkage= h_clust_matrix, fmt=\"\")\n",
    "        cluster_map.figure.tight_layout(h_pad=1, w_pad=0.02, rect=[0, 0, 1, 1])\n",
    "        \n",
    "        plt.savefig(out_path + \"/cluster_condition_activity_difference.pdf\")\n",
    "        plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 221,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_condition_tf_activities_compressed(tf_activity_tables, out_path):\n",
    " \n",
    "  \n",
    "    for _, df in tf_activity_tables.items():\n",
    "        name_df = pd.DataFrame(df)\n",
    "        \n",
    "        significant_res = name_df[name_df[\"tag\"] == \"***\"]\n",
    "        significant_genes = np.unique(significant_res[\"tf\"])\n",
    "        name_df = name_df[name_df['tf'].isin(significant_genes)]\n",
    "        \n",
    "        name_df_r = name_df[[\"r\", \"tf\", \"CellType\"]]\n",
    "        name_df_cluster = name_df_r.pivot_table(index = \"tf\", columns = \"CellType\", values = \"r\", aggfunc = \"mean\")\n",
    "        name_df_cluster.fillna(0, inplace=True) \n",
    "\n",
    "        h_clust_matrix = h_clust(name_df_cluster)\n",
    "        name_df_cluster.reset_index()\n",
    "        sns.clustermap(name_df_cluster, cbar_kws={\"label\": \"r\"}, figsize=(8,10), cmap=\"vlag\", center=0, annot= None,\n",
    "                       yticklabels=False, col_linkage= h_clust_matrix, fmt=\"\")\n",
    "        \n",
    "        plt.savefig(out_path + \"/cluster_condition_activity_difference_compressed.pdf\")\n",
    "        plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "metadata": {},
   "outputs": [],
   "source": [
    "def map_z_value(tf_scores_df, anndataobject_markers):\n",
    "    genes = []\n",
    "    clusters = []\n",
    "    z_scores = []  \n",
    "\n",
    "    anndataobject_markers = anndataobject_markers.set_index(\"gene\")\n",
    "    \n",
    "    for i in range(len(anndataobject_markers.index)):\n",
    "        a = anndataobject_markers.index[i]\n",
    "        for j in range(len(tf_scores_df.index)):\n",
    "            b = tf_scores_df.index[j]\n",
    "            if a == b:\n",
    "                c = anndataobject_markers.columns.get_loc(\"cluster\")\n",
    "                cluster = anndataobject_markers.iloc[i, c]\n",
    "                gene_rows = tf_scores_df.iloc[j]\n",
    "                if isinstance(gene_rows, pd.Series):\n",
    "                    gene_rows = gene_rows.to_frame().T\n",
    "\n",
    "                for _, gene_row in gene_rows.iterrows():\n",
    "                     score = gene_row[cluster]\n",
    "                     genes.append(a)\n",
    "                     clusters.append(cluster)\n",
    "                     z_scores.append(score)\n",
    "\n",
    "    z_score_df = pd.DataFrame({\n",
    "        'gene': genes,\n",
    "        'cluster': clusters,\n",
    "        'z_score': z_scores\n",
    "    })\n",
    "\n",
    "    return z_score_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_significant_tfs_single(tf_activities_sub, celltype, condition, out_path, pval, logfc, name, plot):\n",
    "    \n",
    "    #does not work if condition is None\n",
    "    renamed_condition = condition.replace(\",\", \"_\")\n",
    "    name = name.replace(\",\", \"_\")\n",
    "\n",
    "    single_result_path = out_path + renamed_condition \n",
    "    if not os.path.isdir(single_result_path):\n",
    "        os.mkdir(single_result_path)\n",
    "\n",
    "    tf_activities_scaled = sc.pp.scale(tf_activities_sub, copy= True)\n",
    "\n",
    "    #tf_activities_sub = sc.pp.normalize_total(tf_activities_scaled, copy=True)\n",
    "    #tf_activities_sub = sc.pp.log1p(tf_activities_sub, copy=True) \n",
    "    # \"warning: seems to be already log transformed\"\n",
    "\n",
    "    number_of_clusters = len(tf_activities_sub.obs[\"new_annotation\"].cat.categories) \n",
    "\n",
    "\n",
    "    sc.tl.rank_genes_groups(tf_activities_sub, groupby= \"new_annotation\", reference=\"rest\", method=\"wilcoxon\", key_added=\"wilcoxon_markers\", corr_method= \"bonferroni\")\n",
    "    #sc.tl.filter_rank_genes_groups(anndataobject, min_in_group_fraction=0, key=\"wilcoxon_markers\", key_added= \"wilcoxon_markers_filtered\")\n",
    "    \n",
    "\n",
    "    sc.tl.rank_genes_groups(tf_activities_sub, groupby= \"new_annotation\", reference=\"rest\", method=\"t-test_overestim_var\", key_added=\"t_test_overestim_var_markers\", corr_method= \"bonferroni\" )\n",
    "    #sc.tl.filter_rank_genes_groups(anndataobject, min_in_group_fraction=0, key=\"t_test_overestim_var_markers\", key_added=\"t_test_overestim_filtered\")\n",
    "\n",
    "\n",
    "    result1 = tf_activities_sub.uns['wilcoxon_markers']\n",
    "    groups = result1['names'].dtype.names\n",
    "    anndataobject_markers = pd.DataFrame(\n",
    "    {group + '_' + key[:1]: result1[key][group]\n",
    "    for group in groups for key in ['names','logfoldchanges','pvals','pvals_adj']})\n",
    "\n",
    "    result2 = tf_activities_sub.uns['t_test_overestim_var_markers']\n",
    "    groups = result2['names'].dtype.names\n",
    "    anndataobject_markers = pd.DataFrame(\n",
    "    {group + '_' + key[:1]: result2[key][group]\n",
    "    for group in groups for key in ['names','logfoldchanges','pvals','pvals_adj']})\n",
    "\n",
    "    anndataobject_markers_wilcoxon = sc.get.rank_genes_groups_df(tf_activities_sub, group = None, log2fc_min=0, key=\"wilcoxon_markers\")\n",
    "    \n",
    "    anndataobject_markers_wilcoxon.rename(columns={\"names\":\"gene\", \"group\": \"cluster\"}, inplace=True)\n",
    "    \n",
    "    #documentation says this won't update the main dataframe but will only overwrite a copy in future pandas versions (after v3)\n",
    "    anndataobject_markers_wilcoxon[\"tag\"] = None\n",
    "    anndataobject_markers_wilcoxon[\"log_fc_tag\"] = None\n",
    "    \n",
    "    for i in range(len(anndataobject_markers_wilcoxon[\"pvals_adj\"])):\n",
    "         anndataobject_markers_wilcoxon[\"tag\"].iloc[i,] = eval_pval(anndataobject_markers_wilcoxon[\"pvals_adj\"].iloc[i,])\n",
    "         anndataobject_markers_wilcoxon[\"log_fc_tag\"].iloc[i,] = eval_log_fc_tag(anndataobject_markers_wilcoxon[\"logfoldchanges\"].iloc[i,])\n",
    "     \n",
    "\n",
    "    anndataobject_markers_wilcoxon.to_csv(single_result_path + \"/\" + name + \"_specific_markers_wilcoxon_test.csv\",index=0)\n",
    "\n",
    "    anndataobject_markers_t_over = sc.get.rank_genes_groups_df(tf_activities_sub, group = None, log2fc_min=0, key=\"t_test_overestim_var_markers\")\n",
    " \n",
    "    anndataobject_markers_t_over.rename(columns={\"names\":\"gene\", \"group\": \"cluster\"}, inplace=True)\n",
    "\n",
    "    anndataobject_markers_t_over[\"tag\"] = None\n",
    "    anndataobject_markers_t_over[\"log_fc_tag\"] = None\n",
    "    for i in range(len(anndataobject_markers_t_over[\"pvals_adj\"])):\n",
    "         anndataobject_markers_t_over[\"tag\"].iloc[i,] = eval_pval(anndataobject_markers_t_over[\"pvals_adj\"].iloc[i,])\n",
    "         anndataobject_markers_t_over[\"log_fc_tag\"].iloc[i,] = eval_pval(anndataobject_markers_t_over[\"logfoldchanges\"].iloc[i,])\n",
    "\n",
    "    anndataobject_markers_t_over.to_csv(single_result_path + \"/\" + name + \"_specific_markers_t_test_overestim_test.csv\",index=0)\n",
    "\n",
    "   #tag mapping wilcoxon\n",
    "    tag_mapping_wilcox = anndataobject_markers_wilcoxon[[\"gene\", \"tag\", \"log_fc_tag\", \"cluster\", \"pvals_adj\", \"logfoldchanges\"]]\n",
    "    tag_mapping_wilcox = tag_mapping_wilcox[(tag_mapping_wilcox[\"pvals_adj\"] < float(pval)) & \n",
    "                              ((tag_mapping_wilcox[\"logfoldchanges\"] > float(logfc)) | \n",
    "                              (tag_mapping_wilcox[\"logfoldchanges\"] < -float(logfc)))]\n",
    "\n",
    "    tag_mapping_wilcox = tag_mapping_wilcox.pivot(index=\"gene\", columns=\"cluster\", values=\"tag\")\n",
    "    clusters = anndataobject_markers_wilcoxon[\"cluster\"].unique()\n",
    "\n",
    "    for cluster in clusters:\n",
    "        if cluster not in tag_mapping_wilcox.columns:\n",
    "            tag_mapping_wilcox[cluster] = np.nan\n",
    "\n",
    "    tag_mapping_wilcox.fillna(\"ns\", inplace=True)\n",
    "\n",
    "    tf_activities_scaled.obs_names = tf_activities_scaled.obs[celltype]\n",
    "    tf_scores_df = tf_activities_scaled.to_df()\n",
    "    tf_scores_df.columns.name = None\n",
    "    unfiltered_tf_scores = create_unfiltered_tf_scores(tf_scores_df, condition, celltype, single_result_path)\n",
    "   \n",
    "    #Filter to only include tfs that match the tag_mapping/are markers\n",
    "    col_num = tf_scores_df.columns.isin(tag_mapping_wilcox.index)  \n",
    "    filtered_tf_scores_df = tf_scores_df.loc[:, col_num] \n",
    "    \n",
    "    filtered_summarized_tf_scores_df = filtered_tf_scores_df.groupby(celltype, observed = False).mean().T\n",
    "    filtered_summarized_tf_scores_df.index.name = \"gene\"\n",
    "    filtered_summarized_tf_scores_df.to_csv(f'{single_result_path}/tf_scores_{condition}.csv')\n",
    "    tf_scores_variable_table = save_variable_tf_score(filtered_summarized_tf_scores_df, condition, single_result_path, plot)\n",
    "\n",
    "    if plot:\n",
    "        plot_tf_activity(filtered_summarized_tf_scores_df, tag_mapping_wilcox, condition, single_result_path)\n",
    "    \n",
    "    #filtered_summarized_tf_scores_df.index = re.sub((\".,\"), \"_\", filtered_summarized_tf_scores_df.index)\n",
    "    anndataobject_markers_wilcoxon_merged = anndataobject_markers_wilcoxon.merge(map_z_value(filtered_summarized_tf_scores_df, anndataobject_markers_wilcoxon),  on=['gene', 'cluster'], how='inner')\n",
    "    anndataobject_markers_wilcoxon_merged = anndataobject_markers_wilcoxon_merged[anndataobject_markers_wilcoxon_merged.tag != \"ns\"]\n",
    "    anndataobject_markers_wilcoxon_merged.dropna(inplace=True)\n",
    "    res_wilcoxon = anndataobject_markers_wilcoxon_merged[[\"gene\",\"tag\", \"cluster\", \"z_score\"]]\n",
    "\n",
    "    #anndataobject_markers_t_over_merged = anndataobject_markers_t_over.merge(map_z_value_filtered(filtered_summarized_tf_scores_df, anndataobject_markers_t_over),  on=['gene', 'cluster'], how='inner')\n",
    "    #anndataobject_markers_t_over_merged = anndataobject_markers_t_over_merged[anndataobject_markers_t_over_merged.tag != \"ns\"]\n",
    "    #anndataobject_markers_t_over_merged.dropna(inplace=True)\n",
    "    #res_t_test = anndataobject_markers_t_over[[\"gene\",\"tag\", \"cluster\", \"z_score\"]]\n",
    "\n",
    "    res_wilcoxon.to_csv(single_result_path + \"/\" + name + \"_significant_markers_wilcoxon.csv\", index=0)\n",
    "    #res_t_test.to_csv(single_result_path + \"/\" + name + \"_significant_markers_t_test.csv\", index=0)\n",
    "\n",
    "     #//TODO: \n",
    "    #delete one variant and put test type as a variable\n",
    "\n",
    "    res = {}\n",
    "    res[\"cluster\"] = res_wilcoxon\n",
    "    return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "metadata": {},
   "outputs": [],
   "source": [
    "#check if it's okay to not pre set the column type as string or float (maybe no problem in python but was problem in r)\n",
    "\n",
    "def create_empty_CTR_dataframe():\n",
    "  \n",
    "  empty_df = pd.DataFrame(\n",
    "    columns=[\n",
    "    \"source\",\n",
    "    \"target\",\n",
    "    \"gene_A\",\n",
    "    \"gene_B\",\n",
    "    \"type_gene_A\",\n",
    "    \"type_gene_B\",\n",
    "    \"MeanLR\"\n",
    "    ])\n",
    "  \n",
    "  return(empty_df)\n",
    "\n",
    "\n",
    "def add_entry(source, target, gene_A, gene_B, type_gene_A, type_gene_B, MeanLR):\n",
    "  df = {\"source\" : source,\n",
    "      \"target\" : target,\n",
    "      \"gene_A\" : gene_A,\n",
    "      \"gene_B\" : gene_B,\n",
    "      \"type_gene_A\" : type_gene_A,\n",
    "      \"type_gene_B\" : type_gene_B,\n",
    "      \"MeanLR\" : MeanLR}\n",
    "\n",
    "  return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_CrossTalkeR_input(tf_activities, gene_expression, out_path, regulon = None, organism = \"human\"):\n",
    "\n",
    "  if organism == \"human\":\n",
    "    ligands = pd.read_csv(\"ligands_human.csv\")\n",
    "    R2TF = pd.read_csv(\"rtf_db_human.csv\")\n",
    "  else: \n",
    "    ligands = pd.read_csv(\"lignads_mouse.csv\")\n",
    "    R2TF = pd.read_csv(\"rtf_db_mouse.csv\")\n",
    "\n",
    "  R2TF = R2TF.set_index(\"tf\")\n",
    "\n",
    "  sorted_regulon = regulon[[\"tf\", \"target\"]]\n",
    "  sorted_regulon = sorted_regulon.set_index(\"tf\")\n",
    "\n",
    "  output_list = []\n",
    "\n",
    "  for row in range(len((tf_activities))):\n",
    "    \n",
    "    tf_l = []\n",
    "    r_tf = []\n",
    "\n",
    "    #if (tf_activities[\"z_score\"].iloc[row] > 0):\n",
    "    tf = str(tf_activities[\"gene\"].iloc[row])\n",
    "    if tf in sorted_regulon.index:\n",
    "      targets = sorted_regulon.loc[tf, \"target\"]\n",
    "\n",
    "    if tf in R2TF.index:\n",
    "        receptors = R2TF.loc[tf, \"receptor\"]\n",
    "\n",
    "    else:\n",
    "        receptors = []\n",
    "\n",
    "    tf_ligands = np.intersect1d(targets, ligands)\n",
    "\n",
    "    if organism == \"human\":\n",
    "      if len(tf_ligands) > 0:\n",
    "        for ligand in tf_ligands:\n",
    "            expressed = False\n",
    "            if ligand in gene_expression.index:\n",
    "              ex_value = gene_expression.loc[ligand, tf_activities.iloc[row, 2]]\n",
    "              if (ex_value != 0):\n",
    "                expressed = True\n",
    "\n",
    "            \n",
    "            if (expressed == True):\n",
    "              df_list_l = add_entry(source = tf_activities.iloc[row, 2],\n",
    "                                                      target = tf_activities.iloc[row, 2],\n",
    "                                                      gene_A =tf_activities.iloc[row, 0],\n",
    "                                                      gene_B = ligand,\n",
    "                                                      type_gene_A = \"Transcription_Factor\",\n",
    "                                                      type_gene_B= \"Ligand\",\n",
    "                                                      MeanLR= tf_activities.iloc[row, 3]\n",
    "                                                      )\n",
    "                \n",
    "              output_list.append(df_list_l)\n",
    "              \n",
    "\n",
    "        if (len(receptors) > 0):\n",
    "          for receptor in receptors:\n",
    "            df_list_r = add_entry(source = tf_activities.iloc[row, 2],\n",
    "                                                target = tf_activities.iloc[row, 2],\n",
    "                                                gene_A= receptor,\n",
    "                                                gene_B= tf_activities.iloc[row, 0],\n",
    "                                                type_gene_A= \"Receptor\",\n",
    "                                                type_gene_B= \"Transcription Factor\",\n",
    "                                                MeanLR= tf_activities.iloc[row, 3]\n",
    "                                                )\n",
    "\n",
    "            output_list.append(df_list_r)\n",
    "          \n",
    "                \n",
    "          \n",
    "    else: \n",
    "      if len(tf_ligands) > 0:\n",
    "        for ligand in tf_ligands:\n",
    "            expressed = False\n",
    "            translations = ligand\n",
    "            if len(translations) > 0:\n",
    "              for l in translations:\n",
    "                print(gene_expression.index)\n",
    "                if l in gene_expression.index:\n",
    "                  ex_value = gene_expression.loc[l, tf_activities.iloc[row, 2]]\n",
    "                  if (ex_value != 0):\n",
    "                    expressed = True\n",
    "          \n",
    "                df_list_l = []\n",
    "            \n",
    "                if (expressed == True):\n",
    "                  df_list_l = add_entry(source = tf_activities.iloc[row, 2],\n",
    "                                                      target = tf_activities.iloc[row, 2],\n",
    "                                                      gene_A =tf_activities.iloc[row, 0],\n",
    "                                                      gene_B = ligand,\n",
    "                                                      type_gene_A = \"Transcription_Factor\",\n",
    "                                                      type_gene_B= \"Ligand\",\n",
    "                                                      MeanLR= tf_activities.iloc[row, 3]\n",
    "                                                      )\n",
    "                \n",
    "                  output_list.append(df_list_l)\n",
    "      \n",
    "              if (len(receptors) > 0):\n",
    "                for receptor in receptors:\n",
    "                  df_list_r = [] \n",
    "                  df_list_r = add_entry(tf_activities.iloc[row, 2],\n",
    "                                                tf_activities.iloc[row, 2],\n",
    "                                                receptor,\n",
    "                                                tf_activities.iloc[row, 0],\n",
    "                                                \"Receptor\",\n",
    "                                                \"Transcription Factor\",\n",
    "                                                tf_activities.iloc[row, 3]\n",
    "                                                )\n",
    "                                                \n",
    "                  output_list.append(df_list_r)\n",
    "        #tf_l.to_csv(single_result_path + \"/\" + renamed_condition + \"_ctr_test_l.csv\", index=0)\n",
    "        #r_tf.to_csv(single_result_path + \"/\" + renamed_condition + \"_ctr_test_r.csv\", index=0)\n",
    "\n",
    "    #    r_tf[\"gene_A\"] <- gsub(\"_\", \"+\", r_tf$gene_A, fixed = TRUE)\n",
    "    #   r_tf[\"gene_B\"] <- gsub(\"_\", \"+\", r_tf$gene_B, fixed = TRUE)\n",
    "    #   tf_l[\"gene_A\"] <- gsub(\"_\", \"+\", tf_l$gene_A, fixed = TRUE)\n",
    "    #   tf_l[\"gene_B\"] <- gsub(\"_\", \"+\", tf_l$gene_B, fixed = TRUE\n",
    "  \n",
    "  #output_df = pd.concat([output_df, r_tf], ignore_index=True)\n",
    "  #output_df = pd.concat([output_df, tf_l], ignore_index=True)\n",
    "  output_df = pd.DataFrame(output_list)\n",
    "  output_df.to_csv(\"tf_l_r.csv\", index=0)\n",
    "  print(output_df)\n",
    "\n",
    "  return output_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_intracellular_network(tf_activities, gene_expression, outpath, regulon, organism=\"human\"):\n",
    "\n",
    "    if len(tf_activities.shape) > 0:\n",
    "        if organism == \"human\":\n",
    "            R2TF = pd.read_csv(\"rtf_db_human.csv\").set_index(\"tf\")\n",
    "        else:\n",
    "            R2TF = pd.read_csv(\"rtf_db_mouse.csv\").set_index(\"tf\")\n",
    "\n",
    "    sorted_regulon = regulon[[\"tf\", \"target\"]].set_index(\"tf\")\n",
    "\n",
    "    #preextract values\n",
    "    tf_genes = tf_activities[\"gene\"].values\n",
    "    tf_celltypes = tf_activities.iloc[:, 2].values\n",
    "    tf_scores = tf_activities.iloc[:, 3].values\n",
    "\n",
    "    TFTG_list = []\n",
    "    RTF_list = []\n",
    "\n",
    "    for row in range(len(tf_activities)):\n",
    "        tf = str(tf_genes[row])\n",
    "        celltype = tf_celltypes[row]\n",
    "        tf_score = tf_scores[row]\n",
    "\n",
    "        targets = sorted_regulon.loc[tf, \"target\"] if tf in sorted_regulon.index else []\n",
    "        receptors = R2TF.loc[tf, \"receptor\"] if tf in R2TF.index else []\n",
    "\n",
    "        if len(targets) > 0 and len(receptors) > 0:\n",
    "            for target in targets:\n",
    "                if target in gene_expression.index:\n",
    "                    ex_value = gene_expression.at[target, celltype]\n",
    "                    if ex_value != 0:\n",
    "                        TFTG_list.append({\n",
    "                            \"celltype\": celltype,\n",
    "                            \"TF\": tf,\n",
    "                            \"Target_Gene\": target,\n",
    "                            \"TF_Score\": tf_score\n",
    "                        })\n",
    "\n",
    "            for receptor in receptors:\n",
    "                RTF_list.append({\n",
    "                    \"Receptor\": receptor,\n",
    "                    \"TF\": tf\n",
    "                })\n",
    "\n",
    "    TFTG_df = pd.DataFrame(TFTG_list)\n",
    "    RTF_df = pd.DataFrame(RTF_list)\n",
    "\n",
    "    recept_regulon = pd.merge(RTF_df, TFTG_df, on=\"TF\")\n",
    "\n",
    "    return recept_regulon"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import false_discovery_control\n",
    "from itertools import combinations\n",
    "\n",
    "def condition_comparison_significant(tf_activities, out_path, celltype, condition, comparison_list):\n",
    "\n",
    "    vs_df_dic = {}\n",
    "\n",
    "    if isinstance(comparison_list[0], str):  # Single pair provided as [\"PMF2\", \"control\"]\n",
    "        comparison_list = [comparison_list]\n",
    "    \n",
    "    for vs1, vs2 in comparison_list:\n",
    "\n",
    "        print(f\"vs1: {vs1}, vs2: {vs2}\") \n",
    "\n",
    "        all_tf_list = tf_activities.var_names\n",
    "\n",
    "        res = pd.DataFrame()\n",
    "        for i in tf_activities.obs[celltype].unique(): \n",
    "            comparison_sub = tf_activities[(tf_activities.obs[celltype] == i) & (tf_activities.obs[condition].isin([vs1, vs2]))]\n",
    "            if len(pd.unique(comparison_sub.obs[condition])) == 2:\n",
    "                condition_table = comparison_sub.obs[[condition]].copy()\n",
    "                condition_table.columns = [\"condition\"]\n",
    "                metadata_counts = condition_table.groupby(\"condition\", observed = False).size()\n",
    "                \n",
    "                if (metadata_counts[0] + metadata_counts[1]) > 10:\n",
    "                    g = comparison_sub.obs[condition].astype(\"category\")\n",
    "                    g = g.cat.set_categories([vs1, vs2])\n",
    "                    \n",
    "                    sc.tl.rank_genes_groups(comparison_sub, groupby= condition,\n",
    "                                         reference=\"rest\", method=\"wilcoxon\", key_added=\"condition_comp_markers\", corr_method= \"bonferroni\")\n",
    "                    \n",
    "                    #sc.pl.rank_genes_groups_heatmap(comparison_sub, show_gene_labels=True, key=\"condition_comp_markers\")\n",
    "\n",
    "                    res_tmp = sc.get.rank_genes_groups_df(comparison_sub, group = None, log2fc_min=0, key=\"condition_comp_markers\")\n",
    "                \n",
    "                    res_tmp[\"FDR\"] = false_discovery_control(res_tmp[\"pvals\"])\n",
    "\n",
    "                    group1 = comparison_sub.X[g == vs1]\n",
    "                    group2 = comparison_sub.X[g == vs2]\n",
    "                        \n",
    "                    \n",
    "                    res_tmp[\"r\"] = res_tmp[\"scores\"] / np.sqrt(len(group1) + len(group2))\n",
    "                    res_tmp[\"CellType\"] = i\n",
    "\n",
    "                    res = pd.concat([res, res_tmp], ignore_index=True)\n",
    "\n",
    "        res_df = res.dropna()\n",
    "\n",
    "        def assign_significance_tag(fdr):\n",
    "            if fdr < 0.001:\n",
    "                return \"***\"\n",
    "            elif fdr < 0.01:\n",
    "                return \"**\"\n",
    "            elif fdr < 0.05:\n",
    "                return \"*\"\n",
    "            else:\n",
    "                return \"ns\"\n",
    "\n",
    "        res_df[\"tag\"] = res_df[\"FDR\"].apply(assign_significance_tag)\n",
    "        \n",
    "        res_df.rename(columns={\"names\":\"tf\", \"group\": \"condition\"}, inplace=True)\n",
    "        res_df.to_csv(f\"{out_path}/all_tfs_{vs1}_vs_{vs2}.csv\", index=False)\n",
    "\n",
    "        result_name = f\"{vs1}_{vs2}\"\n",
    "        vs_df_dic[result_name] = res_df\n",
    "        \n",
    "        return vs_df_dic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_significant_tfs(tf_activities_sub, condition, out_path, tf_condition_significant, celltype, pval, logfc, plot):\n",
    "    \n",
    "     #does not work if condition is None\n",
    "    renamed_condition = condition.replace(\",\", \"_\")\n",
    "    #name = name.replace(\",\", \"_\")\n",
    "\n",
    "    single_result_path = out_path + renamed_condition \n",
    "    if not os.path.isdir(single_result_path):\n",
    "        os.mkdir(single_result_path)\n",
    "\n",
    "    tf_activities_scaled = sc.pp.scale(tf_activities_sub, copy= True)\n",
    "\n",
    "    #tf_activities_sub = sc.pp.normalize_total(tf_activities_scaled, copy=True)\n",
    "    #tf_activities_sub = sc.pp.log1p(tf_activities_sub, copy=True) \n",
    "    # \"warning: seems to be already log transformed\"\n",
    "\n",
    "    number_of_clusters = len(tf_activities_sub.obs[\"new_annotation\"].cat.categories) \n",
    "\n",
    "\n",
    "    sc.tl.rank_genes_groups(tf_activities_sub, groupby= \"new_annotation\", reference=\"rest\", method=\"wilcoxon\", key_added=\"wilcoxon_markers\", corr_method= \"bonferroni\")\n",
    "    #sc.tl.filter_rank_genes_groups(anndataobject, min_in_group_fraction=0, key=\"wilcoxon_markers\", key_added= \"wilcoxon_markers_filtered\")\n",
    "    \n",
    "\n",
    "    sc.tl.rank_genes_groups(tf_activities_sub, groupby= \"new_annotation\", reference=\"rest\", method=\"t-test_overestim_var\", key_added=\"t_test_overestim_var_markers\", corr_method= \"bonferroni\" )\n",
    "    #sc.tl.filter_rank_genes_groups(anndataobject, min_in_group_fraction=0, key=\"t_test_overestim_var_markers\", key_added=\"t_test_overestim_filtered\")\n",
    "\n",
    "\n",
    "    result1 = tf_activities_sub.uns['wilcoxon_markers']\n",
    "    groups = result1['names'].dtype.names\n",
    "    anndataobject_markers = pd.DataFrame(\n",
    "    {group + '_' + key[:1]: result1[key][group]\n",
    "    for group in groups for key in ['names','logfoldchanges','pvals','pvals_adj']})\n",
    "\n",
    "    result2 = tf_activities_sub.uns['t_test_overestim_var_markers']\n",
    "    groups = result2['names'].dtype.names\n",
    "    anndataobject_markers = pd.DataFrame(\n",
    "    {group + '_' + key[:1]: result2[key][group]\n",
    "    for group in groups for key in ['names','logfoldchanges','pvals','pvals_adj']})\n",
    "\n",
    "    anndataobject_markers_wilcoxon = sc.get.rank_genes_groups_df(tf_activities_sub, group = None, log2fc_min=0, key=\"wilcoxon_markers\")\n",
    "    \n",
    "    anndataobject_markers_wilcoxon.rename(columns={\"names\":\"gene\", \"group\": \"cluster\"}, inplace=True)\n",
    "    \n",
    "    #documentation says this won't update the main dataframe but will only overwrite a copy in future pandas versions (after v3)\n",
    "    anndataobject_markers_wilcoxon[\"tag\"] = None\n",
    "    anndataobject_markers_wilcoxon[\"log_fc_tag\"] = None\n",
    "    \n",
    "    for i in range(len(anndataobject_markers_wilcoxon[\"pvals_adj\"])):\n",
    "         anndataobject_markers_wilcoxon[\"tag\"].iloc[i,] = eval_pval(anndataobject_markers_wilcoxon[\"pvals_adj\"].iloc[i,])\n",
    "         anndataobject_markers_wilcoxon[\"log_fc_tag\"].iloc[i,] = eval_log_fc_tag(anndataobject_markers_wilcoxon[\"logfoldchanges\"].iloc[i,])\n",
    "     \n",
    "\n",
    "    anndataobject_markers_wilcoxon.to_csv(single_result_path + \"/\" + renamed_condition + \"_specific_markers_wilcoxon_test.csv\",index=0)\n",
    "\n",
    "    anndataobject_markers_t_over = sc.get.rank_genes_groups_df(tf_activities_sub, group = None, log2fc_min=0, key=\"t_test_overestim_var_markers\")\n",
    " \n",
    "    anndataobject_markers_t_over.rename(columns={\"names\":\"gene\", \"group\": \"cluster\"}, inplace=True)\n",
    "\n",
    "    anndataobject_markers_t_over[\"tag\"] = None\n",
    "    anndataobject_markers_t_over[\"log_fc_tag\"] = None\n",
    "    for i in range(len(anndataobject_markers_t_over[\"pvals_adj\"])):\n",
    "         anndataobject_markers_t_over[\"tag\"].iloc[i,] = eval_pval(anndataobject_markers_t_over[\"pvals_adj\"].iloc[i,])\n",
    "         anndataobject_markers_t_over[\"log_fc_tag\"].iloc[i,] = eval_pval(anndataobject_markers_t_over[\"logfoldchanges\"].iloc[i,])\n",
    "\n",
    "    anndataobject_markers_t_over.to_csv(single_result_path + \"/\" + renamed_condition + \"_specific_markers_t_test_overestim_test.csv\",index=0)\n",
    "\n",
    "   #tag mapping wilcoxon\n",
    "    tag_mapping_wilcox = anndataobject_markers_wilcoxon[[\"gene\", \"tag\", \"log_fc_tag\", \"cluster\", \"pvals_adj\", \"logfoldchanges\"]]\n",
    "    tag_mapping_wilcox = tag_mapping_wilcox[(tag_mapping_wilcox[\"pvals_adj\"] < float(pval)) & \n",
    "                              ((tag_mapping_wilcox[\"logfoldchanges\"] > float(logfc)) | \n",
    "                              (tag_mapping_wilcox[\"logfoldchanges\"] < -float(logfc)))]\n",
    "\n",
    "    tag_mapping_wilcox = tag_mapping_wilcox.pivot(index=\"gene\", columns=\"cluster\", values=\"tag\")\n",
    "    clusters = anndataobject_markers_wilcoxon[\"cluster\"].unique()\n",
    "\n",
    "    for cluster in clusters:\n",
    "        if cluster not in tag_mapping_wilcox.columns:\n",
    "            tag_mapping_wilcox[cluster] = np.nan\n",
    "\n",
    "    tag_mapping_wilcox.fillna(\"ns\", inplace=True)\n",
    "\n",
    "    tf_activities_scaled.obs_names = tf_activities_scaled.obs[celltype]\n",
    "    tf_scores_df = tf_activities_scaled.to_df()\n",
    "    tf_scores_df.columns.name = None\n",
    "    unfiltered_tf_scores = create_unfiltered_tf_scores(tf_scores_df, condition, celltype, single_result_path)\n",
    "   \n",
    "    #Filter to only include tfs that match the tag_mapping/are markers\n",
    "    col_num = tf_scores_df.columns.isin(tag_mapping_wilcox.index)  \n",
    "    filtered_tf_scores_df = tf_scores_df.loc[:, col_num] \n",
    "    \n",
    "    filtered_summarized_tf_scores_df = filtered_tf_scores_df.groupby(celltype, observed = False).mean().T\n",
    "    filtered_summarized_tf_scores_df.index.name = \"gene\"\n",
    "    filtered_summarized_tf_scores_df.to_csv(f'{single_result_path}/tf_scores_{condition}.csv')\n",
    "    tf_scores_variable_table = save_variable_tf_score(filtered_summarized_tf_scores_df, condition, single_result_path, plot)\n",
    "\n",
    "    if plot:\n",
    "        plot_tf_activity(filtered_summarized_tf_scores_df, tag_mapping_wilcox, condition, single_result_path)\n",
    "    \n",
    "    #filtered_summarized_tf_scores_df.index = re.sub((\".,\"), \"_\", filtered_summarized_tf_scores_df.index)\n",
    "    \n",
    "    anndataobject_markers_wilcoxon_merged = anndataobject_markers_wilcoxon.merge(map_z_value(filtered_summarized_tf_scores_df, anndataobject_markers_wilcoxon),  on=['gene', 'cluster'], how='inner')\n",
    "    anndataobject_markers_wilcoxon_merged = anndataobject_markers_wilcoxon_merged[anndataobject_markers_wilcoxon_merged.tag != \"ns\"]\n",
    "    anndataobject_markers_wilcoxon_merged.dropna(inplace=True)\n",
    "    res_wilcoxon = anndataobject_markers_wilcoxon_merged[[\"gene\",\"tag\", \"cluster\", \"z_score\"]]\n",
    "\n",
    "    #anndataobject_markers_t_over_merged = anndataobject_markers_t_over.merge(map_z_value_filtered(filtered_summarized_tf_scores_df, anndataobject_markers_t_over),  on=['gene', 'cluster'], how='inner')\n",
    "    #anndataobject_markers_t_over_merged = anndataobject_markers_t_over_merged[anndataobject_markers_t_over_merged.tag != \"ns\"]\n",
    "    #anndataobject_markers_t_over_merged.dropna(inplace=True)\n",
    "    #res_t_test = anndataobject_markers_t_over[[\"gene\",\"tag\", \"cluster\", \"z_score\"]]\n",
    "\n",
    "    res_wilcoxon.to_csv(single_result_path + \"/\" + renamed_condition + \"_significant_markers_wilcoxon.csv\", index=0)\n",
    "    #res_t_test.to_csv(single_result_path + \"/\" + renamed_condition + \"_significant_markers_t_test.csv\", index=0)\n",
    "\n",
    "    res = {}\n",
    "    res[\"cluster\"] = res_wilcoxon\n",
    "    \n",
    "    #tf_condition_significant[\"gene\"] = gsub(\".\", \"-\", tf_condition_significant$gene, fixed = TRUE)\n",
    "    tf_condition_significant = tf_condition_significant.merge(map_z_value(unfiltered_tf_scores, tf_condition_significant), left_on=None, right_on=None, left_index=False, right_index=False)\n",
    "    tf_condition_significant.dropna(inplace=True)\n",
    "    \n",
    "    res[\"condition\"] = tf_condition_significant\n",
    "    res[\"condition\"].to_csv(f\"{single_result_path}/significant_condition_tf_results_{condition} .csv\")\n",
    "\n",
    "    return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "metadata": {},
   "outputs": [],
   "source": [
    "def IntraTalker_analysis(anndataobject, arguments_list = None):\n",
    "    \n",
    "    if (isinstance(anndataobject, str)):\n",
    "        anndataobject = ad.read_h5ad(anndataobject)\n",
    "\n",
    "    arguments_list = validate_input_arguments(arguments_list)\n",
    "\n",
    "    if arguments_list[\"decoupler_matrix_format\"] == \"R\":\n",
    "        anndataobject = anndataobject.T\n",
    "\n",
    "    if not os.path.isdir(arguments_list[\"out_path\"]):\n",
    "        os.mkdir(arguments_list[\"out_path\"])\n",
    "        tf_path = arguments_list[\"out_path\"] + \"TF_results/\"\n",
    "        os.mkdir(tf_path)\n",
    "    else:\n",
    "        tf_path = arguments_list[\"out_path\"] + \"TF_results/\"\n",
    "\n",
    "\n",
    "    condition = anndataobject.obs[arguments_list[\"condition\"]]\n",
    "\n",
    "    #checks for tf activity csv, if nothing there, runs decoupler\n",
    "    if isinstance(arguments_list[\"tf_activities\"], str):\n",
    "         tf_activities = ad.read_csv(arguments_list[\"tf_activities\"])\n",
    "         tf_activities.obs = anndataobject.obs.reindex(tf_activities.obs.index)\n",
    "         tf_activities.obsm = anndataobject.obsm\n",
    "         tf_activities.uns = anndataobject.uns\n",
    "\n",
    "    elif arguments_list[\"tf_activities\"] is None:\n",
    "         raise NameError(\"Please attach a csv file with the tf activity values. (For further clarification view the 'Decoupler' section of the vignette.)\")\n",
    "        \n",
    "\n",
    "    #sets the stage for decision if single condition or comparison analysis is done\n",
    "\n",
    "    if not pd.isnull(all(arguments_list[\"comparison_list\"])):\n",
    "        if (len(arguments_list[\"comparison_list\"]) > 0) & (len(pd.unique(anndataobject.obs[arguments_list[\"condition\"]])) < 2):\n",
    "            arguments_list[\"comparison_list\"] = np.nan\n",
    "            print(\"Only one condition was found in the data, although a list of comparisons was provided. The analyses are performed only for the present condition!\")\n",
    "\n",
    "    #code for single condition  analysis\n",
    "\n",
    "    if pd.isnull(all(arguments_list[\"comparison_list\"])):\n",
    "\n",
    "        result_list = {}\n",
    "        gene_expression_list = {}\n",
    "        CTR_cluster_list = {}\n",
    "        intranet_cluster_list = {}\n",
    "\n",
    "        #creates loop until after tf activity score\n",
    "        \n",
    "        for name_iterable in anndataobject.obs[arguments_list[\"condition\"]].unique():\n",
    "            sub_object = anndataobject[anndataobject.obs[arguments_list[\"condition\"]] == name_iterable]\n",
    "            tf_activities_sub = tf_activities[tf_activities.obs[arguments_list[\"condition\"]] == name_iterable]\n",
    "\n",
    "            sub_object_avg = AverageExpression(sub_object, name_iterable= name_iterable, celltype = arguments_list[\"celltype\"], outpath= arguments_list[\"out_path\"])\n",
    "            \n",
    "            #check how sub object is returned by average expression (subobject.T) or rename return?\n",
    "            tf_activity_scores = get_significant_tfs_single(tf_activities_sub, celltype = arguments_list[\"celltype\"],\n",
    "                                                            condition = name_iterable, out_path= tf_path, pval = arguments_list[\"pval\"], \n",
    "                                                            logfc = arguments_list[\"logfc\"], name = name_iterable, plot = arguments_list[\"plot\"])\n",
    "\n",
    "            result_list[name_iterable] = tf_activity_scores\n",
    "            \n",
    "            gene_expression_list[name_iterable] = sub_object_avg\n",
    "            \n",
    "        \n",
    "    \n",
    "            CTR_cluster_list[name_iterable] = generate_CrossTalkeR_input(tf_activity_scores[\"cluster\"],\n",
    "                                                                            gene_expression_list[name_iterable],\n",
    "                                                                            arguments_list[\"out_path\"],                                             \n",
    "                                                                            arguments_list[\"reg\"],\n",
    "                                                                            arguments_list[\"organism\"])\n",
    "    \n",
    "              \n",
    "            intranet_cluster_list[name_iterable] = generate_intracellular_network(tf_activity_scores[\"cluster\"],\n",
    "                                                                                  gene_expression_list[name_iterable],\n",
    "                                                                                  arguments_list[\"out_path\"],\n",
    "                                                                                  arguments_list[\"reg\"],\n",
    "                                                                                  arguments_list[\"organism\"])\n",
    "            \n",
    "            #also return anndata object with avg expression and tf score as uns layer?\n",
    "\n",
    "        tf = make_TFOBj(\n",
    "                tf_activities_condition = list(),\n",
    "                tf_activities_cluster = result_list,\n",
    "                average_gene_expression = gene_expression_list,\n",
    "                regulon = arguments_list[\"reg\"],\n",
    "                CTR_input_condition = list(),\n",
    "                CTR_input_cluster = CTR_cluster_list,\n",
    "                intracellular_network_condition = list(),\n",
    "                intracellular_network_cluster = intranet_cluster_list)\n",
    "\n",
    "        with open((arguments_list[\"out_path\"] + \"tf.pickle\"), \"wb\") as file:\n",
    "            pickle.dump(tf, file)\n",
    "\n",
    "        return tf\n",
    "\n",
    "    else:\n",
    "        out_path_compared = (tf_path + \"compared\")\n",
    "        if not os.path.isdir(out_path_compared):\n",
    "            os.mkdir(out_path_compared)\n",
    "\n",
    "        compared_significant_tfs = condition_comparison_significant(tf_activities, out_path_compared, arguments_list[\"celltype\"], \n",
    "                                                                    arguments_list[\"condition\"], arguments_list[\"comparison_list\"])\n",
    "        \n",
    "        print(\"compared tfs done\")\n",
    "        \n",
    "        if arguments_list[\"plot\"] == True:\n",
    "            plot_condition_tf_activities(compared_significant_tfs, out_path_compared)\n",
    "            plot_condition_tf_activities_compressed(compared_significant_tfs, out_path_compared)\n",
    "\n",
    "    \n",
    "        result_condition_list = {}\n",
    "        result_cluster_list = {}\n",
    "        gene_expression_list = {}\n",
    "        CTR_condition_list = {}\n",
    "        CTR_cluster_list = {}\n",
    "        intranet_condition_list = {}\n",
    "        intranet_cluster_list = {}\n",
    "\n",
    "        for name_iterable in anndataobject.obs[arguments_list[\"condition\"]].unique():\n",
    "            sub_object = anndataobject[anndataobject.obs[arguments_list[\"condition\"]] == name_iterable]\n",
    "            tf_activities_sub = tf_activities[tf_activities.obs[arguments_list[\"condition\"]] == name_iterable]\n",
    "            \n",
    "\n",
    "            compared_tfs = pd.DataFrame({\"gene\" : pd.Series(dtype=\"str\"), \"tag\" : pd.Series(dtype=\"str\"), \"cluster\" : pd.Series(dtype=\"str\")})\n",
    "            \n",
    "        \n",
    "            for result_name, df in zip(map(str, range(len(compared_significant_tfs))), compared_significant_tfs):  \n",
    "                if name_iterable in result_name:\n",
    "                    tf_condition_significant = compared_significant_tfs[[result_name]]\n",
    "                    tf_condition_significant = tf_condition_significant[tf_condition_significant[\"FDR\"] < arguments_list[\"pval\"]]\n",
    "                    tf_condition_significant = tf_condition_significant[(tf_condition_significant[\"logfoldchanges\"] > float(arguments_list[\"logfc\"])) | (tf_condition_significant[\"logfoldchanges\"] < (0 - float(arguments_list[\"logfc\"])))]\n",
    "                    tf_condition_significant = tf_condition_significant[[\"tf\", \"tag\", \"CellType\"]]\n",
    "                    tf_condition_significant.rename(columns={\"tf\":\"gene\", \"CellType\": \"cluster\"}, inplace=True)\n",
    "                    compared_tfs = pd.concat([compared_tfs, tf_condition_significant])\n",
    "\n",
    "            print(compared_tfs)\n",
    "            #compared_tfs[\"gene\"] = compared_tfs[\"gene\"].unique()\n",
    "         \n",
    "            \n",
    "            #name <- str_replace_all(name, \"[,;.:-]\", \"_\"),\n",
    "\n",
    "            sub_object_avg = AverageExpression(sub_object, name_iterable= name_iterable, celltype = arguments_list[\"celltype\"], \n",
    "                                               outpath= arguments_list[\"out_path\"])\n",
    "            \n",
    "            tf_activity_scores = get_significant_tfs(tf_activities_sub,\n",
    "                                               name_iterable,\n",
    "                                               tf_path,\n",
    "                                               compared_tfs,\n",
    "                                               celltype = arguments_list[\"celltype\"],\n",
    "                                               pval = arguments_list[\"pval\"],\n",
    "                                               logfc = arguments_list[\"logfc\"],\n",
    "                                               plot = arguments_list[\"plot\"])\n",
    "            \n",
    "            print(\"tf_activities done\")\n",
    "\n",
    "            result_condition_list[name_iterable] = tf_activity_scores[\"condition\"]\n",
    "            result_cluster_list[name_iterable] = tf_activity_scores[\"cluster\"]\n",
    "\n",
    "            gene_expression_list[name_iterable] = sub_object_avg\n",
    "            \n",
    "        \n",
    "            CTR_condition_list[name_iterable] = generate_CrossTalkeR_input(tf_activity_scores[\"condition\"],\n",
    "                                                                            gene_expression_list[name_iterable],\n",
    "                                                                            arguments_list[\"out_path\"],                                             \n",
    "                                                                            arguments_list[\"reg\"],\n",
    "                                                                            arguments_list[\"organism\"])\n",
    "            \n",
    "            print(\"CTR input condition done\")\n",
    "    \n",
    "            CTR_cluster_list[name_iterable] = generate_CrossTalkeR_input(tf_activity_scores[\"cluster\"],\n",
    "                                                                            gene_expression_list[name_iterable],\n",
    "                                                                            arguments_list[\"out_path\"],                                             \n",
    "                                                                            arguments_list[\"reg\"],\n",
    "                                                                            arguments_list[\"organism\"])\n",
    "    \n",
    "            print(\"CTR input cluster done\")\n",
    "\n",
    "            #intranet_condition_list[name_iterable] = generate_intracellular_network(tf_activity_scores[\"condition\"],\n",
    "            #                                                                      gene_expression_list[name_iterable],\n",
    "            #                                                                      arguments_list[\"out_path\"],\n",
    "            #                                                                      arguments_list[\"reg\"],\n",
    "            #                                                                      arguments_list[\"organism\"])\n",
    "    \n",
    "            print(\"intranet input condition done\")\n",
    "\n",
    "            #intranet_cluster_list[name_iterable] = generate_intracellular_network(tf_activity_scores[\"cluster\"],\n",
    "            #                                                                      gene_expression_list[name_iterable],\n",
    "            #                                                                      arguments_list[\"out_path\"],\n",
    "            #                                                                      arguments_list[\"reg\"],\n",
    "            #                                                                      arguments_list[\"organism\"])\n",
    "            print(\"intranet input cluster done\")\n",
    "\n",
    "        tf = make_TFOBj(\n",
    "                tf_activities_condition = result_condition_list,\n",
    "                tf_activities_cluster = result_cluster_list,\n",
    "                average_gene_expression = gene_expression_list,\n",
    "                regulon = arguments_list[\"reg\"],\n",
    "                CTR_input_condition = CTR_condition_list,\n",
    "                CTR_input_cluster = CTR_cluster_list,\n",
    "                intracellular_network_condition = intranet_condition_list,\n",
    "                intracellular_network_cluster = intranet_cluster_list)\n",
    "\n",
    "        with open((arguments_list[\"out_path\"] + \"tf.pickle\"), \"wb\") as file:\n",
    "            pickle.dump(tf, file)\n",
    "        \n",
    "        return tf\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 222,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "vs1: PMF,MF2, vs2: control\n",
      "compared tfs done\n",
      "          tf  tag       CellType\n",
      "0        REL  ***  Megakaryocyte\n",
      "1      KLF13  ***  Megakaryocyte\n",
      "2       IRF9  ***  Megakaryocyte\n",
      "3       NRF1  ***  Megakaryocyte\n",
      "6       HIC1   **  Megakaryocyte\n",
      "...      ...  ...            ...\n",
      "1419   FOXP1  ***         Neural\n",
      "1420  NFATC1  ***         Neural\n",
      "1433    E2F7    *         Neural\n",
      "1466    ADNP  ***         Neural\n",
      "1467   FOXF2  ***         Neural\n",
      "\n",
      "[764 rows x 3 columns]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Larissa\\AppData\\Local\\Temp\\ipykernel_21032\\783873770.py:25: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n",
      "  if (metadata_counts[0] + metadata_counts[1]) > 10:\n",
      "d:\\studium\\LR2TF_HiWi\\.venv\\Lib\\site-packages\\scanpy\\tools\\_rank_genes_groups.py:640: ImplicitModificationWarning: Trying to modify attribute `._uns` of view, initializing view as actual.\n",
      "  adata.uns[key_added] = {}\n",
      "d:\\studium\\LR2TF_HiWi\\.venv\\Lib\\site-packages\\scanpy\\tools\\_rank_genes_groups.py:455: RuntimeWarning: invalid value encountered in log2\n",
      "  self.stats[group_name, \"logfoldchanges\"] = np.log2(\n",
      "d:\\studium\\LR2TF_HiWi\\.venv\\Lib\\site-packages\\scanpy\\tools\\_rank_genes_groups.py:455: RuntimeWarning: invalid value encountered in log2\n",
      "  self.stats[group_name, \"logfoldchanges\"] = np.log2(\n",
      "C:\\Users\\Larissa\\AppData\\Local\\Temp\\ipykernel_21032\\783873770.py:25: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n",
      "  if (metadata_counts[0] + metadata_counts[1]) > 10:\n",
      "d:\\studium\\LR2TF_HiWi\\.venv\\Lib\\site-packages\\scanpy\\tools\\_rank_genes_groups.py:640: ImplicitModificationWarning: Trying to modify attribute `._uns` of view, initializing view as actual.\n",
      "  adata.uns[key_added] = {}\n",
      "d:\\studium\\LR2TF_HiWi\\.venv\\Lib\\site-packages\\scanpy\\tools\\_rank_genes_groups.py:455: RuntimeWarning: invalid value encountered in log2\n",
      "  self.stats[group_name, \"logfoldchanges\"] = np.log2(\n",
      "d:\\studium\\LR2TF_HiWi\\.venv\\Lib\\site-packages\\scanpy\\tools\\_rank_genes_groups.py:455: RuntimeWarning: invalid value encountered in log2\n",
      "  self.stats[group_name, \"logfoldchanges\"] = np.log2(\n",
      "C:\\Users\\Larissa\\AppData\\Local\\Temp\\ipykernel_21032\\783873770.py:25: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n",
      "  if (metadata_counts[0] + metadata_counts[1]) > 10:\n",
      "d:\\studium\\LR2TF_HiWi\\.venv\\Lib\\site-packages\\scanpy\\tools\\_rank_genes_groups.py:640: ImplicitModificationWarning: Trying to modify attribute `._uns` of view, initializing view as actual.\n",
      "  adata.uns[key_added] = {}\n",
      "d:\\studium\\LR2TF_HiWi\\.venv\\Lib\\site-packages\\scanpy\\tools\\_rank_genes_groups.py:455: RuntimeWarning: invalid value encountered in log2\n",
      "  self.stats[group_name, \"logfoldchanges\"] = np.log2(\n",
      "d:\\studium\\LR2TF_HiWi\\.venv\\Lib\\site-packages\\scanpy\\tools\\_rank_genes_groups.py:455: RuntimeWarning: invalid value encountered in log2\n",
      "  self.stats[group_name, \"logfoldchanges\"] = np.log2(\n",
      "C:\\Users\\Larissa\\AppData\\Local\\Temp\\ipykernel_21032\\783873770.py:25: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n",
      "  if (metadata_counts[0] + metadata_counts[1]) > 10:\n",
      "d:\\studium\\LR2TF_HiWi\\.venv\\Lib\\site-packages\\scanpy\\tools\\_rank_genes_groups.py:640: ImplicitModificationWarning: Trying to modify attribute `._uns` of view, initializing view as actual.\n",
      "  adata.uns[key_added] = {}\n",
      "d:\\studium\\LR2TF_HiWi\\.venv\\Lib\\site-packages\\scanpy\\tools\\_rank_genes_groups.py:455: RuntimeWarning: invalid value encountered in log2\n",
      "  self.stats[group_name, \"logfoldchanges\"] = np.log2(\n",
      "d:\\studium\\LR2TF_HiWi\\.venv\\Lib\\site-packages\\scanpy\\tools\\_rank_genes_groups.py:455: RuntimeWarning: invalid value encountered in log2\n",
      "  self.stats[group_name, \"logfoldchanges\"] = np.log2(\n",
      "C:\\Users\\Larissa\\AppData\\Local\\Temp\\ipykernel_21032\\783873770.py:25: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n",
      "  if (metadata_counts[0] + metadata_counts[1]) > 10:\n",
      "d:\\studium\\LR2TF_HiWi\\.venv\\Lib\\site-packages\\scanpy\\tools\\_rank_genes_groups.py:640: ImplicitModificationWarning: Trying to modify attribute `._uns` of view, initializing view as actual.\n",
      "  adata.uns[key_added] = {}\n",
      "d:\\studium\\LR2TF_HiWi\\.venv\\Lib\\site-packages\\scanpy\\tools\\_rank_genes_groups.py:455: RuntimeWarning: invalid value encountered in log2\n",
      "  self.stats[group_name, \"logfoldchanges\"] = np.log2(\n",
      "d:\\studium\\LR2TF_HiWi\\.venv\\Lib\\site-packages\\scanpy\\tools\\_rank_genes_groups.py:455: RuntimeWarning: invalid value encountered in log2\n",
      "  self.stats[group_name, \"logfoldchanges\"] = np.log2(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Empty DataFrame\n",
      "Columns: [gene, tag, cluster]\n",
      "Index: []\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\studium\\LR2TF_HiWi\\.venv\\Lib\\site-packages\\scanpy\\tools\\_rank_genes_groups.py:640: ImplicitModificationWarning: Trying to modify attribute `._uns` of view, initializing view as actual.\n",
      "  adata.uns[key_added] = {}\n",
      "d:\\studium\\LR2TF_HiWi\\.venv\\Lib\\site-packages\\scanpy\\tools\\_rank_genes_groups.py:455: RuntimeWarning: invalid value encountered in log2\n",
      "  self.stats[group_name, \"logfoldchanges\"] = np.log2(\n",
      "d:\\studium\\LR2TF_HiWi\\.venv\\Lib\\site-packages\\scanpy\\tools\\_rank_genes_groups.py:455: RuntimeWarning: invalid value encountered in log2\n",
      "  self.stats[group_name, \"logfoldchanges\"] = np.log2(\n",
      "d:\\studium\\LR2TF_HiWi\\.venv\\Lib\\site-packages\\scanpy\\tools\\_rank_genes_groups.py:455: RuntimeWarning: invalid value encountered in log2\n",
      "  self.stats[group_name, \"logfoldchanges\"] = np.log2(\n",
      "d:\\studium\\LR2TF_HiWi\\.venv\\Lib\\site-packages\\scanpy\\tools\\_rank_genes_groups.py:455: RuntimeWarning: invalid value encountered in log2\n",
      "  self.stats[group_name, \"logfoldchanges\"] = np.log2(\n",
      "d:\\studium\\LR2TF_HiWi\\.venv\\Lib\\site-packages\\scanpy\\tools\\_rank_genes_groups.py:455: RuntimeWarning: invalid value encountered in log2\n",
      "  self.stats[group_name, \"logfoldchanges\"] = np.log2(\n",
      "d:\\studium\\LR2TF_HiWi\\.venv\\Lib\\site-packages\\scanpy\\tools\\_rank_genes_groups.py:455: RuntimeWarning: invalid value encountered in log2\n",
      "  self.stats[group_name, \"logfoldchanges\"] = np.log2(\n",
      "d:\\studium\\LR2TF_HiWi\\.venv\\Lib\\site-packages\\scanpy\\tools\\_rank_genes_groups.py:455: RuntimeWarning: invalid value encountered in log2\n",
      "  self.stats[group_name, \"logfoldchanges\"] = np.log2(\n",
      "d:\\studium\\LR2TF_HiWi\\.venv\\Lib\\site-packages\\scanpy\\tools\\_rank_genes_groups.py:455: RuntimeWarning: invalid value encountered in log2\n",
      "  self.stats[group_name, \"logfoldchanges\"] = np.log2(\n",
      "d:\\studium\\LR2TF_HiWi\\.venv\\Lib\\site-packages\\scanpy\\tools\\_rank_genes_groups.py:455: RuntimeWarning: invalid value encountered in log2\n",
      "  self.stats[group_name, \"logfoldchanges\"] = np.log2(\n",
      "d:\\studium\\LR2TF_HiWi\\.venv\\Lib\\site-packages\\scanpy\\tools\\_rank_genes_groups.py:455: RuntimeWarning: invalid value encountered in log2\n",
      "  self.stats[group_name, \"logfoldchanges\"] = np.log2(\n",
      "C:\\Users\\Larissa\\AppData\\Local\\Temp\\ipykernel_21032\\626901821.py:49: FutureWarning: ChainedAssignmentError: behaviour will change in pandas 3.0!\n",
      "You are setting values through chained assignment. Currently this works in certain cases, but when using Copy-on-Write (which will become the default behaviour in pandas 3.0) this will never work to update the original DataFrame or Series, because the intermediate object on which we are setting values will behave as a copy.\n",
      "A typical example is when you are setting values in a column of a DataFrame, like:\n",
      "\n",
      "df[\"col\"][row_indexer] = value\n",
      "\n",
      "Use `df.loc[row_indexer, \"col\"] = values` instead, to perform the assignment in a single step and ensure this keeps updating the original `df`.\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "\n",
      "  anndataobject_markers_wilcoxon[\"tag\"].iloc[i,] = eval_pval(anndataobject_markers_wilcoxon[\"pvals_adj\"].iloc[i,])\n",
      "C:\\Users\\Larissa\\AppData\\Local\\Temp\\ipykernel_21032\\626901821.py:49: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  anndataobject_markers_wilcoxon[\"tag\"].iloc[i,] = eval_pval(anndataobject_markers_wilcoxon[\"pvals_adj\"].iloc[i,])\n",
      "C:\\Users\\Larissa\\AppData\\Local\\Temp\\ipykernel_21032\\626901821.py:50: FutureWarning: ChainedAssignmentError: behaviour will change in pandas 3.0!\n",
      "You are setting values through chained assignment. Currently this works in certain cases, but when using Copy-on-Write (which will become the default behaviour in pandas 3.0) this will never work to update the original DataFrame or Series, because the intermediate object on which we are setting values will behave as a copy.\n",
      "A typical example is when you are setting values in a column of a DataFrame, like:\n",
      "\n",
      "df[\"col\"][row_indexer] = value\n",
      "\n",
      "Use `df.loc[row_indexer, \"col\"] = values` instead, to perform the assignment in a single step and ensure this keeps updating the original `df`.\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "\n",
      "  anndataobject_markers_wilcoxon[\"log_fc_tag\"].iloc[i,] = eval_log_fc_tag(anndataobject_markers_wilcoxon[\"logfoldchanges\"].iloc[i,])\n",
      "C:\\Users\\Larissa\\AppData\\Local\\Temp\\ipykernel_21032\\626901821.py:50: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  anndataobject_markers_wilcoxon[\"log_fc_tag\"].iloc[i,] = eval_log_fc_tag(anndataobject_markers_wilcoxon[\"logfoldchanges\"].iloc[i,])\n",
      "C:\\Users\\Larissa\\AppData\\Local\\Temp\\ipykernel_21032\\626901821.py:62: FutureWarning: ChainedAssignmentError: behaviour will change in pandas 3.0!\n",
      "You are setting values through chained assignment. Currently this works in certain cases, but when using Copy-on-Write (which will become the default behaviour in pandas 3.0) this will never work to update the original DataFrame or Series, because the intermediate object on which we are setting values will behave as a copy.\n",
      "A typical example is when you are setting values in a column of a DataFrame, like:\n",
      "\n",
      "df[\"col\"][row_indexer] = value\n",
      "\n",
      "Use `df.loc[row_indexer, \"col\"] = values` instead, to perform the assignment in a single step and ensure this keeps updating the original `df`.\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "\n",
      "  anndataobject_markers_t_over[\"tag\"].iloc[i,] = eval_pval(anndataobject_markers_t_over[\"pvals_adj\"].iloc[i,])\n",
      "C:\\Users\\Larissa\\AppData\\Local\\Temp\\ipykernel_21032\\626901821.py:62: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  anndataobject_markers_t_over[\"tag\"].iloc[i,] = eval_pval(anndataobject_markers_t_over[\"pvals_adj\"].iloc[i,])\n",
      "C:\\Users\\Larissa\\AppData\\Local\\Temp\\ipykernel_21032\\626901821.py:63: FutureWarning: ChainedAssignmentError: behaviour will change in pandas 3.0!\n",
      "You are setting values through chained assignment. Currently this works in certain cases, but when using Copy-on-Write (which will become the default behaviour in pandas 3.0) this will never work to update the original DataFrame or Series, because the intermediate object on which we are setting values will behave as a copy.\n",
      "A typical example is when you are setting values in a column of a DataFrame, like:\n",
      "\n",
      "df[\"col\"][row_indexer] = value\n",
      "\n",
      "Use `df.loc[row_indexer, \"col\"] = values` instead, to perform the assignment in a single step and ensure this keeps updating the original `df`.\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "\n",
      "  anndataobject_markers_t_over[\"log_fc_tag\"].iloc[i,] = eval_pval(anndataobject_markers_t_over[\"logfoldchanges\"].iloc[i,])\n",
      "C:\\Users\\Larissa\\AppData\\Local\\Temp\\ipykernel_21032\\626901821.py:63: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  anndataobject_markers_t_over[\"log_fc_tag\"].iloc[i,] = eval_pval(anndataobject_markers_t_over[\"logfoldchanges\"].iloc[i,])\n",
      "C:\\Users\\Larissa\\AppData\\Local\\Temp\\ipykernel_21032\\626901821.py:80: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value 'ns' has dtype incompatible with float64, please explicitly cast to a compatible dtype first.\n",
      "  tag_mapping_wilcox.fillna(\"ns\", inplace=True)\n",
      "d:\\studium\\LR2TF_HiWi\\.venv\\Lib\\site-packages\\anndata\\_core\\anndata.py:841: UserWarning: \n",
      "AnnData expects .obs.index to contain strings, but got values like:\n",
      "    ['Megakaryocyte', 'Fibroblast', 'MSC', 'Megakaryocyte', 'Megakaryocyte']\n",
      "\n",
      "    Inferred to be: categorical\n",
      "\n",
      "  names = self._prep_dim_index(names, \"obs\")\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "You are trying to merge on object and float64 columns for key 'gene'. If you wish to proceed you should use pd.concat",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[222], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[43mIntraTalker_analysis\u001b[49m\u001b[43m(\u001b[49m\u001b[43manndataobject\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mLR2TF_test_run/anndata_object.h5ad\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43marguments_list\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43m{\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mout_path\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m \u001b[49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mscript_test\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[0;32m      2\u001b[0m \u001b[43m                                                                                                    \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcelltype\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m \u001b[49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mnew_annotation\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m      3\u001b[0m \u001b[43m                                                                                                    \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcondition\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m \u001b[49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mprotocol\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[0;32m      4\u001b[0m \u001b[43m                                                                                                    \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43morganism\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m \u001b[49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mhuman\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[0;32m      5\u001b[0m \u001b[43m                                                                                                    \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcomparison_list\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m \u001b[49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43m[\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mPMF,MF2\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcontrol\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mtest1\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mtest2\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[0;32m      6\u001b[0m \u001b[43m                                                                                                    \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mlogfc\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m \u001b[49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m0\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m      7\u001b[0m \u001b[43m                                                                                                    \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mpval\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m \u001b[49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[0;32m      8\u001b[0m \u001b[43m                                                                                                    \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mnum_cell_filter\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m      9\u001b[0m \u001b[43m                                                                                                    \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mreg\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m \u001b[49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mfilterd_regulon.csv\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[0;32m     10\u001b[0m \u001b[43m                                                                                                    \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mtf_activities\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m \u001b[49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mdecoupler_results.csv\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[0;32m     11\u001b[0m \u001b[43m                                                                                                    \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mplot\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m \u001b[49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m     12\u001b[0m \u001b[43m                                                                                                    \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mdecoupler_matrix_format\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m \u001b[49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mPython\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m}\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[1;32mIn[211], line 146\u001b[0m, in \u001b[0;36mIntraTalker_analysis\u001b[1;34m(anndataobject, arguments_list)\u001b[0m\n\u001b[0;32m    138\u001b[0m \u001b[38;5;66;03m#compared_tfs[\"gene\"] = compared_tfs[\"gene\"].unique()\u001b[39;00m\n\u001b[0;32m    139\u001b[0m \n\u001b[0;32m    140\u001b[0m \n\u001b[0;32m    141\u001b[0m \u001b[38;5;66;03m#name <- str_replace_all(name, \"[,;.:-]\", \"_\"),\u001b[39;00m\n\u001b[0;32m    143\u001b[0m sub_object_avg \u001b[38;5;241m=\u001b[39m AverageExpression(sub_object, name_iterable\u001b[38;5;241m=\u001b[39m name_iterable, celltype \u001b[38;5;241m=\u001b[39m arguments_list[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcelltype\u001b[39m\u001b[38;5;124m\"\u001b[39m], \n\u001b[0;32m    144\u001b[0m                                    outpath\u001b[38;5;241m=\u001b[39m arguments_list[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mout_path\u001b[39m\u001b[38;5;124m\"\u001b[39m])\n\u001b[1;32m--> 146\u001b[0m tf_activity_scores \u001b[38;5;241m=\u001b[39m \u001b[43mget_significant_tfs\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtf_activities_sub\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    147\u001b[0m \u001b[43m                                   \u001b[49m\u001b[43mname_iterable\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    148\u001b[0m \u001b[43m                                   \u001b[49m\u001b[43mtf_path\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    149\u001b[0m \u001b[43m                                   \u001b[49m\u001b[43mcompared_tfs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    150\u001b[0m \u001b[43m                                   \u001b[49m\u001b[43mcelltype\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43marguments_list\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcelltype\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    151\u001b[0m \u001b[43m                                   \u001b[49m\u001b[43mpval\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43marguments_list\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mpval\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    152\u001b[0m \u001b[43m                                   \u001b[49m\u001b[43mlogfc\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43marguments_list\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mlogfc\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    153\u001b[0m \u001b[43m                                   \u001b[49m\u001b[43mplot\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43marguments_list\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mplot\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    155\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtf_activities done\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    157\u001b[0m result_condition_list[name_iterable] \u001b[38;5;241m=\u001b[39m tf_activity_scores[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcondition\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n",
      "Cell \u001b[1;32mIn[196], line 118\u001b[0m, in \u001b[0;36mget_significant_tfs\u001b[1;34m(tf_activities_sub, condition, out_path, tf_condition_significant, celltype, pval, logfc, plot)\u001b[0m\n\u001b[0;32m    115\u001b[0m res[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcluster\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m res_wilcoxon\n\u001b[0;32m    117\u001b[0m \u001b[38;5;66;03m#tf_condition_significant[\"gene\"] = gsub(\".\", \"-\", tf_condition_significant$gene, fixed = TRUE)\u001b[39;00m\n\u001b[1;32m--> 118\u001b[0m tf_condition_significant \u001b[38;5;241m=\u001b[39m \u001b[43mtf_condition_significant\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmerge\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmap_z_value\u001b[49m\u001b[43m(\u001b[49m\u001b[43munfiltered_tf_scores\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtf_condition_significant\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mleft_on\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mright_on\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mleft_index\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mright_index\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[0;32m    119\u001b[0m tf_condition_significant\u001b[38;5;241m.\u001b[39mdropna(inplace\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[0;32m    121\u001b[0m res[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcondition\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m tf_condition_significant\n",
      "File \u001b[1;32md:\\studium\\LR2TF_HiWi\\.venv\\Lib\\site-packages\\pandas\\core\\frame.py:10832\u001b[0m, in \u001b[0;36mDataFrame.merge\u001b[1;34m(self, right, how, on, left_on, right_on, left_index, right_index, sort, suffixes, copy, indicator, validate)\u001b[0m\n\u001b[0;32m  10813\u001b[0m \u001b[38;5;129m@Substitution\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m  10814\u001b[0m \u001b[38;5;129m@Appender\u001b[39m(_merge_doc, indents\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m2\u001b[39m)\n\u001b[0;32m  10815\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mmerge\u001b[39m(\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m  10828\u001b[0m     validate: MergeValidate \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[0;32m  10829\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m DataFrame:\n\u001b[0;32m  10830\u001b[0m     \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mpandas\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcore\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mreshape\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmerge\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m merge\n\u001b[1;32m> 10832\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mmerge\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m  10833\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m  10834\u001b[0m \u001b[43m        \u001b[49m\u001b[43mright\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m  10835\u001b[0m \u001b[43m        \u001b[49m\u001b[43mhow\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mhow\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m  10836\u001b[0m \u001b[43m        \u001b[49m\u001b[43mon\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mon\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m  10837\u001b[0m \u001b[43m        \u001b[49m\u001b[43mleft_on\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mleft_on\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m  10838\u001b[0m \u001b[43m        \u001b[49m\u001b[43mright_on\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mright_on\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m  10839\u001b[0m \u001b[43m        \u001b[49m\u001b[43mleft_index\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mleft_index\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m  10840\u001b[0m \u001b[43m        \u001b[49m\u001b[43mright_index\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mright_index\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m  10841\u001b[0m \u001b[43m        \u001b[49m\u001b[43msort\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msort\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m  10842\u001b[0m \u001b[43m        \u001b[49m\u001b[43msuffixes\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msuffixes\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m  10843\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcopy\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcopy\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m  10844\u001b[0m \u001b[43m        \u001b[49m\u001b[43mindicator\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mindicator\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m  10845\u001b[0m \u001b[43m        \u001b[49m\u001b[43mvalidate\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mvalidate\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m  10846\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32md:\\studium\\LR2TF_HiWi\\.venv\\Lib\\site-packages\\pandas\\core\\reshape\\merge.py:170\u001b[0m, in \u001b[0;36mmerge\u001b[1;34m(left, right, how, on, left_on, right_on, left_index, right_index, sort, suffixes, copy, indicator, validate)\u001b[0m\n\u001b[0;32m    155\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m _cross_merge(\n\u001b[0;32m    156\u001b[0m         left_df,\n\u001b[0;32m    157\u001b[0m         right_df,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    167\u001b[0m         copy\u001b[38;5;241m=\u001b[39mcopy,\n\u001b[0;32m    168\u001b[0m     )\n\u001b[0;32m    169\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 170\u001b[0m     op \u001b[38;5;241m=\u001b[39m \u001b[43m_MergeOperation\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    171\u001b[0m \u001b[43m        \u001b[49m\u001b[43mleft_df\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    172\u001b[0m \u001b[43m        \u001b[49m\u001b[43mright_df\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    173\u001b[0m \u001b[43m        \u001b[49m\u001b[43mhow\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mhow\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    174\u001b[0m \u001b[43m        \u001b[49m\u001b[43mon\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mon\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    175\u001b[0m \u001b[43m        \u001b[49m\u001b[43mleft_on\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mleft_on\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    176\u001b[0m \u001b[43m        \u001b[49m\u001b[43mright_on\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mright_on\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    177\u001b[0m \u001b[43m        \u001b[49m\u001b[43mleft_index\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mleft_index\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    178\u001b[0m \u001b[43m        \u001b[49m\u001b[43mright_index\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mright_index\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    179\u001b[0m \u001b[43m        \u001b[49m\u001b[43msort\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msort\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    180\u001b[0m \u001b[43m        \u001b[49m\u001b[43msuffixes\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msuffixes\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    181\u001b[0m \u001b[43m        \u001b[49m\u001b[43mindicator\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mindicator\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    182\u001b[0m \u001b[43m        \u001b[49m\u001b[43mvalidate\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mvalidate\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    183\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    184\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m op\u001b[38;5;241m.\u001b[39mget_result(copy\u001b[38;5;241m=\u001b[39mcopy)\n",
      "File \u001b[1;32md:\\studium\\LR2TF_HiWi\\.venv\\Lib\\site-packages\\pandas\\core\\reshape\\merge.py:807\u001b[0m, in \u001b[0;36m_MergeOperation.__init__\u001b[1;34m(self, left, right, how, on, left_on, right_on, left_index, right_index, sort, suffixes, indicator, validate)\u001b[0m\n\u001b[0;32m    803\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_validate_tolerance(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mleft_join_keys)\n\u001b[0;32m    805\u001b[0m \u001b[38;5;66;03m# validate the merge keys dtypes. We may need to coerce\u001b[39;00m\n\u001b[0;32m    806\u001b[0m \u001b[38;5;66;03m# to avoid incompatible dtypes\u001b[39;00m\n\u001b[1;32m--> 807\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_maybe_coerce_merge_keys\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    809\u001b[0m \u001b[38;5;66;03m# If argument passed to validate,\u001b[39;00m\n\u001b[0;32m    810\u001b[0m \u001b[38;5;66;03m# check if columns specified as unique\u001b[39;00m\n\u001b[0;32m    811\u001b[0m \u001b[38;5;66;03m# are in fact unique.\u001b[39;00m\n\u001b[0;32m    812\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m validate \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "File \u001b[1;32md:\\studium\\LR2TF_HiWi\\.venv\\Lib\\site-packages\\pandas\\core\\reshape\\merge.py:1508\u001b[0m, in \u001b[0;36m_MergeOperation._maybe_coerce_merge_keys\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1502\u001b[0m     \u001b[38;5;66;03m# unless we are merging non-string-like with string-like\u001b[39;00m\n\u001b[0;32m   1503\u001b[0m     \u001b[38;5;28;01melif\u001b[39;00m (\n\u001b[0;32m   1504\u001b[0m         inferred_left \u001b[38;5;129;01min\u001b[39;00m string_types \u001b[38;5;129;01mand\u001b[39;00m inferred_right \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m string_types\n\u001b[0;32m   1505\u001b[0m     ) \u001b[38;5;129;01mor\u001b[39;00m (\n\u001b[0;32m   1506\u001b[0m         inferred_right \u001b[38;5;129;01min\u001b[39;00m string_types \u001b[38;5;129;01mand\u001b[39;00m inferred_left \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m string_types\n\u001b[0;32m   1507\u001b[0m     ):\n\u001b[1;32m-> 1508\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(msg)\n\u001b[0;32m   1510\u001b[0m \u001b[38;5;66;03m# datetimelikes must match exactly\u001b[39;00m\n\u001b[0;32m   1511\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m needs_i8_conversion(lk\u001b[38;5;241m.\u001b[39mdtype) \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m needs_i8_conversion(rk\u001b[38;5;241m.\u001b[39mdtype):\n",
      "\u001b[1;31mValueError\u001b[0m: You are trying to merge on object and float64 columns for key 'gene'. If you wish to proceed you should use pd.concat"
     ]
    }
   ],
   "source": [
    "result = IntraTalker_analysis(anndataobject= \"LR2TF_test_run/anndata_object.h5ad\", arguments_list= {\"out_path\" : \"script_test\", \n",
    "                                                                                                    \"celltype\" : \"new_annotation\",\n",
    "                                                                                                    \"condition\" : \"protocol\", \n",
    "                                                                                                    \"organism\" : \"human\", \n",
    "                                                                                                    \"comparison_list\" : [[\"PMF,MF2\", \"control\"], [\"test1\", \"test2\"]], \n",
    "                                                                                                    \"logfc\" : \"0\",\n",
    "                                                                                                    \"pval\" : None, \n",
    "                                                                                                    \"num_cell_filter\": None,\n",
    "                                                                                                    \"reg\" : \"filterd_regulon.csv\", \n",
    "                                                                                                    \"tf_activities\" : \"decoupler_results.csv\", \n",
    "                                                                                                    \"plot\" : True,\n",
    "                                                                                                    \"decoupler_matrix_format\" : \"Python\"})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_node_type(df):\n",
    "    \n",
    "    df['gene_A'] = np.where(df['type_gene_A'] == 'Ligand', df['gene_A'] + '|L', df['gene_A'])\n",
    "    df['gene_A'] = np.where(df['type_gene_A'] == 'Receptor', df['gene_A'] + '|R', df['gene_A'])\n",
    "    df['gene_A'] = np.where(df['type_gene_A'] == 'Transcription Factor', df['gene_A'] + '|TF', df['gene_A'])\n",
    "    df['gene_B'] = np.where(df['type_gene_B'] == 'Ligand', df['gene_B'] + '|L', df['gene_B'])\n",
    "    df['gene_B'] = np.where(df['type_gene_B'] == 'Receptor', df['gene_B'] + '|R', df['gene_B'])\n",
    "    df['gene_B'] = np.where(df['type_gene_B'] == 'Transcription Factor', df['gene_B'] + '|TF', df['gene_B'])\n",
    "    return df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [],
   "source": [
    "def combine_LR_and_TF(tf_table, LR_prediction, out_path, condition, add_nodetype = False):\n",
    "\n",
    "  if isinstance(LR_prediction, pd.DataFrame):\n",
    "    lr_table = LR_prediction\n",
    "  else: \n",
    "    #fix this\n",
    "    lr_table = read_csv(LR_prediction)\n",
    "    lr_table.rownames = lr_table.columns[\"X\"]\n",
    "    lr_table.columns[\"X\"] = None\n",
    "\n",
    "  intra_connections = pd.DataFrame()\n",
    "  for celltype in np.unique([lr_table[\"source\"], lr_table[\"target\"]]):\n",
    "    lr_filtered_ligands = lr_table[lr_table[\"source\"] == celltype]\n",
    "    lr_filtered_receptors = lr_table[lr_table[\"target\"] == celltype]\n",
    "    lr_ligands = np.unique(lr_filtered_ligands[\"gene_A\"])\n",
    "    lr_receptors = np.unique(lr_filtered_receptors[\"gene_B\"])\n",
    "    \n",
    "    tf_table_receptors = tf_table[(tf_table[\"target\"] == celltype) & (tf_table[\"type_gene_A\"] == \"Receptor\")]\n",
    "    tf_table_ligands = tf_table[(tf_table[\"source\"] == celltype) & (tf_table[\"type_gene_B\"] == \"Ligand\")]\n",
    "\n",
    "    tf_receptor_interactions =  tf_table_receptors[tf_table_receptors[\"gene_A\"].isin(lr_receptors)]\n",
    "    tf_ligand_interactions = tf_table_ligands[tf_table_ligands[\"gene_B\"].isin(lr_ligands)]\n",
    "\n",
    "    intra_connections = pd.concat([intra_connections, tf_receptor_interactions, tf_ligand_interactions])\n",
    "  intra_connections[\"all_pair\"] = (intra_connections[\"source\"] + \"/\" \n",
    "                                    + intra_connections[\"gene_A\"] + \"/\"\n",
    "                                    + intra_connections[\"target\"] + \"/\"\n",
    "                                    + intra_connections[\"gene_B\"])\n",
    "    \n",
    "  intra_connections = intra_connections.drop_duplicates(subset=[\"all_pair\"])\n",
    "  intra_connections.drop(columns=[\"all_pair\"], inplace=True)\n",
    "\n",
    "  complete_interactions = pd.concat([intra_connections, lr_table])\n",
    "\n",
    "  if add_nodetype:\n",
    "    complete_interactions = add_node_type(complete_interactions)\n",
    "      \n",
    "  complete_interactions.to_csv((out_path + \"CrossTalkeR_input_\" + condition + \".csv\"), index=0)\n",
    "  return(complete_interactions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [],
   "source": [
    "def combine_LR_and_TF_unfiltered(tf_table, LR_prediction, out_path, condition, add_nodetype = False):\n",
    "\n",
    "  if isinstance(LR_prediction, pd.DataFrame):\n",
    "    lr_table = LR_prediction\n",
    "  else: \n",
    "    #fix this\n",
    "    lr_table = read_csv(LR_prediction)\n",
    "    lr_table.rownames = lr_table.columns[\"X\"]\n",
    "    lr_table.columns[\"X\"] = None\n",
    "\n",
    "\n",
    "  complete_interactions = pd.concat([tf_table, lr_table])\n",
    "\n",
    "  if add_nodetype:\n",
    "    complete_interactions = add_node_type(complete_interactions)\n",
    "      \n",
    "  complete_interactions.to_csv((out_path + \"CrossTalkeR_input_\" + condition + \".csv\"), index=0)\n",
    "  return(complete_interactions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [],
   "source": [
    "#ask for list with complexes to try?\n",
    "\n",
    "def combine_LR_and_TF_complexes(tf_table, LR_prediction, out_path, condition, add_nodetype = False):\n",
    "\n",
    "  if isinstance(LR_prediction, pd.DataFrame):\n",
    "    lr_table = LR_prediction\n",
    "  else: \n",
    "    #fix this\n",
    "    lr_table = read_csv(LR_prediction)\n",
    "    lr_table.rownames = lr_table.columns[\"X\"]\n",
    "    lr_table.drop(columns=[\"X\"], inplace=True)\n",
    "\n",
    "  intra_connections = pd.DataFrame()\n",
    "  for celltype in np.unique([lr_table[\"source\"], lr_table[\"target\"]]):\n",
    "    lr_filtered_ligands = lr_table[lr_table[\"source\"] == celltype]\n",
    "    lr_filtered_receptors = lr_table[lr_table[\"target\"] == celltype]\n",
    "    lr_ligands = np.unique(lr_filtered_ligands[\"gene_A\"])\n",
    "    lr_receptors = np.unique(lr_filtered_receptors[\"gene_B\"])\n",
    "\n",
    "    lr_receptors = pd.Series(lr_receptors)\n",
    "    contains_complex = lr_receptors.str.contains(\"_\", na=False)\n",
    "    \n",
    "    R_with_complex = lr_receptors[contains_complex]\n",
    "    R_without_complex = lr_receptors[(~contains_complex)]\n",
    "  \n",
    "    tf_table_receptors = tf_table[(tf_table[\"target\"] == celltype) & (tf_table[\"type_gene_A\"] == \"Receptor\")]\n",
    " \n",
    "    tf_receptor_interactions =  tf_table_receptors[tf_table_receptors[\"gene_A\"].isin(R_without_complex)]\n",
    "    \n",
    "    complex_df = pd.DataFrame()\n",
    "    if len(R_with_complex) > 0:\n",
    "      for complex in R_with_complex:\n",
    "        receptors = complex.split(\"_\")\n",
    "        R_TF_with_complex = tf_table_receptors[tf_table_receptors[\"gene_A\"].isin(receptors)]\n",
    "    \n",
    "        if len(R_TF_with_complex) == 0:\n",
    "          continue\n",
    "        \n",
    "        R_TF_with_complex.drop_duplicates()\n",
    "        R_TF_with_complex[\"gene_A\"] = complex\n",
    "        \n",
    "        complex_df = pd.concat([complex_df, R_TF_with_complex])\n",
    "\n",
    "      complex_df.drop_duplicates()\n",
    "\n",
    "    tf_receptor_interactions = pd.concat([tf_receptor_interactions, complex_df])\n",
    "    print(tf_receptor_interactions)\n",
    "    \n",
    "    tf_table_ligands = tf_table[(tf_table[\"source\"] == celltype) & (tf_table[\"type_gene_B\"] == \"Ligand\")]\n",
    "\n",
    "    \n",
    "    tf_ligand_interactions = tf_table_ligands[tf_table_ligands[\"gene_B\"].isin(lr_ligands)]\n",
    "\n",
    "    intra_connections = pd.concat([intra_connections, tf_receptor_interactions, tf_ligand_interactions])\n",
    "  intra_connections[\"all_pair\"] = (intra_connections[\"source\"] + \"/\" \n",
    "                                    + intra_connections[\"gene_A\"] + \"/\"\n",
    "                                    + intra_connections[\"target\"] + \"/\"\n",
    "                                    + intra_connections[\"gene_B\"])\n",
    "  print(intra_connections)\n",
    "  intra_connections = intra_connections.drop_duplicates(subset=[\"all_pair\"])\n",
    "  intra_connections.drop(columns=[\"all_pair\"], inplace=True)\n",
    "\n",
    "  complete_interactions = pd.concat([intra_connections, lr_table])\n",
    "\n",
    "  if add_nodetype:\n",
    "    complete_interactions = add_node_type(complete_interactions)\n",
    "      \n",
    "  complete_interactions.to_csv((out_path + \"CrossTalkeR_input_\" + condition + \".csv\"), index=0)\n",
    "  return(complete_interactions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#WINDOWS\n",
    "table_ctr = pd.read_csv(\"LR2TF_test_run\\\\CTR_LR_complex_edited.csv\")\n",
    "table_exp = pd.read_csv(\"LR2TF_test_run\\\\EXP_LR.csv\")\n",
    "\n",
    "ctr_input = combine_LR_and_TF_complexes(result.CTR_input_cluster[\"control\"], table_ctr, \"script_test/\", \"control\")\n",
    "exp_input = combine_LR_and_TF(result.CTR_input_cluster[\"PMF,MF2\"], table_exp, \"script_test/\", \"PMF_MF2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#LINUX\n",
    "table_ctr = pd.read_csv(\"/home/larissa/Documents/LR2TF_HiWi/LR2TF_test_run/CTR_LR.csv\")\n",
    "table_exp = pd.read_csv(\"/home/larissa/Documents/LR2TF_HiWi/LR2TF_test_run/EXP_LR.csv\")\n",
    "\n",
    "ctr_input = combine_LR_and_TF(result.CTR_input_cluster[\"control\"], table_ctr, \"script_test/\", \"control\")\n",
    "exp_input = combine_LR_and_TF(result.CTR_input_cluster[\"PMF,MF2\"], table_exp, \"script_test/\", \"PMF_MF2\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
