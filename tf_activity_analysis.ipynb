{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import anndata as ad\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import scanpy as sc\n",
    "import decoupler as dc\n",
    "import os\n",
    "import re\n",
    "import statistics\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "#import pyreadr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def validate_input_arguments (arguments_list):\n",
    "    if arguments_list[\"out_path\"] is None:\n",
    "        print(\"Please provide an output path\")\n",
    "    elif arguments_list[\"out_path\"][-1] != \"/\":\n",
    "        arguments_list[\"out_path\"] = arguments_list[\"out_path\"] + \"/\"\n",
    "\n",
    "    if arguments_list[\"celltype\"] is None:\n",
    "        print(\"Please provide the name of the metadata field containing cell type annotations\")\n",
    "\n",
    "    if arguments_list[\"condition\"] is None:\n",
    "        print(\"Please provide the name of the metadata field containing condition annotations\")\n",
    "\n",
    "    if arguments_list[\"organism\"] is None:\n",
    "        arguments_list[\"organism\"] = \"human\"\n",
    "\n",
    "    if arguments_list[\"comparison_list\"] is None:\n",
    "        arguments_list[\"comparison_list\"] = np.nan\n",
    "\n",
    "    if arguments_list[\"logfc\"] is None:\n",
    "        arguments_list[\"logfc\"] = 0.0\n",
    "\n",
    "    if arguments_list [\"pval\"] is None:\n",
    "        arguments_list[\"pval\"] = 0.05\n",
    "\n",
    "    if arguments_list[\"reg\"] is None:\n",
    "        arguments_list[\"reg\"] = load_dorothea_regulon(arguments_list[\"organism\"])\n",
    "\n",
    "    elif isinstance(arguments_list[\"reg\"], str):\n",
    "        arguments_list[\"reg\"] = pd.read_csv(arguments_list[\"reg\"], index_col=0)\n",
    "        arguments_list[\"reg\"] = pd.DataFrame.rename(arguments_list[\"reg\"], columns={\"source\" : \"tf\"})\n",
    "\n",
    "    if not \"tf\" in arguments_list[\"reg\"] and \"target\" in arguments_list[\"reg\"] and \"weight\"in arguments_list[\"reg\"]:\n",
    "        raise Exception(\"Not all necessary columns found in regulon table! Please make sure that the regulon has the columns source, target and weight!\")\n",
    "    \n",
    " \n",
    "   \n",
    "    return(arguments_list)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def AverageExpression(sub_object, celltype = None, name_iterable = None, outpath = None):\n",
    "    gene_ids = sub_object.var.index.values\n",
    "    #cluster line even necessary if not returned?\n",
    "    #clusters = anndataobject.obs[celltype].cat.categories\n",
    "    obs = sub_object[:,gene_ids].X.toarray()\n",
    "    obs = np.expm1(obs)\n",
    "    avg_df = pd.DataFrame(obs,columns=gene_ids,index= sub_object.obs[celltype])\n",
    "    avg_df = avg_df.groupby(level=0, observed=False).mean()\n",
    "    avg_df.T.to_csv(outpath + name_iterable + \"_average_gene_expression_by_cluster_exp.csv\")\n",
    "\n",
    "    return avg_df.T\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def eval_pval(p_val):\n",
    "    p_val = float(p_val)\n",
    "    if p_val < 0.001: \n",
    "      txt = \"***\"\n",
    "    elif p_val < 0.01: \n",
    "      txt = \"**\"\n",
    "    elif p_val < 0.05: \n",
    "      txt = \"*\"\n",
    "    else:\n",
    "      txt = \"ns\"\n",
    "    return(txt)\n",
    "\n",
    "\n",
    "def eval_log_fc_tag(log_fc):\n",
    "    if log_fc >= 1.0: \n",
    "      txt = \"***\"\n",
    "    elif log_fc > 0.5: \n",
    "      txt = \"**\"\n",
    "    elif log_fc > 0.0: \n",
    "      txt = \"*\"\n",
    "    else:\n",
    "      txt = \"ns\"\n",
    "    return(txt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_unfiltered_tf_scores(tf_scores_df, condition, celltype, out_path):   \n",
    "    summarized_tf_scores_df = tf_scores_df.groupby(celltype, observed = True).mean().T\n",
    "    #tf_scores_df.groupby(celltype, observed = True).apply(display)\n",
    "    #agg([\"mean\", \"var\"])\n",
    "    summarized_tf_scores_df.to_csv(out_path + \"/unfiltered_tf_scores_\" + condition + \".csv\")\n",
    "    return summarized_tf_scores_df\n",
    "\n",
    "#np.var() returns a value that is different from R's var(), whereas statistics.variance() is the same as R's var()\n",
    "def save_variable_tf_score(filtered_summarized_tf_scores_df, condition, out_path, plot):\n",
    "    filtered_summarized_tf_scores_df[\"var\"] = filtered_summarized_tf_scores_df.apply(statistics.variance, axis=1).unique()\n",
    "    filtered_summarized_tf_scores_df.to_csv(out_path + \"/variable_tf_scores_\" + condition + \".csv\")\n",
    "\n",
    "    if plot:\n",
    "        top_variable_tfs = filtered_summarized_tf_scores_df.sort_values(\"var\", ascending=False).head(n=20).drop(columns=\"var\")\n",
    "        fig, ax = plt.subplots(figsize=(8,7))   \n",
    "        ax = sns.heatmap(top_variable_tfs, cmap=\"vlag\", center=0, vmin=top_variable_tfs.min(axis=None), cbar_kws={\"label\": \"z-score\"})\n",
    "        ax.set(xlabel=\"Cell Type\", ylabel=\"Transcription Factor\")\n",
    "        ax.get_figure()\n",
    "        plt.savefig(out_path + \"/tf_activity_top20_variable_\" + condition + \".pdf\")\n",
    "        plt.close()\n",
    "\n",
    "    filtered_summarized_tf_scores_df_var = filtered_summarized_tf_scores_df\n",
    "    return filtered_summarized_tf_scores_df_var\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_tf_activity(filtered_summarized_tf_scores_df, tag_mapping, condition, out_path):\n",
    "    filtered_summarized_tf_scores_df = filtered_summarized_tf_scores_df.drop(columns=\"var\")\n",
    "    sns.clustermap(filtered_summarized_tf_scores_df, cbar_kws={\"label\": \"z-score\"}, figsize=(8,7), cmap=\"vlag\", center=0, yticklabels=False)\n",
    "    plt.savefig(out_path + \"/tf_activity_compressed_\" + condition + \".pdf\")\n",
    "    plt.close()\n",
    "\n",
    "    sns.clustermap(filtered_summarized_tf_scores_df, cbar_kws={\"label\": \"z-score\"}, figsize=(8,50), cmap=\"vlag\", center=0, annot= tag_mapping, fmt=\"\")\n",
    "    plt.savefig(out_path + \"/tf_activity_\" + condition + \".pdf\")\n",
    "    plt.close()\n",
    "\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "def map_z_value_filtered(filtered_summarized_tf_scores_df, anndataobject_markers):\n",
    "    genes = []\n",
    "    clusters = []\n",
    "    z_scores = []  \n",
    "\n",
    "    anndataobject_markers = anndataobject_markers.set_index(\"gene\")\n",
    "    #print(filtered_summarized_tf_scores_df)\n",
    "    \n",
    "    for i in range(len(anndataobject_markers.index)):\n",
    "        a = anndataobject_markers.index[i]\n",
    "        for j in range(len(filtered_summarized_tf_scores_df.index)):\n",
    "            b = filtered_summarized_tf_scores_df.index[j]\n",
    "            if a == b:\n",
    "                c = anndataobject_markers.columns.get_loc(\"cluster\")\n",
    "                cluster = anndataobject_markers.iloc[i, c]\n",
    "                gene_rows = filtered_summarized_tf_scores_df.iloc[j]\n",
    "                if isinstance(gene_rows, pd.Series):\n",
    "                    gene_rows = gene_rows.to_frame().T\n",
    "\n",
    "                for _, gene_row in gene_rows.iterrows():\n",
    "                     score = gene_row[cluster]\n",
    "                     genes.append(a)\n",
    "                     clusters.append(cluster)\n",
    "                     z_scores.append(score)\n",
    "\n",
    "    z_score_df = pd.DataFrame({\n",
    "        'gene': genes,\n",
    "        'cluster': clusters,\n",
    "        'z_score': z_scores\n",
    "    })\n",
    "\n",
    "    return z_score_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [],
   "source": [
    "#not per cluster but cluster and pval etc need to be added to csv (check against specific marker csv from lr2tf test run in R)\n",
    "\n",
    "def get_significant_tfs_single(tf_activities_sub, celltype, condition, out_path, pval, logfc, name, plot):\n",
    "    \n",
    "    #does not work if condition is None\n",
    "    renamed_condition = condition.replace(\",\", \"_\")\n",
    "    name = name.replace(\",\", \"_\")\n",
    "\n",
    "    single_result_path = out_path + renamed_condition \n",
    "    if not os.path.isdir(single_result_path):\n",
    "        os.mkdir(single_result_path)\n",
    "\n",
    "    tf_activities_scaled = sc.pp.scale(tf_activities_sub, copy= True)\n",
    "\n",
    "    #tf_activities_sub = sc.pp.normalize_total(tf_activities_scaled, copy=True)\n",
    "    #tf_activities_sub = sc.pp.log1p(tf_activities_sub, copy=True) \n",
    "    # \"warning: seems to be already log transformed\"\n",
    "\n",
    "    number_of_clusters = len(tf_activities_sub.obs[\"new_annotation\"].cat.categories) \n",
    "\n",
    "\n",
    "    sc.tl.rank_genes_groups(tf_activities_sub, groupby= \"new_annotation\", reference=\"rest\", method=\"wilcoxon\", key_added=\"wilcoxon_markers\", corr_method= \"bonferroni\")\n",
    "    #sc.tl.filter_rank_genes_groups(anndataobject, min_in_group_fraction=0, key=\"wilcoxon_markers\", key_added= \"wilcoxon_markers_filtered\")\n",
    "    \n",
    "\n",
    "    sc.tl.rank_genes_groups(tf_activities_sub, groupby= \"new_annotation\", reference=\"rest\", method=\"t-test_overestim_var\", key_added=\"t_test_overestim_var_markers\", corr_method= \"bonferroni\" )\n",
    "    #sc.tl.filter_rank_genes_groups(anndataobject, min_in_group_fraction=0, key=\"t_test_overestim_var_markers\", key_added=\"t_test_overestim_filtered\")\n",
    "\n",
    "\n",
    "    result1 = tf_activities_sub.uns['wilcoxon_markers']\n",
    "    groups = result1['names'].dtype.names\n",
    "    anndataobject_markers = pd.DataFrame(\n",
    "    {group + '_' + key[:1]: result1[key][group]\n",
    "    for group in groups for key in ['names','logfoldchanges','pvals','pvals_adj']})\n",
    "\n",
    "    result2 = tf_activities_sub.uns['t_test_overestim_var_markers']\n",
    "    groups = result2['names'].dtype.names\n",
    "    anndataobject_markers = pd.DataFrame(\n",
    "    {group + '_' + key[:1]: result2[key][group]\n",
    "    for group in groups for key in ['names','logfoldchanges','pvals','pvals_adj']})\n",
    "\n",
    "    anndataobject_markers_wilcoxon = sc.get.rank_genes_groups_df(tf_activities_sub, group = None, log2fc_min=0, key=\"wilcoxon_markers\")\n",
    "    \n",
    "    anndataobject_markers_wilcoxon.rename(columns={\"names\":\"gene\", \"group\": \"cluster\"}, inplace=True)\n",
    "    \n",
    "    #documentation says this won't update the main dataframe but will only overwrite a copy in future pandas versions (after v3)\n",
    "    anndataobject_markers_wilcoxon[\"tag\"] = None\n",
    "    anndataobject_markers_wilcoxon[\"log_fc_tag\"] = None\n",
    "    for i in range(len(anndataobject_markers_wilcoxon[\"pvals_adj\"])):\n",
    "         anndataobject_markers_wilcoxon[\"tag\"].iloc[i,] = eval_pval(anndataobject_markers_wilcoxon[\"pvals_adj\"].iloc[i,])\n",
    "         anndataobject_markers_wilcoxon[\"log_fc_tag\"].iloc[i,] = eval_log_fc_tag(anndataobject_markers_wilcoxon[\"logfoldchanges\"].iloc[i,])\n",
    "     \n",
    "\n",
    "    anndataobject_markers_wilcoxon.to_csv(single_result_path + \"/\" + name + \"_specific_markers_wilcoxon_test.csv\",index=0)\n",
    "\n",
    "    anndataobject_markers_t_over = sc.get.rank_genes_groups_df(tf_activities_sub, group = None, log2fc_min=0, key=\"t_test_overestim_var_markers\")\n",
    " \n",
    "    anndataobject_markers_t_over.rename(columns={\"names\":\"gene\", \"group\": \"cluster\"}, inplace=True)\n",
    "\n",
    "    anndataobject_markers_t_over[\"tag\"] = None\n",
    "    anndataobject_markers_t_over[\"log_fc_tag\"] = None\n",
    "    for i in range(len(anndataobject_markers_t_over[\"pvals_adj\"])):\n",
    "         anndataobject_markers_t_over[\"tag\"].iloc[i,] = eval_pval(anndataobject_markers_t_over[\"pvals_adj\"].iloc[i,])\n",
    "         anndataobject_markers_t_over[\"log_fc_tag\"].iloc[i,] = eval_pval(anndataobject_markers_t_over[\"logfoldchanges\"].iloc[i,])\n",
    "\n",
    "    anndataobject_markers_t_over.to_csv(single_result_path + \"/\" + name + \"_specific_markers_t_test_overestim_test.csv\",index=0)\n",
    "\n",
    "   #tag mapping wilcoxon\n",
    "    tag_mapping_wilcox = anndataobject_markers_wilcoxon[[\"gene\", \"tag\", \"log_fc_tag\", \"cluster\", \"pvals_adj\", \"logfoldchanges\"]]\n",
    "    tag_mapping_wilcox = tag_mapping_wilcox[(tag_mapping_wilcox[\"pvals_adj\"] < float(pval)) & \n",
    "                              ((tag_mapping_wilcox[\"logfoldchanges\"] > float(logfc)) | \n",
    "                              (tag_mapping_wilcox[\"logfoldchanges\"] < -float(logfc)))]\n",
    "\n",
    "    tag_mapping_wilcox = tag_mapping_wilcox.pivot(index=\"gene\", columns=\"cluster\", values=\"tag\")\n",
    "    clusters = anndataobject_markers_wilcoxon[\"cluster\"].unique()\n",
    "\n",
    "    for cluster in clusters:\n",
    "        if cluster not in tag_mapping_wilcox.columns:\n",
    "            tag_mapping_wilcox[cluster] = np.nan\n",
    "\n",
    "    tag_mapping_wilcox.fillna(\"ns\", inplace=True)\n",
    "\n",
    "    tf_activities_scaled.obs_names = tf_activities_scaled.obs[celltype]\n",
    "    tf_scores_df = tf_activities_scaled.to_df()\n",
    "    tf_scores_df.columns.name = None\n",
    "    unfiltered_tf_scores = create_unfiltered_tf_scores(tf_scores_df, condition, celltype, single_result_path)\n",
    "   \n",
    "    #Filter to only include tfs that match the tag_mapping/are markers\n",
    "    col_num = tf_scores_df.columns.isin(tag_mapping_wilcox.index)  \n",
    "    filtered_tf_scores_df = tf_scores_df.loc[:, col_num] \n",
    "    \n",
    "    filtered_summarized_tf_scores_df = filtered_tf_scores_df.groupby(celltype, observed = False).mean().T\n",
    "    filtered_summarized_tf_scores_df.index.name = \"gene\"\n",
    "    filtered_summarized_tf_scores_df.to_csv(f'{single_result_path}/tf_scores_{condition}.csv')\n",
    "    tf_scores_variable_table = save_variable_tf_score(filtered_summarized_tf_scores_df, condition, single_result_path, plot)\n",
    "\n",
    "    if plot:\n",
    "        plot_tf_activity(filtered_summarized_tf_scores_df, tag_mapping_wilcox, condition, single_result_path)\n",
    "    \n",
    "    #filtered_summarized_tf_scores_df.index = re.sub((\".,\"), \"_\", filtered_summarized_tf_scores_df.index)\n",
    "    anndataobject_markers_wilcoxon_merged = anndataobject_markers_wilcoxon.merge(map_z_value_filtered(filtered_summarized_tf_scores_df, anndataobject_markers_wilcoxon),  on=['gene', 'cluster'], how='inner')\n",
    "    anndataobject_markers_wilcoxon_merged = anndataobject_markers_wilcoxon_merged[anndataobject_markers_wilcoxon_merged.tag != \"ns\"]\n",
    "    anndataobject_markers_wilcoxon_merged.dropna(inplace=True)\n",
    "    res_wilcoxon = anndataobject_markers_wilcoxon_merged[[\"gene\",\"tag\", \"cluster\", \"z_score\"]]\n",
    "\n",
    "    #anndataobject_markers_t_over_merged = anndataobject_markers_t_over.merge(map_z_value_filtered(filtered_summarized_tf_scores_df, anndataobject_markers_t_over),  on=['gene', 'cluster'], how='inner')\n",
    "    #anndataobject_markers_t_over_merged = anndataobject_markers_t_over_merged[anndataobject_markers_t_over_merged.tag != \"ns\"]\n",
    "    #anndataobject_markers_t_over_merged.dropna(inplace=True)\n",
    "    #res_t_test = anndataobject_markers_t_over[[\"gene\",\"tag\", \"cluster\", \"z_score\"]]\n",
    "\n",
    "    res_wilcoxon.to_csv(single_result_path + \"/\" + name + \"_significant_markers_wilcoxon.csv\", index=0)\n",
    "    #res_t_test.to_csv(single_result_path + \"/\" + name + \"_significant_markers_t_test.csv\", index=0)\n",
    "\n",
    "    \n",
    "\n",
    "     #//TODO: \n",
    "    #delete one variant and put test type as a variable\n",
    "\n",
    "    return res_wilcoxon#, res_t_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [],
   "source": [
    "#check if it's okay to not pre set the column type as string or float (maybe no problem in python but was problem in r)\n",
    "\n",
    "def create_empty_CTR_dataframe():\n",
    "  \n",
    "  empty_df = pd.DataFrame(\n",
    "    columns=[\n",
    "    \"source\",\n",
    "    \"target\",\n",
    "    \"gene_A\",\n",
    "    \"gene_B\",\n",
    "    \"type_gene_A\",\n",
    "    \"type_gene_B\",\n",
    "    \"MeanLR\"\n",
    "    ])\n",
    "  \n",
    "  return(empty_df)\n",
    "\n",
    "\n",
    "def add_entry_to_CTR_dataframe(source, target, gene_A, gene_B, type_gene_A, type_gene_B, MeanLR):\n",
    "  df = pd.DataFrame(\n",
    "      source,\n",
    "      target,\n",
    "      gene_A,\n",
    "      gene_B,\n",
    "      type_gene_A,\n",
    "      type_gene_B,\n",
    "      MeanLR)\n",
    "\n",
    "  return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_CrossTalkeR_input(tf_activities, gene_expression, regulon = None):\n",
    "\n",
    "  #tf_activities[\"cluster\"] = \"Neural\"\n",
    "\n",
    "  ligands = pd.read_csv(\"ligands_human.csv\")\n",
    "  R2TF = pd.read_csv(\"rtf_db.csv\")\n",
    "\n",
    "  sorted_regulon = regulon[[\"tf\", \"target\"]]\n",
    "  sorted_regulon.rename(columns={\"target\" : \"targets\"})\n",
    "  sorted_regulon = sorted_regulon.set_index(\"tf\")\n",
    "\n",
    "  output_df = create_empty_CTR_dataframe()\n",
    "\n",
    "  for row in range(len((tf_activities))):\n",
    "\n",
    "    r_tf = create_empty_CTR_dataframe()\n",
    "    tf_l = create_empty_CTR_dataframe()\n",
    "\n",
    "  #if (tf_activities[\"z_score\"].iloc[row] > 0):\n",
    "    tf_var = str(tf_activities[\"gene\"].iloc[row])\n",
    "    if tf_var in sorted_regulon.index:\n",
    "      targets = sorted_regulon.loc[tf_var]\n",
    "    if tf_var in R2TF.index:\n",
    "      receptors = R2TF.loc[tf_var]\n",
    "    tf_ligands = np.intersect1d(targets, ligands)\n",
    "  \n",
    "\n",
    "    #expressed = False\n",
    "    #if ligand in gene_expression.index:\n",
    "    #  ex_value = gene_expression.loc[ligand, \"Neural\"]\n",
    "    #  if (ex_value != 0):\n",
    "    #    expressed = True\n",
    "        \n",
    "    #print(tf_activities.iloc[row[]])\n",
    "    #if (expressed == True):\n",
    "    #  df_list_l = list[tf_activities.iloc[row, 2],\n",
    "    #                                         tf_activities.iloc[row, 2],\n",
    "    #                                         tf_activities.iloc[row, 0],\n",
    "    #                                         ligand,\n",
    "    #                                         \"Transcription Factor\",\n",
    "    #                                         \"Ligand\",\n",
    "    #                                        tf_activities.iloc[row, 3]]\n",
    "      \n",
    "    #if (len(receptors) > 0):\n",
    "    #   for receptor in receptors:\n",
    "    #     df_list_r = list[tf_activities.iloc[row, 2],\n",
    "    #                                     tf_activities.iloc[row, 2],\n",
    "    #                                     receptor,\n",
    "    #                                     tf_activities.iloc[row, 0],\n",
    "    #                                     'Receptor',\n",
    "    #                                     'Transcription Factor',\n",
    "     #                                    tf_activities.iloc[row, 3]]\n",
    "   \n",
    "#tf_l = pd.DataFrame(df_list_l, columns=[\"source\", \"target\", \"gene_A\", \"gene_B\", \"type_gene_A\", \"type_gene_B\", \"MeanLR\"])\n",
    "#print(tf_l)\n",
    "#r_tf = pd.DataFrame(df_list_r)\n",
    "      \n",
    "  #    r_tf[\"gene_A\"] <- gsub(\"_\", \"+\", r_tf$gene_A, fixed = TRUE)\n",
    "   #   r_tf[\"gene_B\"] <- gsub(\"_\", \"+\", r_tf$gene_B, fixed = TRUE)\n",
    "   #   tf_l[\"gene_A\"] <- gsub(\"_\", \"+\", tf_l$gene_A, fixed = TRUE)\n",
    "   #   tf_l[\"gene_B\"] <- gsub(\"_\", \"+\", tf_l$gene_B, fixed = TRUE)\n",
    "\n",
    "   #   output_df = pd.concat(output_df, r_tf)\n",
    "   #   output_df = pd.concat(output_df, tf_l)\n",
    "\n",
    "  #return output_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyreadr\n",
    "ligands_readin = pyreadr.read_r(\"ligands_human.rda\")\n",
    "ligands = ligands_readin[\"ligands_human\"]\n",
    "ligands.to_csv(\"ligands_human.csv\", index=False)\n",
    "\n",
    "rtf_readin = pyreadr.read_r(\"RTF_DB_2.rda\") \n",
    "rtf_db = rtf_readin[\"RTF_DB_2\"]\n",
    "rtf_db.to_csv(\"rtf_db.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [],
   "source": [
    "#ignore extra tfs from decoupler while writing script \n",
    "\n",
    "def tf_activity_analysis (anndataobject, arguments_list = None):\n",
    "    \n",
    "    if (isinstance(anndataobject, str)):\n",
    "        anndataobject = ad.read_h5ad(anndataobject)\n",
    "\n",
    "    arguments_list = validate_input_arguments(arguments_list)\n",
    "\n",
    "    if not os.path.isdir(arguments_list[\"out_path\"]):\n",
    "        os.mkdir(arguments_list[\"out_path\"])\n",
    "        tf_path = arguments_list[\"out_path\"] + \"TF_results/\"\n",
    "        os.mkdir(tf_path)\n",
    "    else:\n",
    "        tf_path = arguments_list[\"out_path\"] + \"TF_results/\"\n",
    "\n",
    "    #rename the arguments inserted into argument list (eg protocol to condition)(unfinished)\n",
    "    condition = anndataobject.obs[arguments_list[\"condition\"]]\n",
    "\n",
    "    #checks for tf activity csv, if nothing there, runs decoupler\n",
    "    if isinstance(arguments_list[\"tf_activities\"], str):\n",
    "         tf_activities = ad.read_csv(arguments_list[\"tf_activities\"])\n",
    "         #print(tf_activities.obs.index)\n",
    "         tf_activities.obs = anndataobject.obs.reindex(tf_activities.obs.index)\n",
    "         tf_activities.obsm = anndataobject.obsm\n",
    "         tf_activities.uns = anndataobject.uns\n",
    "    elif arguments_list[\"tf_activities\"] is None:\n",
    "         dc.run_ulm(mat = anndataobject, net = (arguments_list[\"reg\"]), source ='tf', target ='target', weight ='weight', verbose = True, use_raw = False)\n",
    "         tf_activities = anndataobject.obsm['ulm_estimate']\n",
    "         tf_activities.to_csv(\"decoupler_results_test.csv\")\n",
    "\n",
    "    #sets the stage for decision if single condition or comparison analysis is done\n",
    "\n",
    "    if not np.isnan(arguments_list[\"comparison_list\"]):\n",
    "        if len(arguments_list[\"comparison_list\"]) > 0 & len(anndataobject.obs[\"comparison_list\"]) < 2:\n",
    "            arguments_list[\"comparison_list\"] <- np.nan\n",
    "            print(\"Only one condition was found in the data, although a list of comparisons was provided. The analyses are performed only for the present condition!\")\n",
    "\n",
    "    #code for single condition  analysis\n",
    "\n",
    "    if np.isnan(arguments_list[\"comparison_list\"]):\n",
    "        result_list = []\n",
    "        gene_expression_list = []\n",
    "        CTR_cluster_list = []\n",
    "        intranet_cluster_list = []\n",
    "\n",
    "        #creates loop until after tf activity score\n",
    "        \n",
    "        for name_iterable in anndataobject.obs.protocol.unique():\n",
    "            sub_object = anndataobject[anndataobject.obs.protocol == name_iterable]\n",
    "            tf_activities_sub = tf_activities[tf_activities.obs.protocol == name_iterable]\n",
    "\n",
    "            sub_object_avg = AverageExpression(sub_object, name_iterable= name_iterable, celltype = arguments_list[\"celltype\"], outpath= arguments_list[\"out_path\"])\n",
    "            #check if its fine to only have the average expression as a dataframe and not as part of an anndata object\n",
    "\n",
    "            #check how sub object is returned by average expression (subobject.T) or rename return?\n",
    "            tf_activity_scores = get_significant_tfs_single(tf_activities_sub, celltype = arguments_list[\"celltype\"],condition = name_iterable, out_path= tf_path, pval = arguments_list[\"pval\"], logfc = arguments_list[\"logfc\"], name = name_iterable, plot = arguments_list[\"plot\"])\n",
    "\n",
    "            #turn them into dictionaries?\n",
    "            #result_list = result_list.append(tf_activity_scores)\n",
    "            #gene_expression_list[[name_iterable + \"_average_expression\"]] = sub_object_avg\n",
    "            \n",
    "            if (arguments_list[\"organism\"] == \"human\"):\n",
    "               CTR_cluster_list = generate_CrossTalkeR_input(tf_activity_scores,\n",
    "                                                                                 #gene_expression_list[[(name_iterable + \"_average_expression\")]],\n",
    "                                                                                 sub_object_avg,\n",
    "                                                                                 arguments_list[\"reg\"])\n",
    "    \n",
    "            #else:\n",
    "            #  CTR_cluster_list[[name_iterable]] = generate_CrossTalkeR_input_mouse(tf_activity_scores[[\"cluster\"]],\n",
    "            #                                                                     gene_expression_list[[(name_iterable + \"_average_expression\")]],\n",
    "            #                                                                     arguments_list[\"reg\"])\n",
    "              \n",
    "            #intranet_cluster_list[[name_iterable]] = generate_intracellular_network(tf_activity_scores[[\"cluster\"]],\n",
    "            #                                                          gene_expression_list[[paste0(name, \"_average_expression\")]],\n",
    "            #                                                          arguments_list$reg,\n",
    "            #                                                          arguments_list$organism)\n",
    "        #return(sub_object) #return tf when finished"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/larissa/miniconda3/envs/testpy/lib/python3.12/site-packages/scanpy/tools/_rank_genes_groups.py:640: ImplicitModificationWarning: Trying to modify attribute `._uns` of view, initializing view as actual.\n",
      "  adata.uns[key_added] = {}\n",
      "/home/larissa/miniconda3/envs/testpy/lib/python3.12/site-packages/scanpy/tools/_rank_genes_groups.py:455: RuntimeWarning: invalid value encountered in log2\n",
      "  self.stats[group_name, \"logfoldchanges\"] = np.log2(\n",
      "/home/larissa/miniconda3/envs/testpy/lib/python3.12/site-packages/scanpy/tools/_rank_genes_groups.py:455: RuntimeWarning: invalid value encountered in log2\n",
      "  self.stats[group_name, \"logfoldchanges\"] = np.log2(\n",
      "/home/larissa/miniconda3/envs/testpy/lib/python3.12/site-packages/scanpy/tools/_rank_genes_groups.py:455: RuntimeWarning: invalid value encountered in log2\n",
      "  self.stats[group_name, \"logfoldchanges\"] = np.log2(\n",
      "/home/larissa/miniconda3/envs/testpy/lib/python3.12/site-packages/scanpy/tools/_rank_genes_groups.py:455: RuntimeWarning: invalid value encountered in log2\n",
      "  self.stats[group_name, \"logfoldchanges\"] = np.log2(\n",
      "/home/larissa/miniconda3/envs/testpy/lib/python3.12/site-packages/scanpy/tools/_rank_genes_groups.py:455: RuntimeWarning: invalid value encountered in log2\n",
      "  self.stats[group_name, \"logfoldchanges\"] = np.log2(\n",
      "/home/larissa/miniconda3/envs/testpy/lib/python3.12/site-packages/scanpy/tools/_rank_genes_groups.py:455: RuntimeWarning: invalid value encountered in log2\n",
      "  self.stats[group_name, \"logfoldchanges\"] = np.log2(\n",
      "/home/larissa/miniconda3/envs/testpy/lib/python3.12/site-packages/scanpy/tools/_rank_genes_groups.py:455: RuntimeWarning: invalid value encountered in log2\n",
      "  self.stats[group_name, \"logfoldchanges\"] = np.log2(\n",
      "/home/larissa/miniconda3/envs/testpy/lib/python3.12/site-packages/scanpy/tools/_rank_genes_groups.py:455: RuntimeWarning: invalid value encountered in log2\n",
      "  self.stats[group_name, \"logfoldchanges\"] = np.log2(\n",
      "/home/larissa/miniconda3/envs/testpy/lib/python3.12/site-packages/scanpy/tools/_rank_genes_groups.py:455: RuntimeWarning: invalid value encountered in log2\n",
      "  self.stats[group_name, \"logfoldchanges\"] = np.log2(\n",
      "/home/larissa/miniconda3/envs/testpy/lib/python3.12/site-packages/scanpy/tools/_rank_genes_groups.py:455: RuntimeWarning: invalid value encountered in log2\n",
      "  self.stats[group_name, \"logfoldchanges\"] = np.log2(\n",
      "/tmp/ipykernel_2367669/244379999.py:50: FutureWarning: ChainedAssignmentError: behaviour will change in pandas 3.0!\n",
      "You are setting values through chained assignment. Currently this works in certain cases, but when using Copy-on-Write (which will become the default behaviour in pandas 3.0) this will never work to update the original DataFrame or Series, because the intermediate object on which we are setting values will behave as a copy.\n",
      "A typical example is when you are setting values in a column of a DataFrame, like:\n",
      "\n",
      "df[\"col\"][row_indexer] = value\n",
      "\n",
      "Use `df.loc[row_indexer, \"col\"] = values` instead, to perform the assignment in a single step and ensure this keeps updating the original `df`.\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "\n",
      "  anndataobject_markers_wilcoxon[\"tag\"].iloc[i,] = eval_pval(anndataobject_markers_wilcoxon[\"pvals_adj\"].iloc[i,])\n",
      "/tmp/ipykernel_2367669/244379999.py:50: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  anndataobject_markers_wilcoxon[\"tag\"].iloc[i,] = eval_pval(anndataobject_markers_wilcoxon[\"pvals_adj\"].iloc[i,])\n",
      "/tmp/ipykernel_2367669/244379999.py:51: FutureWarning: ChainedAssignmentError: behaviour will change in pandas 3.0!\n",
      "You are setting values through chained assignment. Currently this works in certain cases, but when using Copy-on-Write (which will become the default behaviour in pandas 3.0) this will never work to update the original DataFrame or Series, because the intermediate object on which we are setting values will behave as a copy.\n",
      "A typical example is when you are setting values in a column of a DataFrame, like:\n",
      "\n",
      "df[\"col\"][row_indexer] = value\n",
      "\n",
      "Use `df.loc[row_indexer, \"col\"] = values` instead, to perform the assignment in a single step and ensure this keeps updating the original `df`.\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "\n",
      "  anndataobject_markers_wilcoxon[\"log_fc_tag\"].iloc[i,] = eval_log_fc_tag(anndataobject_markers_wilcoxon[\"logfoldchanges\"].iloc[i,])\n",
      "/tmp/ipykernel_2367669/244379999.py:51: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  anndataobject_markers_wilcoxon[\"log_fc_tag\"].iloc[i,] = eval_log_fc_tag(anndataobject_markers_wilcoxon[\"logfoldchanges\"].iloc[i,])\n",
      "/tmp/ipykernel_2367669/244379999.py:63: FutureWarning: ChainedAssignmentError: behaviour will change in pandas 3.0!\n",
      "You are setting values through chained assignment. Currently this works in certain cases, but when using Copy-on-Write (which will become the default behaviour in pandas 3.0) this will never work to update the original DataFrame or Series, because the intermediate object on which we are setting values will behave as a copy.\n",
      "A typical example is when you are setting values in a column of a DataFrame, like:\n",
      "\n",
      "df[\"col\"][row_indexer] = value\n",
      "\n",
      "Use `df.loc[row_indexer, \"col\"] = values` instead, to perform the assignment in a single step and ensure this keeps updating the original `df`.\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "\n",
      "  anndataobject_markers_t_over[\"tag\"].iloc[i,] = eval_pval(anndataobject_markers_t_over[\"pvals_adj\"].iloc[i,])\n",
      "/tmp/ipykernel_2367669/244379999.py:63: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  anndataobject_markers_t_over[\"tag\"].iloc[i,] = eval_pval(anndataobject_markers_t_over[\"pvals_adj\"].iloc[i,])\n",
      "/tmp/ipykernel_2367669/244379999.py:64: FutureWarning: ChainedAssignmentError: behaviour will change in pandas 3.0!\n",
      "You are setting values through chained assignment. Currently this works in certain cases, but when using Copy-on-Write (which will become the default behaviour in pandas 3.0) this will never work to update the original DataFrame or Series, because the intermediate object on which we are setting values will behave as a copy.\n",
      "A typical example is when you are setting values in a column of a DataFrame, like:\n",
      "\n",
      "df[\"col\"][row_indexer] = value\n",
      "\n",
      "Use `df.loc[row_indexer, \"col\"] = values` instead, to perform the assignment in a single step and ensure this keeps updating the original `df`.\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "\n",
      "  anndataobject_markers_t_over[\"log_fc_tag\"].iloc[i,] = eval_pval(anndataobject_markers_t_over[\"logfoldchanges\"].iloc[i,])\n",
      "/tmp/ipykernel_2367669/244379999.py:64: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  anndataobject_markers_t_over[\"log_fc_tag\"].iloc[i,] = eval_pval(anndataobject_markers_t_over[\"logfoldchanges\"].iloc[i,])\n",
      "/tmp/ipykernel_2367669/244379999.py:81: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value 'ns' has dtype incompatible with float64, please explicitly cast to a compatible dtype first.\n",
      "  tag_mapping_wilcox.fillna(\"ns\", inplace=True)\n",
      "/home/larissa/.local/lib/python3.12/site-packages/anndata/_core/anndata.py:841: UserWarning: \n",
      "AnnData expects .obs.index to contain strings, but got values like:\n",
      "    ['Megakaryocyte', 'Fibroblast', 'MSC', 'Megakaryocyte', 'Megakaryocyte']\n",
      "\n",
      "    Inferred to be: categorical\n",
      "\n",
      "  names = self._prep_dim_index(names, \"obs\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "None\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/larissa/miniconda3/envs/testpy/lib/python3.12/site-packages/scanpy/tools/_rank_genes_groups.py:640: ImplicitModificationWarning: Trying to modify attribute `._uns` of view, initializing view as actual.\n",
      "  adata.uns[key_added] = {}\n",
      "/home/larissa/miniconda3/envs/testpy/lib/python3.12/site-packages/scanpy/tools/_rank_genes_groups.py:455: RuntimeWarning: invalid value encountered in log2\n",
      "  self.stats[group_name, \"logfoldchanges\"] = np.log2(\n",
      "/home/larissa/miniconda3/envs/testpy/lib/python3.12/site-packages/scanpy/tools/_rank_genes_groups.py:455: RuntimeWarning: invalid value encountered in log2\n",
      "  self.stats[group_name, \"logfoldchanges\"] = np.log2(\n",
      "/home/larissa/miniconda3/envs/testpy/lib/python3.12/site-packages/scanpy/tools/_rank_genes_groups.py:455: RuntimeWarning: invalid value encountered in log2\n",
      "  self.stats[group_name, \"logfoldchanges\"] = np.log2(\n",
      "/home/larissa/miniconda3/envs/testpy/lib/python3.12/site-packages/scanpy/tools/_rank_genes_groups.py:455: RuntimeWarning: invalid value encountered in log2\n",
      "  self.stats[group_name, \"logfoldchanges\"] = np.log2(\n",
      "/home/larissa/miniconda3/envs/testpy/lib/python3.12/site-packages/scanpy/tools/_rank_genes_groups.py:455: RuntimeWarning: invalid value encountered in log2\n",
      "  self.stats[group_name, \"logfoldchanges\"] = np.log2(\n",
      "/home/larissa/miniconda3/envs/testpy/lib/python3.12/site-packages/scanpy/tools/_rank_genes_groups.py:455: RuntimeWarning: invalid value encountered in log2\n",
      "  self.stats[group_name, \"logfoldchanges\"] = np.log2(\n",
      "/home/larissa/miniconda3/envs/testpy/lib/python3.12/site-packages/scanpy/tools/_rank_genes_groups.py:455: RuntimeWarning: invalid value encountered in log2\n",
      "  self.stats[group_name, \"logfoldchanges\"] = np.log2(\n",
      "/home/larissa/miniconda3/envs/testpy/lib/python3.12/site-packages/scanpy/tools/_rank_genes_groups.py:455: RuntimeWarning: invalid value encountered in log2\n",
      "  self.stats[group_name, \"logfoldchanges\"] = np.log2(\n",
      "/home/larissa/miniconda3/envs/testpy/lib/python3.12/site-packages/scanpy/tools/_rank_genes_groups.py:455: RuntimeWarning: invalid value encountered in log2\n",
      "  self.stats[group_name, \"logfoldchanges\"] = np.log2(\n",
      "/home/larissa/miniconda3/envs/testpy/lib/python3.12/site-packages/scanpy/tools/_rank_genes_groups.py:455: RuntimeWarning: invalid value encountered in log2\n",
      "  self.stats[group_name, \"logfoldchanges\"] = np.log2(\n",
      "/tmp/ipykernel_2367669/244379999.py:50: FutureWarning: ChainedAssignmentError: behaviour will change in pandas 3.0!\n",
      "You are setting values through chained assignment. Currently this works in certain cases, but when using Copy-on-Write (which will become the default behaviour in pandas 3.0) this will never work to update the original DataFrame or Series, because the intermediate object on which we are setting values will behave as a copy.\n",
      "A typical example is when you are setting values in a column of a DataFrame, like:\n",
      "\n",
      "df[\"col\"][row_indexer] = value\n",
      "\n",
      "Use `df.loc[row_indexer, \"col\"] = values` instead, to perform the assignment in a single step and ensure this keeps updating the original `df`.\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "\n",
      "  anndataobject_markers_wilcoxon[\"tag\"].iloc[i,] = eval_pval(anndataobject_markers_wilcoxon[\"pvals_adj\"].iloc[i,])\n",
      "/tmp/ipykernel_2367669/244379999.py:50: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  anndataobject_markers_wilcoxon[\"tag\"].iloc[i,] = eval_pval(anndataobject_markers_wilcoxon[\"pvals_adj\"].iloc[i,])\n",
      "/tmp/ipykernel_2367669/244379999.py:51: FutureWarning: ChainedAssignmentError: behaviour will change in pandas 3.0!\n",
      "You are setting values through chained assignment. Currently this works in certain cases, but when using Copy-on-Write (which will become the default behaviour in pandas 3.0) this will never work to update the original DataFrame or Series, because the intermediate object on which we are setting values will behave as a copy.\n",
      "A typical example is when you are setting values in a column of a DataFrame, like:\n",
      "\n",
      "df[\"col\"][row_indexer] = value\n",
      "\n",
      "Use `df.loc[row_indexer, \"col\"] = values` instead, to perform the assignment in a single step and ensure this keeps updating the original `df`.\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "\n",
      "  anndataobject_markers_wilcoxon[\"log_fc_tag\"].iloc[i,] = eval_log_fc_tag(anndataobject_markers_wilcoxon[\"logfoldchanges\"].iloc[i,])\n",
      "/tmp/ipykernel_2367669/244379999.py:51: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  anndataobject_markers_wilcoxon[\"log_fc_tag\"].iloc[i,] = eval_log_fc_tag(anndataobject_markers_wilcoxon[\"logfoldchanges\"].iloc[i,])\n",
      "/tmp/ipykernel_2367669/244379999.py:63: FutureWarning: ChainedAssignmentError: behaviour will change in pandas 3.0!\n",
      "You are setting values through chained assignment. Currently this works in certain cases, but when using Copy-on-Write (which will become the default behaviour in pandas 3.0) this will never work to update the original DataFrame or Series, because the intermediate object on which we are setting values will behave as a copy.\n",
      "A typical example is when you are setting values in a column of a DataFrame, like:\n",
      "\n",
      "df[\"col\"][row_indexer] = value\n",
      "\n",
      "Use `df.loc[row_indexer, \"col\"] = values` instead, to perform the assignment in a single step and ensure this keeps updating the original `df`.\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "\n",
      "  anndataobject_markers_t_over[\"tag\"].iloc[i,] = eval_pval(anndataobject_markers_t_over[\"pvals_adj\"].iloc[i,])\n",
      "/tmp/ipykernel_2367669/244379999.py:63: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  anndataobject_markers_t_over[\"tag\"].iloc[i,] = eval_pval(anndataobject_markers_t_over[\"pvals_adj\"].iloc[i,])\n",
      "/tmp/ipykernel_2367669/244379999.py:64: FutureWarning: ChainedAssignmentError: behaviour will change in pandas 3.0!\n",
      "You are setting values through chained assignment. Currently this works in certain cases, but when using Copy-on-Write (which will become the default behaviour in pandas 3.0) this will never work to update the original DataFrame or Series, because the intermediate object on which we are setting values will behave as a copy.\n",
      "A typical example is when you are setting values in a column of a DataFrame, like:\n",
      "\n",
      "df[\"col\"][row_indexer] = value\n",
      "\n",
      "Use `df.loc[row_indexer, \"col\"] = values` instead, to perform the assignment in a single step and ensure this keeps updating the original `df`.\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "\n",
      "  anndataobject_markers_t_over[\"log_fc_tag\"].iloc[i,] = eval_pval(anndataobject_markers_t_over[\"logfoldchanges\"].iloc[i,])\n",
      "/tmp/ipykernel_2367669/244379999.py:64: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  anndataobject_markers_t_over[\"log_fc_tag\"].iloc[i,] = eval_pval(anndataobject_markers_t_over[\"logfoldchanges\"].iloc[i,])\n",
      "/home/larissa/.local/lib/python3.12/site-packages/anndata/_core/anndata.py:841: UserWarning: \n",
      "AnnData expects .obs.index to contain strings, but got values like:\n",
      "    ['Neural', 'MSC', 'Megakaryocyte', 'Neural', 'Neural']\n",
      "\n",
      "    Inferred to be: categorical\n",
      "\n",
      "  names = self._prep_dim_index(names, \"obs\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "None\n"
     ]
    }
   ],
   "source": [
    "result = tf_activity_analysis(anndataobject= \"LR2TF_test_run/anndata_object.h5ad\", arguments_list= {\"out_path\" : \"script_test\", \"celltype\" : \"new_annotation\", \"condition\" : \"protocol\", \"organism\" : None, \"comparison_list\" : None, \"logfc\" : \"0\", \"pval\" : None, \"reg\" : \"filterd_regulon.csv\", \"tf_activities\" : \"decoupler_results.csv\", \"plot\" : True})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def csv_comparison (result_1, result_2, outpath, suffixes_df=(\"_py\", \"_r\")):\n",
    "    result1 = pd.read_csv(result_1)\n",
    "    result2 = pd.read_csv(result_2)\n",
    "\n",
    "\n",
    "    result1 = result1[result1[\"pvals_adj\"] < 0.05]\n",
    "    if \"p_val_adj\" in result2.columns:\n",
    "        result2 = result2[result2[\"p_val_adj\"] < 0.05]\n",
    "    else:\n",
    "        result2 = result2[result2[\"pvals_adj\"] < 0.05]\n",
    "\n",
    "    result1 = result1.rename(columns={\"names\": \"gene\", \"group\": \"cluster\"})\n",
    "    result2 = result2.rename(columns={\"names\": \"gene\", \"group\": \"cluster\"})\n",
    "\n",
    "\n",
    "    df_output_1 = pd.DataFrame()\n",
    "\n",
    "    for i in range(len(result1)):\n",
    "        a = result1[\"gene\"].iloc[i]\n",
    "        for j in range(len(result2)):\n",
    "            b = result2[\"gene\"].iloc[j]\n",
    "            if a == b:\n",
    "                df_output_1[i] = result1.iloc[i]\n",
    "            \n",
    "\n",
    "    df_output_1 = df_output_1.T\n",
    "\n",
    "    df_output_2 = pd.DataFrame()\n",
    "    for i in range(len(result2)):\n",
    "        a = result2[\"gene\"].iloc[i]\n",
    "        for j in range(len(result1)):\n",
    "            b = result1[\"gene\"].iloc[j]\n",
    "            if a == b:\n",
    "                df_output_2[i] = result2.iloc[i]\n",
    "\n",
    "\n",
    "    df_output_2 = df_output_2.T\n",
    "\n",
    "\n",
    "    df_output = pd.merge(df_output_1, df_output_2, on=\"gene\", suffixes=suffixes_df)\n",
    "\n",
    "    df_output_3 = pd.DataFrame()\n",
    "    for i in range(len(result1)):\n",
    "        a = result1[\"gene\"].iloc[i]\n",
    "        b = list(result2[\"gene\"])\n",
    "        if a not in b:\n",
    "            df_output_3[i] = result1.iloc[i]\n",
    "            \n",
    "    df_output_3 = df_output_3.T\n",
    "    df_output.rename(columns={\"Unnamed: 0\": \"gene_r\"}, inplace=True)\n",
    "    df_output_3.rename(columns={\"cluster\": \"cluster\" + suffixes_df[0]}, inplace=True)\n",
    "    if suffixes_df[0] == \"_py_wilcox\":\n",
    "        df_output_3.rename(columns={\"scores\": \"scores\" + suffixes_df[0], \"logfoldchanges\": \"logfoldchanges\" + suffixes_df[0], \"pvals\": \"pvals\" + suffixes_df[0], \"pvals_adj\": \"pvals_adj\" + suffixes_df[0]}, inplace=True)\n",
    "        df_output_4 = pd.DataFrame()\n",
    "        for i in range(len(result2)):\n",
    "            a = result2[\"gene\"].iloc[i]\n",
    "            b = list(result1[\"gene\"])\n",
    "            if a not in b:\n",
    "                df_output_4[i] = result2.iloc[i]\n",
    "        df_output_4 = df_output_4.T\n",
    "        df_output_4.rename(columns={\"cluster\": \"cluster\" + suffixes_df[1], \"scores\": \"scores\" + suffixes_df[1], \"logfoldchanges\": \"logfoldchanges\" + suffixes_df[1], \"pvals\": \"pvals\" + suffixes_df[1], \"pvals_adj\": \"pvals_adj\" + suffixes_df[1]}, inplace=True)\n",
    "        df_output_3 = pd.concat([df_output_3, df_output_4])\n",
    "        \n",
    "\n",
    "    df_output = pd.concat([df_output, df_output_3])\n",
    "\n",
    "    df_output.to_csv(outpath, index=0)\n",
    "    print(df_output_3.columns)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#WINDOWS VERSION\n",
    "\n",
    "#CONTROL\n",
    "#comparison python wilcoxon and r wilcoxon control\n",
    "csv_comparison(\"script_test\\\\TF_results\\\\control\\\\control_specific_markers_wilcoxon_test.csv\", \"LR2TF_test_run\\\\results\\\\TF_results\\\\control\\\\all_specificmarker__control.csv\",\n",
    "                \"tf_comparison_r_py\\\\py_wilcoxon_r_same_genes_control_filtered.csv\", suffixes_df=(\"_py\", \"_r\"))\n",
    "\n",
    "#comparison python t test and r wilcoxon control\n",
    "csv_comparison(\"script_test\\\\TF_results\\\\control\\\\control_specific_markers_t_test_overestim_test.csv\", \"LR2TF_test_run\\\\results\\\\TF_results\\\\control\\\\all_specificmarker__control.csv\",\n",
    "                \"tf_comparison_r_py\\\\py_t_test_r_same_genes_control_filtered.csv\", suffixes_df=(\"_py\", \"_r\"))\n",
    "\n",
    "# py wilcox vs py t test control\n",
    "\n",
    "csv_comparison(\"script_test\\\\TF_results\\\\control\\\\control_specific_markers_wilcoxon_test.csv\", \"script_test\\\\TF_results\\\\control\\\\control_specific_markers_t_test_overestim_test.csv\",\n",
    "                \"tf_comparison_r_py\\\\py_wilcox_py_t_test_same_genes_control_filtered.csv\", suffixes_df=(\"_py_wilcox\", \"_py_t_test\"))\n",
    "################################################################################################################################################################################################\n",
    "#PMF MF2\n",
    "#python wilcox vs r wilcox PMF MF2\n",
    "csv_comparison(\"script_test\\\\TF_results\\\\PMF_MF2\\\\PMF_MF2_specific_markers_wilcoxon_test.csv\", \"LR2TF_test_run\\\\results\\\\TF_results\\\\PMF_MF2\\\\all_specificmarker__PMF_MF2.csv\",\n",
    "                \"tf_comparison_r_py\\\\py_wilcoxon_r_same_genes_PMF_MF2_filtered.csv\", suffixes_df=(\"_py\", \"_r\"))\n",
    "\n",
    "#comparison python t test and r wilcoxon PMF MF2\n",
    "csv_comparison(\"script_test\\\\TF_results\\\\PMF_MF2\\\\PMF_MF2_specific_markers_t_test_overestim_test.csv\", \"LR2TF_test_run\\\\results\\\\TF_results\\\\PMF_MF2\\\\all_specificmarker__PMF_MF2.csv\",\n",
    "                \"tf_comparison_r_py\\\\py_t_test_r_same_genes_PMF_MF2_filtered.csv\", suffixes_df=(\"_py\", \"_r\"))\n",
    "\n",
    "csv_comparison(\"script_test\\\\TF_results\\\\PMF_MF2\\\\PMF_MF2_specific_markers_wilcoxon_test.csv\", \"script_test\\\\TF_results\\\\PMF_MF2\\\\PMF_MF2_specific_markers_t_test_overestim_test.csv\",\n",
    "                \"tf_comparison_r_py\\\\py_wilcox_py_t_test_same_genes_PMF_MF2_filtered.csv\", suffixes_df=(\"_py_wilcox\", \"_py_t_test\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#LINUX VERSION\n",
    "\n",
    "#CONTROL\n",
    "#comparison python wilcoxon and r wilcoxon control\n",
    "csv_comparison(\"script_test/TF_results/control/control_specific_markers_wilcoxon_test.csv\", \"LR2TF_test_run/results/TF_results/control/all_specificmarker__control.csv\",\n",
    "                \"tf_comparison_r_py//py_wilcoxon_r_same_genes_control_filtered.csv\", suffixes_df=(\"_py\", \"_r\"))\n",
    "\n",
    "#comparison python t test and r wilcoxon control\n",
    "csv_comparison(\"script_test/TF_results/control/control_specific_markers_t_test_overestim_test.csv\", \"LR2TF_test_run/results/TF_results/control/all_specificmarker__control.csv\",\n",
    "                \"tf_comparison_r_py/py_t_test_r_same_genes_control_filtered.csv\", suffixes_df=(\"_py\", \"_r\"))\n",
    "\n",
    "# py wilcox vs py t test control\n",
    "\n",
    "csv_comparison(\"script_test/TF_results/control/control_specific_markers_wilcoxon_test.csv\", \"script_test/TF_results/control/control_specific_markers_t_test_overestim_test.csv\",\n",
    "                \"tf_comparison_r_py/py_wilcox_py_t_test_same_genes_control_filtered.csv\", suffixes_df=(\"_py_wilcox\", \"_py_t_test\"))\n",
    "################################################################################################################################################################################################\n",
    "#PMF MF2\n",
    "#python wilcox vs r wilcox PMF MF2\n",
    "csv_comparison(\"script_test/TF_results/PMF_MF2/PMF_MF2_specific_markers_wilcoxon_test.csv\", \"LR2TF_test_run/results/TF_results/PMF_MF2/all_specificmarker__PMF_MF2.csv\",\n",
    "                \"tf_comparison_r_py/py_wilcoxon_r_same_genes_PMF_MF2_filtered.csv\", suffixes_df=(\"_py\", \"_r\"))\n",
    "\n",
    "#comparison python t test and r wilcoxon PMF MF2\n",
    "csv_comparison(\"script_test/TF_results/PMF_MF2/PMF_MF2_specific_markers_t_test_overestim_test.csv\", \"LR2TF_test_run/results/TF_results/PMF_MF2/all_specificmarker__PMF_MF2.csv\",\n",
    "                \"tf_comparison_r_py/py_t_test_r_same_genes_PMF_MF2_filtered.csv\", suffixes_df=(\"_py\", \"_r\"))\n",
    "\n",
    "csv_comparison(\"script_test/TF_results/PMF_MF2/PMF_MF2_specific_markers_wilcoxon_test.csv\", \"script_test/TF_results/PMF_MF2/PMF_MF2_specific_markers_t_test_overestim_test.csv\",\n",
    "                \"tf_comparison_r_py/py_wilcox_py_t_test_same_genes_PMF_MF2_filtered.csv\", suffixes_df=(\"_py_wilcox\", \"_py_t_test\"))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
