{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import anndata as ad\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import scanpy as sc\n",
    "import decoupler as dc\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def validate_input_arguments (arguments_list):\n",
    "    if arguments_list[\"out_path\"] is None:\n",
    "        print(\"Please provide an output path\")\n",
    "    elif arguments_list[\"out_path\"][-1] != \"/\":\n",
    "        arguments_list[\"out_path\"] = arguments_list[\"out_path\"] + \"/\"\n",
    "\n",
    "    if arguments_list[\"celltype\"] is None:\n",
    "        print(\"Please provide the name of the metadata field containing cell type annotations\")\n",
    "\n",
    "    if arguments_list[\"condition\"] is None:\n",
    "        print(\"Please provide the name of the metadata field containing condition annotations\")\n",
    "\n",
    "    if arguments_list[\"organism\"] is None:\n",
    "        arguments_list[\"organism\"] = \"human\"\n",
    "\n",
    "    if arguments_list[\"comparison_list\"] is None:\n",
    "        arguments_list[\"comparison_list\"] = np.nan\n",
    "\n",
    "    if arguments_list[\"logfc\"] is None:\n",
    "        arguments_list[\"logfc\"] = 0.0\n",
    "\n",
    "    if arguments_list [\"pval\"] is None:\n",
    "        arguments_list[\"pval\"] = 0.05\n",
    "\n",
    "    if arguments_list[\"reg\"] is None:\n",
    "        arguments_list[\"reg\"] = load_dorothea_regulon(arguments_list[\"organism\"])\n",
    "\n",
    "    elif isinstance(arguments_list[\"reg\"], str):\n",
    "        arguments_list[\"reg\"] = pd.read_csv(arguments_list[\"reg\"], index_col=0)\n",
    "        arguments_list[\"reg\"] = pd.DataFrame.rename(arguments_list[\"reg\"], columns={\"source\" : \"tf\"})\n",
    "\n",
    "    if not \"tf\" in arguments_list[\"reg\"] and \"target\" in arguments_list[\"reg\"] and \"weight\"in arguments_list[\"reg\"]:\n",
    "        raise Exception(\"Not all necessary columns found in regulon table! Please make sure that the regulon has the columns source, target and weight!\")\n",
    "    \n",
    " \n",
    "   \n",
    "    return(arguments_list)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def AverageExpression(anndataobject, celltype = None, outpath = None):\n",
    "    gene_ids = anndataobject.var.index.values\n",
    "    #cluster line even necessary if not returned?\n",
    "    #clusters = anndataobject.obs[celltype].cat.categories\n",
    "    obs = anndataobject[:,gene_ids].X.toarray()\n",
    "    obs = np.expm1(obs)\n",
    "    sub_object = pd.DataFrame(obs,columns=gene_ids,index= anndataobject.obs[celltype])\n",
    "    sub_object = sub_object.groupby(level=0, observed=False).mean()\n",
    "    sub_object.T.to_csv(outpath + \"average_gene_expression_by_cluster_exp.csv\")\n",
    "\n",
    "    return sub_object.T\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#not per cluster but cluster and pval etc need to be added to csv (check against specific marker csv from lr2tf test run in R)\n",
    "\n",
    "def get_significant_tfs_single(anndataobject, celltype, condition, out_path, pval, logfc):\n",
    "    \n",
    "    #does not work if condition is None\n",
    "    single_result_path = out_path + condition \n",
    "    if not os.path.isdir(single_result_path):\n",
    "        os.mkdir(single_result_path)\n",
    "    \n",
    "    #sc.pp.scale(tf_activities)\n",
    "    #or sc.pp.normalize_total(anndataobject)\n",
    "    # sc.pp.log1p(anndata_object) \n",
    "    \n",
    "\n",
    "    number_of_clusters = len(anndataobject.obs[\"new_annotation\"].cat.categories) \n",
    "    \n",
    "    \n",
    "    sc.tl.rank_genes_groups(tf_activities, groupby= \"new_annotation\", reference=\"rest\", method=\"wilcoxon\", key_added=\"wilcoxon_markers\", corr_method= \"bonferroni\")\n",
    "    #sc.tl.filter_rank_genes_groups(anndataobject, min_in_group_fraction=0, key=\"wilcoxon_markers\", key_added= \"wilcoxon_markers_filtered\")\n",
    "     \n",
    "    sc.tl.rank_genes_groups(tf_activities, groupby= \"new_annotation\", reference=\"rest\", method=\"t-test_overestim_var\", key_added=\"t_test_overestim_var_markers\")\n",
    "    #sc.tl.filter_rank_genes_groups(anndataobject, min_in_group_fraction=0, key=\"t_test_overestim_var_markers\", key_added=\"t_test_overestim_filtered\")\n",
    "\n",
    "    #FindAllMarkers(seuratobject, only.pos = TRUE, min.pct = 0, logfc.threshold = 0, verbose = FALSE)\n",
    "\n",
    "    result1 = tf_activities.uns['wilcoxon_markers']\n",
    "    groups = result1['names'].dtype.names\n",
    "    anndataobject_markers = pd.DataFrame(\n",
    "    {group + '_' + key[:1]: result1[key][group]\n",
    "    for group in groups for key in ['names','logfoldchanges','pvals','pvals_adj']})\n",
    "\n",
    "    result2 = tf_activities.uns['t_test_overestim_var_markers']\n",
    "    groups = result2['names'].dtype.names\n",
    "    anndataobject_markers = pd.DataFrame(\n",
    "    {group + '_' + key[:1]: result2[key][group]\n",
    "    for group in groups for key in ['names','logfoldchanges','pvals','pvals_adj']})\n",
    "\n",
    "    anndataobject_markers_wilcoxon = sc.get.rank_genes_groups_df(tf_activities, group = None, log2fc_min=0, key=\"wilcoxon_markers\")\n",
    "    anndataobject_markers_wilcoxon.to_csv(\"specific_markers_wilcoxon_test.csv\",index=0)\n",
    "\n",
    "    anndataobject_markers_t_over = sc.get.rank_genes_groups_df(tf_activities, group = None, log2fc_min=0, key=\"t_test_overestim_var_markers\")\n",
    "    anndataobject_markers_t_over.to_csv(\"specific_markers_t_test_overestim_test.csv\",index=0)\n",
    "\n",
    "    \n",
    "\n",
    "    res = list()\n",
    "\n",
    "    return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5"
      ]
     },
     "execution_count": 130,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#cell is only for trying out stuff\n",
    "#anndataobject = ad.read_h5ad(\"LR2TF_test_run/anndata_object.h5ad\")\n",
    "\n",
    "#tf_activities = ad.read_csv(\"decoupler_results.csv\")\n",
    "#tf_activities.obsm = anndataobject.obsm\n",
    "#tf_activities.uns = anndataobject.uns\n",
    "#tf_activities.obs = anndataobject.obs\n",
    "\n",
    "#sc.pp.scale(tf_activities,zero_center=True)\n",
    "#del tf_activities.var[\"mean\"]\n",
    "#del tf_activities.var[\"std\"]\n",
    "#or sc.pp.normalize_total(tf_activities)\n",
    "\n",
    "#expects logarithmized data\n",
    "#sc.tl.rank_genes_groups(tf_activities, groupby= \"new_annotation\", reference=\"rest\", method=\"wilcoxon\", key_added=\"wilcoxon_markers\", corr_method= \"bonferroni\")\n",
    "#sc.tl.filter_rank_genes_groups(anndataobject, min_in_group_fraction=0, key=\"wilcoxon_markers\", key_added= \"wilcoxon_markers_filtered\")\n",
    "     \n",
    "#sc.tl.rank_genes_groups(tf_activities, groupby= \"new_annotation\", reference=\"rest\", method=\"t-test_overestim_var\", key_added=\"t_test_overestim_var_markers\")\n",
    "#sc.tl.filter_rank_genes_groups(anndataobject, min_in_group_fraction=0, key=\"t_test_overestim_var_markers\", key_added=\"t_test_overestim_filtered\")\n",
    "\n",
    "#FindAllMarkers(seuratobject, only.pos = TRUE, min.pct = 0, logfc.threshold = 0, verbose = FALSE)\n",
    "\n",
    "#result1 = tf_activities.uns['wilcoxon_markers']\n",
    "#groups = result1['names'].dtype.names\n",
    "#anndataobject_markers = pd.DataFrame(\n",
    "#{group + '_' + key[:1]: result1[key][group]\n",
    "#for group in groups for key in ['names','logfoldchanges','pvals','pvals_adj']})\n",
    "\n",
    "#result2 = tf_activities.uns['t_test_overestim_var_markers']\n",
    "#groups = result2['names'].dtype.names\n",
    "#anndataobject_markers = pd.DataFrame(\n",
    "#{group + '_' + key[:1]: result2[key][group]\n",
    "#for group in groups for key in ['names','logfoldchanges','pvals','pvals_adj']})\n",
    "\n",
    "#anndataobject_markers_wilcoxon = sc.get.rank_genes_groups_df(tf_activities, group = None, log2fc_min=0, key=\"wilcoxon_markers\")\n",
    "#anndataobject_markers_wilcoxon.to_csv(\"specific_markers_wilcoxon_test.csv\",index=0)\n",
    "\n",
    "#anndataobject_markers_t_over = sc.get.rank_genes_groups_df(tf_activities, group = None, log2fc_min=0, key=\"t_test_overestim_var_markers\")\n",
    "#anndataobject_markers_t_over.to_csv(\"specific_markers_t_test_overestim_test.csv\",index=0)\n",
    "    \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "anndataobject = ad.read_h5ad(\"LR2TF_test_run/anndata_object.h5ad\")\n",
    "\n",
    "tf_activities = ad.read_csv(\"decoupler_results.csv\")\n",
    "tf_activities.obsm = anndataobject.obsm\n",
    "tf_activities.uns = anndataobject.uns\n",
    "tf_activities.obs = anndataobject.obs\n",
    "tf_activities.X\n",
    "sc.pp.scale(tf_activities)\n",
    "tf_activities.X\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#test if subsetting object and using sc.pp.calculate_qc_metrics yields same results (yes it does)\n",
    "\n",
    "#anndataobject = ad.read_h5ad(\"LR2TF_test_run/anndata_object.h5ad\")\n",
    "#anndataobject.obs[\"new_annotation\"]\n",
    "#neural = anndataobject[anndataobject.obs.new_annotation == \"Neural\"]\n",
    "#megakaryocyte = anndataobject[anndataobject.obs.new_annotation == \"Neural\"]\n",
    "#msc = anndataobject[anndataobject.obs.new_annotation == \"Neural\"]\n",
    "#fibroblast = anndataobject[anndataobject.obs.new_annotation == \"Neural\"]\n",
    "#myeloid = anndataobject[anndataobject.obs.new_annotation == \"Neural\"]\n",
    "\n",
    "#test_neural = sc.pp.calculate_qc_metrics(neural, inplace=True)\n",
    "#neural.var.to_csv(\"test_neural\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#ignore extra tfs from decoupler while writing script \n",
    "\n",
    "def tf_activity_analysis (anndataobject, tf_activities = \"decoupler_results.csv\", arguments_list = None):\n",
    "    \n",
    "    if (isinstance(anndataobject, str)):\n",
    "        anndataobject = ad.read_h5ad(anndataobject)\n",
    "\n",
    "    arguments_list = validate_input_arguments(arguments_list)\n",
    "\n",
    "    if not os.path.isdir(arguments_list[\"out_path\"]):\n",
    "        os.mkdir(arguments_list[\"out_path\"])\n",
    "        tf_path = arguments_list[\"out_path\"] + \"TF_results/\"\n",
    "        os.mkdir(tf_path)\n",
    "    else:\n",
    "        tf_path = arguments_list[\"out_path\"] + \"TF_results/\"\n",
    "\n",
    "    #add for tf_activities = 0: access the tf data added by running decoupler\n",
    "    if isinstance(tf_activities, str):\n",
    "        tf_activities = ad.read_csv(tf_activities)\n",
    "        tf_activities.obsm = anndataobject.obsm\n",
    "        tf_activities.uns = anndataobject.uns\n",
    "        tf_activities.obs = anndataobject.obs\n",
    "\n",
    "\n",
    "    anndataobject.obs[\"condition\"] = arguments_list[\"condition\"] \n",
    "    anndataobject.obs[\"cell_type\"] = arguments_list[\"celltype\"]\n",
    "    anndataobject.obs[\"comparison_list\"] = arguments_list[\"comparison_list\"]\n",
    "\n",
    "    if not np.isnan(arguments_list[\"comparison_list\"]):\n",
    "        if len(arguments_list[\"comparison_list\"]) > 0 & len(anndataobject.obs[\"comparison_list\"]) < 2:\n",
    "            arguments_list[\"comparison_list\"] <- np.nan\n",
    "            print(\"Only one condition was found in the data, although a list of comparisons was provided. The analyses are performed only for the present condition!\")\n",
    "\n",
    "    #code for single condition  analysis\n",
    "\n",
    "    if np.isnan(arguments_list[\"comparison_list\"]):\n",
    "        result_list = []\n",
    "        gene_expression_list = []\n",
    "        CTR_cluster_list = []\n",
    "        intranet_cluster_list = []\n",
    "\n",
    "        #Idents(object = seuratobject) <- arguments_list$condition\n",
    "        #seuratobject_list <- SplitObject(seuratobject, split.by = arguments_list$condition)\n",
    "        #for (name in names(seuratobject_list)) {\n",
    "        #sub_object <- seuratobject_list[[name]]\n",
    "        anndataobject_list = list[anndataobject.obs.condition]\n",
    "\n",
    "        sub_object = anndataobject\n",
    "        sub_object.uns[\"Average_Expression\"] = AverageExpression(sub_object, celltype = arguments_list[\"celltype\"], outpath= arguments_list[\"out_path\"])\n",
    "\n",
    "        #add name into parameters later \n",
    "        tf_activity_scores = get_significant_tfs_single(tf_activities, arguments_list[\"celltype\"], arguments_list[\"condition\"], tf_path, pval = arguments_list[\"pval\"], logfc = arguments_list[\"logfc\"])\n",
    "        #result_list[\"name\"] = tf_activity_scores\n",
    "        #gene_expression_list[name + \"_average_expression\"] = sub_object.layers[\"cell_type\"]\n",
    "        #if (arguments_list[\"organism\"] == \"human\"):\n",
    "        #CTR_cluster_list[\"name\"] = generate_CrossTalkeR_input(tf_activity_scores[\n",
    "\n",
    "    return(sub_object)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sub_object = tf_activity_analysis(anndataobject= \"LR2TF_test_run/anndata_object.h5ad\", arguments_list= {\"out_path\" : \"script_test\", \"celltype\" : \"new_annotation\", \"condition\" : \"control\", \"organism\" : None, \"comparison_list\" : None, \"logfc\" : None, \"pval\" : None, \"reg\" : \"filterd_regulon.csv\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#anndataobject[:,\"ISG15\"].X.todense().sum()\n",
    "#sub_object.uns[\"Average_Expression\"]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "testpy",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
