{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import anndata as ad\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import scanpy as sc\n",
    "import decoupler as dc\n",
    "import os\n",
    "import pyreadr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def validate_input_arguments (arguments_list):\n",
    "    if arguments_list[\"out_path\"] is None:\n",
    "        print(\"Please provide an output path\")\n",
    "    elif arguments_list[\"out_path\"][-1] != \"/\":\n",
    "        arguments_list[\"out_path\"] = arguments_list[\"out_path\"] + \"/\"\n",
    "\n",
    "    if arguments_list[\"celltype\"] is None:\n",
    "        print(\"Please provide the name of the metadata field containing cell type annotations\")\n",
    "\n",
    "    if arguments_list[\"condition\"] is None:\n",
    "        print(\"Please provide the name of the metadata field containing condition annotations\")\n",
    "\n",
    "    if arguments_list[\"organism\"] is None:\n",
    "        arguments_list[\"organism\"] = \"human\"\n",
    "\n",
    "    if arguments_list[\"comparison_list\"] is None:\n",
    "        arguments_list[\"comparison_list\"] = np.nan\n",
    "\n",
    "    if arguments_list[\"logfc\"] is None:\n",
    "        arguments_list[\"logfc\"] = 0.0\n",
    "\n",
    "    if arguments_list [\"pval\"] is None:\n",
    "        arguments_list[\"pval\"] = 0.05\n",
    "\n",
    "    if arguments_list[\"reg\"] is None:\n",
    "        arguments_list[\"reg\"] = load_dorothea_regulon(arguments_list[\"organism\"])\n",
    "\n",
    "    elif isinstance(arguments_list[\"reg\"], str):\n",
    "        arguments_list[\"reg\"] = pd.read_csv(arguments_list[\"reg\"], index_col=0)\n",
    "        arguments_list[\"reg\"] = pd.DataFrame.rename(arguments_list[\"reg\"], columns={\"source\" : \"tf\"})\n",
    "\n",
    "    if not \"tf\" in arguments_list[\"reg\"] and \"target\" in arguments_list[\"reg\"] and \"weight\"in arguments_list[\"reg\"]:\n",
    "        raise Exception(\"Not all necessary columns found in regulon table! Please make sure that the regulon has the columns source, target and weight!\")\n",
    "    \n",
    " \n",
    "   \n",
    "    return(arguments_list)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def AverageExpression(sub_object, celltype = None, name_iterable = None, outpath = None):\n",
    "    gene_ids = sub_object.var.index.values\n",
    "    #cluster line even necessary if not returned?\n",
    "    #clusters = anndataobject.obs[celltype].cat.categories\n",
    "    obs = sub_object[:,gene_ids].X.toarray()\n",
    "    obs = np.expm1(obs)\n",
    "    avg_df = pd.DataFrame(obs,columns=gene_ids,index= sub_object.obs[celltype])\n",
    "    avg_df = avg_df.groupby(level=0, observed=False).mean()\n",
    "    avg_df.T.to_csv(outpath + name_iterable + \"_average_gene_expression_by_cluster_exp.csv\")\n",
    "\n",
    "    return avg_df.T\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def eval_pval(p_val):\n",
    "    p_val = float(p_val)\n",
    "    if p_val < 0.001: \n",
    "      txt = \"***\"\n",
    "    elif p_val < 0.01: \n",
    "      txt = \"**\"\n",
    "    elif p_val < 0.05: \n",
    "      txt = \"*\"\n",
    "    else:\n",
    "      txt = \"ns\"\n",
    "    return(txt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#not per cluster but cluster and pval etc need to be added to csv (check against specific marker csv from lr2tf test run in R)\n",
    "\n",
    "def get_significant_tfs_single(tf_activities_sub, celltype, condition, out_path, pval, logfc, name):\n",
    "    \n",
    "    #does not work if condition is None\n",
    "    renamed_condition = condition.replace(\",\", \"_\")\n",
    "    name = name.replace(\",\", \"_\")\n",
    "\n",
    "    single_result_path = out_path + renamed_condition \n",
    "    if not os.path.isdir(single_result_path):\n",
    "        os.mkdir(single_result_path)\n",
    "    \n",
    "    \n",
    "    #tf_activities_scaled = sc.pp.scale(tf_activities_sub, copy=True, max_value=10)\n",
    "    #or sc.pp.normalize_total(anndataobject)\n",
    "    #sc.pp.log1p(tf_activities) \n",
    "    # \"warning: seems to be already log transformed\"\n",
    "\n",
    "    number_of_clusters = len(tf_activities_sub.obs[\"new_annotation\"].cat.categories) \n",
    "    \n",
    "    \n",
    "\n",
    "    sc.tl.rank_genes_groups(tf_activities_sub, groupby= \"new_annotation\", reference=\"rest\", method=\"wilcoxon\", key_added=\"wilcoxon_markers\", corr_method= \"bonferroni\")\n",
    "    #sc.tl.filter_rank_genes_groups(anndataobject, min_in_group_fraction=0, key=\"wilcoxon_markers\", key_added= \"wilcoxon_markers_filtered\")\n",
    "    \n",
    "\n",
    "    sc.tl.rank_genes_groups(tf_activities_sub, groupby= \"new_annotation\", reference=\"rest\", method=\"t-test_overestim_var\", key_added=\"t_test_overestim_var_markers\", corr_method= \"bonferroni\" )\n",
    "    #sc.tl.filter_rank_genes_groups(anndataobject, min_in_group_fraction=0, key=\"t_test_overestim_var_markers\", key_added=\"t_test_overestim_filtered\")\n",
    "\n",
    "    #FindAllMarkers(seuratobject, only.pos = TRUE, min.pct = 0, logfc.threshold = 0, verbose = FALSE)\n",
    "\n",
    "    result1 = tf_activities_sub.uns['wilcoxon_markers']\n",
    "    groups = result1['names'].dtype.names\n",
    "    anndataobject_markers = pd.DataFrame(\n",
    "    {group + '_' + key[:1]: result1[key][group]\n",
    "    for group in groups for key in ['names','logfoldchanges','pvals','pvals_adj']})\n",
    "\n",
    "    result2 = tf_activities_sub.uns['t_test_overestim_var_markers']\n",
    "    groups = result2['names'].dtype.names\n",
    "    anndataobject_markers = pd.DataFrame(\n",
    "    {group + '_' + key[:1]: result2[key][group]\n",
    "    for group in groups for key in ['names','logfoldchanges','pvals','pvals_adj']})\n",
    "\n",
    "    anndataobject_markers_wilcoxon = sc.get.rank_genes_groups_df(tf_activities_sub, group = None, log2fc_min=0, key=\"wilcoxon_markers\")\n",
    "    \n",
    "    #documentation says this won't update the main dataframe but will only overwrite a copy in future pandas versions (after v3)\n",
    "    anndataobject_markers_wilcoxon[\"tag\"] = None\n",
    "    for i in range(len(anndataobject_markers_wilcoxon[\"pvals_adj\"])):\n",
    "         anndataobject_markers_wilcoxon[\"tag\"].iloc[i,] = eval_pval(anndataobject_markers_wilcoxon[\"pvals_adj\"].iloc[i,])\n",
    "\n",
    "\n",
    "    anndataobject_markers_wilcoxon.to_csv(single_result_path + \"/\" + name + \"_specific_markers_wilcoxon_test.csv\",index=0)\n",
    "\n",
    "    anndataobject_markers_t_over = sc.get.rank_genes_groups_df(tf_activities_sub, group = None, log2fc_min=0, key=\"t_test_overestim_var_markers\")\n",
    "\n",
    "    anndataobject_markers_t_over[\"tag\"] = None\n",
    "    for i in range(len(anndataobject_markers_t_over[\"pvals_adj\"])):\n",
    "         anndataobject_markers_t_over[\"tag\"].iloc[i,] = eval_pval(anndataobject_markers_t_over[\"pvals_adj\"].iloc[i,])\n",
    "\n",
    "    anndataobject_markers_t_over.to_csv(single_result_path + \"/\" + name + \"_specific_markers_t_test_overestim_test.csv\",index=0)\n",
    "\n",
    "    #res needs to contain gene, pval tag, cluster and z score\n",
    "    anndataobject_markers_wilcoxon.rename(columns={\"names\":\"gene\", \"group\": \"cluster\"}, inplace=True)\n",
    "    anndataobject_markers_t_over.rename(columns={\"names\":\"gene\", \"group\": \"cluster\"}, inplace=True)\n",
    "\n",
    "    res_wilcoxon = anndataobject_markers_wilcoxon[[\"gene\",\"tag\", \"cluster\"]]\n",
    "    #only for testing code, needs to be calculated properly\n",
    "    res_wilcoxon[\"z_score\"] = 0\n",
    "    res_t_test = anndataobject_markers_t_over[[\"gene\",\"tag\", \"cluster\"]]\n",
    "\n",
    "     #//TODO: \n",
    "    #delete one variant and put test type as a variable\n",
    "\n",
    "    return res_wilcoxon, res_t_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "#check if it's okay to not pre set the column type as string or float (maybe no problem in python but was problem in r)\n",
    "\n",
    "def create_empty_CTR_dataframe():\n",
    "  \n",
    "  empty_df = pd.DataFrame(\n",
    "    columns=[\n",
    "    \"source\",\n",
    "    \"target\",\n",
    "    \"gene_A\",\n",
    "    \"gene_B\",\n",
    "    \"type_gene_A\",\n",
    "    \"type_gene_B\",\n",
    "    \"MeanLR\"\n",
    "    ])\n",
    "  \n",
    "  return(empty_df)\n",
    "\n",
    "\n",
    "def add_entry_to_CTR_dataframe(source, target, gene_A, gene_B, type_gene_A, type_gene_B, MeanLR):\n",
    "  df = pd.DataFrame(\n",
    "      source,\n",
    "      target,\n",
    "      gene_A,\n",
    "      gene_B,\n",
    "      type_gene_A,\n",
    "      type_gene_B,\n",
    "      MeanLR)\n",
    "\n",
    "  return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "               Neural       MSC  Fibroblast  Megakaryocyte   Myeloid\n",
      "FO538757.2        0.0  1.838987    0.000000       0.000000  0.000000\n",
      "RP11-206L10.9     0.0  0.000000    0.386757       0.000000  0.000000\n",
      "SAMD11            0.0  0.000000    0.000000       0.000000  0.000000\n",
      "NOC2L             0.0  0.197924    2.134077       0.780153  0.561325\n",
      "HES4              0.0  0.545435    0.000000       1.190760  0.000000\n",
      "...               ...       ...         ...            ...       ...\n",
      "SMYD5             0.0  0.000000    0.000000       0.000000  0.000000\n",
      "CCDC85C           0.0  0.000000    0.000000       0.000000  0.000000\n",
      "CPNE2             0.0  0.000000    0.000000       0.000000  0.000000\n",
      "TMEM206           0.0  0.000000    0.000000       0.000000  0.000000\n",
      "CCDC9             0.0  0.000000    0.000000       0.000000  0.000000\n",
      "\n",
      "[11426 rows x 5 columns]\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "7 columns passed, passed data had 1 columns",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAssertionError\u001b[0m                            Traceback (most recent call last)",
      "File \u001b[1;32md:\\studium\\LR2TF_HiWi\\.venv\\Lib\\site-packages\\pandas\\core\\internals\\construction.py:939\u001b[0m, in \u001b[0;36m_finalize_columns_and_data\u001b[1;34m(content, columns, dtype)\u001b[0m\n\u001b[0;32m    938\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 939\u001b[0m     columns \u001b[38;5;241m=\u001b[39m \u001b[43m_validate_or_indexify_columns\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcontents\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcolumns\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    940\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mAssertionError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m err:\n\u001b[0;32m    941\u001b[0m     \u001b[38;5;66;03m# GH#26429 do not raise user-facing AssertionError\u001b[39;00m\n",
      "File \u001b[1;32md:\\studium\\LR2TF_HiWi\\.venv\\Lib\\site-packages\\pandas\\core\\internals\\construction.py:986\u001b[0m, in \u001b[0;36m_validate_or_indexify_columns\u001b[1;34m(content, columns)\u001b[0m\n\u001b[0;32m    984\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m is_mi_list \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(columns) \u001b[38;5;241m!=\u001b[39m \u001b[38;5;28mlen\u001b[39m(content):  \u001b[38;5;66;03m# pragma: no cover\u001b[39;00m\n\u001b[0;32m    985\u001b[0m     \u001b[38;5;66;03m# caller's responsibility to check for this...\u001b[39;00m\n\u001b[1;32m--> 986\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mAssertionError\u001b[39;00m(\n\u001b[0;32m    987\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mlen\u001b[39m(columns)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m columns passed, passed data had \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    988\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mlen\u001b[39m(content)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m columns\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    989\u001b[0m     )\n\u001b[0;32m    990\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m is_mi_list:\n\u001b[0;32m    991\u001b[0m     \u001b[38;5;66;03m# check if nested list column, length of each sub-list should be equal\u001b[39;00m\n",
      "\u001b[1;31mAssertionError\u001b[0m: 7 columns passed, passed data had 1 columns",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[43], line 70\u001b[0m\n\u001b[0;32m     61\u001b[0m        \u001b[38;5;28;01mfor\u001b[39;00m receptor \u001b[38;5;129;01min\u001b[39;00m receptors:\n\u001b[0;32m     62\u001b[0m          df_list_r \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m[tf_activities\u001b[38;5;241m.\u001b[39miloc[row, \u001b[38;5;241m2\u001b[39m],\n\u001b[0;32m     63\u001b[0m                                          tf_activities\u001b[38;5;241m.\u001b[39miloc[row, \u001b[38;5;241m2\u001b[39m],\n\u001b[0;32m     64\u001b[0m                                          receptor,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     67\u001b[0m                                          \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mTranscription Factor\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[0;32m     68\u001b[0m                                          tf_activities\u001b[38;5;241m.\u001b[39miloc[row, \u001b[38;5;241m3\u001b[39m]]\n\u001b[1;32m---> 70\u001b[0m tf_l \u001b[38;5;241m=\u001b[39m \u001b[43mpd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mDataFrame\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdf_list_l\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcolumns\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43msource\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mtarget\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mgene_A\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mgene_B\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mtype_gene_A\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mtype_gene_B\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mMeanLR\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     71\u001b[0m \u001b[38;5;28mprint\u001b[39m(tf_l)\n\u001b[0;32m     72\u001b[0m r_tf \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mDataFrame(df_list_r)\n",
      "File \u001b[1;32md:\\studium\\LR2TF_HiWi\\.venv\\Lib\\site-packages\\pandas\\core\\frame.py:851\u001b[0m, in \u001b[0;36mDataFrame.__init__\u001b[1;34m(self, data, index, columns, dtype, copy)\u001b[0m\n\u001b[0;32m    849\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m columns \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    850\u001b[0m         columns \u001b[38;5;241m=\u001b[39m ensure_index(columns)\n\u001b[1;32m--> 851\u001b[0m     arrays, columns, index \u001b[38;5;241m=\u001b[39m \u001b[43mnested_data_to_arrays\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    852\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;66;43;03m# error: Argument 3 to \"nested_data_to_arrays\" has incompatible\u001b[39;49;00m\n\u001b[0;32m    853\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;66;43;03m# type \"Optional[Collection[Any]]\"; expected \"Optional[Index]\"\u001b[39;49;00m\n\u001b[0;32m    854\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    855\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcolumns\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    856\u001b[0m \u001b[43m        \u001b[49m\u001b[43mindex\u001b[49m\u001b[43m,\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# type: ignore[arg-type]\u001b[39;49;00m\n\u001b[0;32m    857\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    858\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    859\u001b[0m     mgr \u001b[38;5;241m=\u001b[39m arrays_to_mgr(\n\u001b[0;32m    860\u001b[0m         arrays,\n\u001b[0;32m    861\u001b[0m         columns,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    864\u001b[0m         typ\u001b[38;5;241m=\u001b[39mmanager,\n\u001b[0;32m    865\u001b[0m     )\n\u001b[0;32m    866\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "File \u001b[1;32md:\\studium\\LR2TF_HiWi\\.venv\\Lib\\site-packages\\pandas\\core\\internals\\construction.py:520\u001b[0m, in \u001b[0;36mnested_data_to_arrays\u001b[1;34m(data, columns, index, dtype)\u001b[0m\n\u001b[0;32m    517\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m is_named_tuple(data[\u001b[38;5;241m0\u001b[39m]) \u001b[38;5;129;01mand\u001b[39;00m columns \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    518\u001b[0m     columns \u001b[38;5;241m=\u001b[39m ensure_index(data[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m.\u001b[39m_fields)\n\u001b[1;32m--> 520\u001b[0m arrays, columns \u001b[38;5;241m=\u001b[39m \u001b[43mto_arrays\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcolumns\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdtype\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    521\u001b[0m columns \u001b[38;5;241m=\u001b[39m ensure_index(columns)\n\u001b[0;32m    523\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m index \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "File \u001b[1;32md:\\studium\\LR2TF_HiWi\\.venv\\Lib\\site-packages\\pandas\\core\\internals\\construction.py:845\u001b[0m, in \u001b[0;36mto_arrays\u001b[1;34m(data, columns, dtype)\u001b[0m\n\u001b[0;32m    842\u001b[0m     data \u001b[38;5;241m=\u001b[39m [\u001b[38;5;28mtuple\u001b[39m(x) \u001b[38;5;28;01mfor\u001b[39;00m x \u001b[38;5;129;01min\u001b[39;00m data]\n\u001b[0;32m    843\u001b[0m     arr \u001b[38;5;241m=\u001b[39m _list_to_arrays(data)\n\u001b[1;32m--> 845\u001b[0m content, columns \u001b[38;5;241m=\u001b[39m \u001b[43m_finalize_columns_and_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43marr\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcolumns\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    846\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m content, columns\n",
      "File \u001b[1;32md:\\studium\\LR2TF_HiWi\\.venv\\Lib\\site-packages\\pandas\\core\\internals\\construction.py:942\u001b[0m, in \u001b[0;36m_finalize_columns_and_data\u001b[1;34m(content, columns, dtype)\u001b[0m\n\u001b[0;32m    939\u001b[0m     columns \u001b[38;5;241m=\u001b[39m _validate_or_indexify_columns(contents, columns)\n\u001b[0;32m    940\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mAssertionError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m err:\n\u001b[0;32m    941\u001b[0m     \u001b[38;5;66;03m# GH#26429 do not raise user-facing AssertionError\u001b[39;00m\n\u001b[1;32m--> 942\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(err) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01merr\u001b[39;00m\n\u001b[0;32m    944\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(contents) \u001b[38;5;129;01mand\u001b[39;00m contents[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m.\u001b[39mdtype \u001b[38;5;241m==\u001b[39m np\u001b[38;5;241m.\u001b[39mobject_:\n\u001b[0;32m    945\u001b[0m     contents \u001b[38;5;241m=\u001b[39m convert_object_array(contents, dtype\u001b[38;5;241m=\u001b[39mdtype)\n",
      "\u001b[1;31mValueError\u001b[0m: 7 columns passed, passed data had 1 columns"
     ]
    }
   ],
   "source": [
    "#def generate_CrossTalkeR_input(tf_activities, gene_expression, regulon = None):\n",
    "\n",
    "tf_activities =  pd.read_csv(\"tf_activities_test_wilcox.csv\")  \n",
    "#tf_activities[\"cluster\"] = \"Neural\"\n",
    "gene_expression = pd.read_csv(\"script_test/control_average_gene_expression_by_cluster_exp.csv\", index_col = 0)\n",
    "print(gene_expression)\n",
    "regulon = pd.read_csv(\"filterd_regulon.csv\", index_col = 0)  \n",
    "regulon = regulon.rename(columns={\"source\" : \"tf\"})\n",
    "\n",
    "\n",
    "\n",
    "ligands_readin = pyreadr.read_r(\"ligands_human.rda\")\n",
    "ligands = ligands_readin[\"ligands_human\"]\n",
    "\n",
    "rtf_readin = pyreadr.read_r(\"RTF_DB_2.rda\") \n",
    "rtf_db = rtf_readin[\"RTF_DB_2\"]\n",
    "\n",
    "#put tf as index column/rownames and receptors as column 1\n",
    "\n",
    "R2TF = rtf_db.set_index(\"tf\")\n",
    "\n",
    "sorted_regulon = regulon[[\"tf\", \"target\"]]\n",
    "sorted_regulon.rename(columns={\"target\" : \"targets\"})\n",
    "sorted_regulon = sorted_regulon.set_index(\"tf\")\n",
    "\n",
    "output_df = create_empty_CTR_dataframe()\n",
    "\n",
    "for row in range(len((tf_activities))):\n",
    "\n",
    "  #r_tf = create_empty_CTR_dataframe()\n",
    "  #tf_l = create_empty_CTR_dataframe()\n",
    "\n",
    "  #if (tf_activities[\"z_score\"].iloc[row] == 0):\n",
    "  tf_var = str(tf_activities[\"gene\"].iloc[row])\n",
    "  if tf_var in sorted_regulon.index:\n",
    "    targets = sorted_regulon.loc[tf_var]\n",
    "  if tf_var in R2TF.index:\n",
    "    receptors = R2TF.loc[tf_var]\n",
    "  tf_ligands = np.intersect1d(targets, ligands)\n",
    "  \n",
    "  \n",
    "  if (len(tf_ligands) > 0):\n",
    "    for ligand in tf_ligands:\n",
    "      expressed = False\n",
    "    if ligand in gene_expression.index:\n",
    "      ex_value = gene_expression.loc[ligand, \"Neural\"]\n",
    "      if (ex_value != 0):\n",
    "        expressed = True\n",
    "        \n",
    "    #print(tf_activities.iloc[row[]])\n",
    "    if (expressed == True):\n",
    "      df_list_l = list[tf_activities.iloc[row, 2],\n",
    "                                             tf_activities.iloc[row, 2],\n",
    "                                             tf_activities.iloc[row, 0],\n",
    "                                             ligand,\n",
    "                                             \"Transcription Factor\",\n",
    "                                             \"Ligand\",\n",
    "                                             tf_activities.iloc[row, 3]]\n",
    "      \n",
    "    if (len(receptors) > 0):\n",
    "       for receptor in receptors:\n",
    "         df_list_r = list[tf_activities.iloc[row, 2],\n",
    "                                         tf_activities.iloc[row, 2],\n",
    "                                         receptor,\n",
    "                                         tf_activities.iloc[row, 0],\n",
    "                                         'Receptor',\n",
    "                                         'Transcription Factor',\n",
    "                                         tf_activities.iloc[row, 3]]\n",
    "   \n",
    "tf_l = pd.DataFrame(df_list_l, columns=[\"source\", \"target\", \"gene_A\", \"gene_B\", \"type_gene_A\", \"type_gene_B\", \"MeanLR\"])\n",
    "print(tf_l)\n",
    "r_tf = pd.DataFrame(df_list_r)\n",
    "      \n",
    "  #    r_tf[\"gene_A\"] <- gsub(\"_\", \"+\", r_tf$gene_A, fixed = TRUE)\n",
    "   #   r_tf[\"gene_B\"] <- gsub(\"_\", \"+\", r_tf$gene_B, fixed = TRUE)\n",
    "   #   tf_l[\"gene_A\"] <- gsub(\"_\", \"+\", tf_l$gene_A, fixed = TRUE)\n",
    "   #   tf_l[\"gene_B\"] <- gsub(\"_\", \"+\", tf_l$gene_B, fixed = TRUE)\n",
    "\n",
    "   #   output_df = pd.concat(output_df, r_tf)\n",
    "   #   output_df = pd.concat(output_df, tf_l)\n",
    "\n",
    "  #return output_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "#ignore extra tfs from decoupler while writing script \n",
    "\n",
    "def tf_activity_analysis (anndataobject, arguments_list = None):\n",
    "    \n",
    "    if (isinstance(anndataobject, str)):\n",
    "        anndataobject = ad.read_h5ad(anndataobject)\n",
    "\n",
    "    arguments_list = validate_input_arguments(arguments_list)\n",
    "\n",
    "    if not os.path.isdir(arguments_list[\"out_path\"]):\n",
    "        os.mkdir(arguments_list[\"out_path\"])\n",
    "        tf_path = arguments_list[\"out_path\"] + \"TF_results/\"\n",
    "        os.mkdir(tf_path)\n",
    "    else:\n",
    "        tf_path = arguments_list[\"out_path\"] + \"TF_results/\"\n",
    "\n",
    "    #rename the arguments inserted into argument list (eg protocol to condition)\n",
    "    condition = anndataobject.obs[arguments_list[\"condition\"]]\n",
    "\n",
    "    #checks for tf activity csv, if nothing there, runs decoupler\n",
    "    if isinstance(arguments_list[\"tf_activities\"], str):\n",
    "         tf_activities = ad.read_csv(arguments_list[\"tf_activities\"])\n",
    "         tf_activities.obsm = anndataobject.obsm\n",
    "         tf_activities.uns = anndataobject.uns\n",
    "         tf_activities.obs = anndataobject.obs\n",
    "    elif arguments_list[\"tf_activities\"] is None:\n",
    "         dc.run_ulm(mat = anndataobject, net = \"reg\", source ='source', target ='target', weight ='weight', verbose = True, use_raw = False)\n",
    "         tf_activities = anndataobject.obsm['ulm_estimate']\n",
    "         tf_activities.to_csv(\"decoupler_results.csv\")\n",
    "\n",
    "\n",
    "    #sets the stage for decision if single condition or comparison analysis is done\n",
    "\n",
    "    if not np.isnan(arguments_list[\"comparison_list\"]):\n",
    "        if len(arguments_list[\"comparison_list\"]) > 0 & len(anndataobject.obs[\"comparison_list\"]) < 2:\n",
    "            arguments_list[\"comparison_list\"] <- np.nan\n",
    "            print(\"Only one condition was found in the data, although a list of comparisons was provided. The analyses are performed only for the present condition!\")\n",
    "\n",
    "    #code for single condition  analysis\n",
    "\n",
    "    if np.isnan(arguments_list[\"comparison_list\"]):\n",
    "        result_list = []\n",
    "        gene_expression_list = []\n",
    "        CTR_cluster_list = []\n",
    "        intranet_cluster_list = []\n",
    "\n",
    "        #creates loop until after tf activity score\n",
    "        \n",
    "        for name_iterable in anndataobject.obs.protocol.unique():\n",
    "            sub_object = anndataobject[anndataobject.obs.protocol == name_iterable]\n",
    "            tf_activities_sub = tf_activities[tf_activities.obs.protocol == name_iterable]\n",
    "\n",
    "            sub_object_avg = AverageExpression(sub_object, name_iterable= name_iterable, celltype = arguments_list[\"celltype\"], outpath= arguments_list[\"out_path\"])\n",
    "            #check if its fine to only have the average expression as a dataframe and not as part of an anndata object\n",
    "\n",
    "            #check how sub object is returned by average expression (subobject.T) or rename return?\n",
    "            tf_activity_scores = get_significant_tfs_single(tf_activities_sub, celltype = arguments_list[\"celltype\"],condition = name_iterable, out_path= tf_path, pval = arguments_list[\"pval\"], logfc = arguments_list[\"logfc\"], name = name_iterable)\n",
    "           \n",
    "            tf_activity_scores[0].to_csv(\"tf_activities_test_wilcox.csv\", index = 0)\n",
    "            tf_activity_scores[1].to_csv(\"tf_activities_test_t_test.csv\", index = 0)\n",
    "\n",
    "            #result_list[[name_iterable]] = tf_activity_scores\n",
    "            #gene_expression_list[[name_iterable + \"_average_expression\"]] = sub_object_avg\n",
    "            \n",
    "            #if (arguments_list[\"organism\"] == \"human\"):\n",
    "            #    CTR_cluster_list[name_iterable] = generate_CrossTalkeR_input(tf_activity_scores[[\"cluster\"]],\n",
    "            #                                                                     gene_expression_list[[(name_iterable + \"_average_expression\")]],\n",
    "            #                                                                     arguments_list[\"reg\"])\n",
    "            #else:\n",
    "            #  CTR_cluster_list[[name_iterable]] = generate_CrossTalkeR_input_mouse(tf_activity_scores[[\"cluster\"]],\n",
    "            #                                                                     gene_expression_list[[(name_iterable + \"_average_expression\")]],\n",
    "            #                                                                     arguments_list[\"reg\"])\n",
    "              \n",
    "            #intranet_cluster_list[[name_iterable]] = generate_intracellular_network(tf_activity_scores[[\"cluster\"]],\n",
    "            #                                                          gene_expression_list[[paste0(name, \"_average_expression\")]],\n",
    "            #                                                          arguments_list$reg,\n",
    "            #                                                          arguments_list$organism)\n",
    "        #return(sub_object) #return tf when finished"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\studium\\LR2TF_HiWi\\.venv\\Lib\\site-packages\\scanpy\\tools\\_rank_genes_groups.py:640: ImplicitModificationWarning: Trying to modify attribute `._uns` of view, initializing view as actual.\n",
      "  adata.uns[key_added] = {}\n",
      "d:\\studium\\LR2TF_HiWi\\.venv\\Lib\\site-packages\\scanpy\\tools\\_rank_genes_groups.py:455: RuntimeWarning: invalid value encountered in log2\n",
      "  self.stats[group_name, \"logfoldchanges\"] = np.log2(\n",
      "d:\\studium\\LR2TF_HiWi\\.venv\\Lib\\site-packages\\scanpy\\tools\\_rank_genes_groups.py:455: RuntimeWarning: invalid value encountered in log2\n",
      "  self.stats[group_name, \"logfoldchanges\"] = np.log2(\n",
      "d:\\studium\\LR2TF_HiWi\\.venv\\Lib\\site-packages\\scanpy\\tools\\_rank_genes_groups.py:455: RuntimeWarning: invalid value encountered in log2\n",
      "  self.stats[group_name, \"logfoldchanges\"] = np.log2(\n",
      "d:\\studium\\LR2TF_HiWi\\.venv\\Lib\\site-packages\\scanpy\\tools\\_rank_genes_groups.py:455: RuntimeWarning: invalid value encountered in log2\n",
      "  self.stats[group_name, \"logfoldchanges\"] = np.log2(\n",
      "d:\\studium\\LR2TF_HiWi\\.venv\\Lib\\site-packages\\scanpy\\tools\\_rank_genes_groups.py:455: RuntimeWarning: invalid value encountered in log2\n",
      "  self.stats[group_name, \"logfoldchanges\"] = np.log2(\n",
      "d:\\studium\\LR2TF_HiWi\\.venv\\Lib\\site-packages\\scanpy\\tools\\_rank_genes_groups.py:455: RuntimeWarning: invalid value encountered in log2\n",
      "  self.stats[group_name, \"logfoldchanges\"] = np.log2(\n",
      "d:\\studium\\LR2TF_HiWi\\.venv\\Lib\\site-packages\\scanpy\\tools\\_rank_genes_groups.py:455: RuntimeWarning: invalid value encountered in log2\n",
      "  self.stats[group_name, \"logfoldchanges\"] = np.log2(\n",
      "d:\\studium\\LR2TF_HiWi\\.venv\\Lib\\site-packages\\scanpy\\tools\\_rank_genes_groups.py:455: RuntimeWarning: invalid value encountered in log2\n",
      "  self.stats[group_name, \"logfoldchanges\"] = np.log2(\n",
      "d:\\studium\\LR2TF_HiWi\\.venv\\Lib\\site-packages\\scanpy\\tools\\_rank_genes_groups.py:455: RuntimeWarning: invalid value encountered in log2\n",
      "  self.stats[group_name, \"logfoldchanges\"] = np.log2(\n",
      "d:\\studium\\LR2TF_HiWi\\.venv\\Lib\\site-packages\\scanpy\\tools\\_rank_genes_groups.py:455: RuntimeWarning: invalid value encountered in log2\n",
      "  self.stats[group_name, \"logfoldchanges\"] = np.log2(\n",
      "C:\\Users\\Larissa\\AppData\\Local\\Temp\\ipykernel_20368\\1923435211.py:49: FutureWarning: ChainedAssignmentError: behaviour will change in pandas 3.0!\n",
      "You are setting values through chained assignment. Currently this works in certain cases, but when using Copy-on-Write (which will become the default behaviour in pandas 3.0) this will never work to update the original DataFrame or Series, because the intermediate object on which we are setting values will behave as a copy.\n",
      "A typical example is when you are setting values in a column of a DataFrame, like:\n",
      "\n",
      "df[\"col\"][row_indexer] = value\n",
      "\n",
      "Use `df.loc[row_indexer, \"col\"] = values` instead, to perform the assignment in a single step and ensure this keeps updating the original `df`.\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "\n",
      "  anndataobject_markers_wilcoxon[\"tag\"].iloc[i,] = eval_pval(anndataobject_markers_wilcoxon[\"pvals_adj\"].iloc[i,])\n",
      "C:\\Users\\Larissa\\AppData\\Local\\Temp\\ipykernel_20368\\1923435211.py:49: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  anndataobject_markers_wilcoxon[\"tag\"].iloc[i,] = eval_pval(anndataobject_markers_wilcoxon[\"pvals_adj\"].iloc[i,])\n",
      "C:\\Users\\Larissa\\AppData\\Local\\Temp\\ipykernel_20368\\1923435211.py:58: FutureWarning: ChainedAssignmentError: behaviour will change in pandas 3.0!\n",
      "You are setting values through chained assignment. Currently this works in certain cases, but when using Copy-on-Write (which will become the default behaviour in pandas 3.0) this will never work to update the original DataFrame or Series, because the intermediate object on which we are setting values will behave as a copy.\n",
      "A typical example is when you are setting values in a column of a DataFrame, like:\n",
      "\n",
      "df[\"col\"][row_indexer] = value\n",
      "\n",
      "Use `df.loc[row_indexer, \"col\"] = values` instead, to perform the assignment in a single step and ensure this keeps updating the original `df`.\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "\n",
      "  anndataobject_markers_t_over[\"tag\"].iloc[i,] = eval_pval(anndataobject_markers_t_over[\"pvals_adj\"].iloc[i,])\n",
      "C:\\Users\\Larissa\\AppData\\Local\\Temp\\ipykernel_20368\\1923435211.py:58: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  anndataobject_markers_t_over[\"tag\"].iloc[i,] = eval_pval(anndataobject_markers_t_over[\"pvals_adj\"].iloc[i,])\n",
      "C:\\Users\\Larissa\\AppData\\Local\\Temp\\ipykernel_20368\\1923435211.py:68: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  res_wilcoxon[\"z_score\"] = 0\n",
      "d:\\studium\\LR2TF_HiWi\\.venv\\Lib\\site-packages\\scanpy\\tools\\_rank_genes_groups.py:640: ImplicitModificationWarning: Trying to modify attribute `._uns` of view, initializing view as actual.\n",
      "  adata.uns[key_added] = {}\n",
      "d:\\studium\\LR2TF_HiWi\\.venv\\Lib\\site-packages\\scanpy\\tools\\_rank_genes_groups.py:455: RuntimeWarning: invalid value encountered in log2\n",
      "  self.stats[group_name, \"logfoldchanges\"] = np.log2(\n",
      "d:\\studium\\LR2TF_HiWi\\.venv\\Lib\\site-packages\\scanpy\\tools\\_rank_genes_groups.py:455: RuntimeWarning: invalid value encountered in log2\n",
      "  self.stats[group_name, \"logfoldchanges\"] = np.log2(\n",
      "d:\\studium\\LR2TF_HiWi\\.venv\\Lib\\site-packages\\scanpy\\tools\\_rank_genes_groups.py:455: RuntimeWarning: invalid value encountered in log2\n",
      "  self.stats[group_name, \"logfoldchanges\"] = np.log2(\n",
      "d:\\studium\\LR2TF_HiWi\\.venv\\Lib\\site-packages\\scanpy\\tools\\_rank_genes_groups.py:455: RuntimeWarning: invalid value encountered in log2\n",
      "  self.stats[group_name, \"logfoldchanges\"] = np.log2(\n",
      "d:\\studium\\LR2TF_HiWi\\.venv\\Lib\\site-packages\\scanpy\\tools\\_rank_genes_groups.py:455: RuntimeWarning: invalid value encountered in log2\n",
      "  self.stats[group_name, \"logfoldchanges\"] = np.log2(\n",
      "d:\\studium\\LR2TF_HiWi\\.venv\\Lib\\site-packages\\scanpy\\tools\\_rank_genes_groups.py:455: RuntimeWarning: invalid value encountered in log2\n",
      "  self.stats[group_name, \"logfoldchanges\"] = np.log2(\n",
      "d:\\studium\\LR2TF_HiWi\\.venv\\Lib\\site-packages\\scanpy\\tools\\_rank_genes_groups.py:455: RuntimeWarning: invalid value encountered in log2\n",
      "  self.stats[group_name, \"logfoldchanges\"] = np.log2(\n",
      "d:\\studium\\LR2TF_HiWi\\.venv\\Lib\\site-packages\\scanpy\\tools\\_rank_genes_groups.py:455: RuntimeWarning: invalid value encountered in log2\n",
      "  self.stats[group_name, \"logfoldchanges\"] = np.log2(\n",
      "d:\\studium\\LR2TF_HiWi\\.venv\\Lib\\site-packages\\scanpy\\tools\\_rank_genes_groups.py:455: RuntimeWarning: invalid value encountered in log2\n",
      "  self.stats[group_name, \"logfoldchanges\"] = np.log2(\n",
      "d:\\studium\\LR2TF_HiWi\\.venv\\Lib\\site-packages\\scanpy\\tools\\_rank_genes_groups.py:455: RuntimeWarning: invalid value encountered in log2\n",
      "  self.stats[group_name, \"logfoldchanges\"] = np.log2(\n",
      "C:\\Users\\Larissa\\AppData\\Local\\Temp\\ipykernel_20368\\1923435211.py:49: FutureWarning: ChainedAssignmentError: behaviour will change in pandas 3.0!\n",
      "You are setting values through chained assignment. Currently this works in certain cases, but when using Copy-on-Write (which will become the default behaviour in pandas 3.0) this will never work to update the original DataFrame or Series, because the intermediate object on which we are setting values will behave as a copy.\n",
      "A typical example is when you are setting values in a column of a DataFrame, like:\n",
      "\n",
      "df[\"col\"][row_indexer] = value\n",
      "\n",
      "Use `df.loc[row_indexer, \"col\"] = values` instead, to perform the assignment in a single step and ensure this keeps updating the original `df`.\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "\n",
      "  anndataobject_markers_wilcoxon[\"tag\"].iloc[i,] = eval_pval(anndataobject_markers_wilcoxon[\"pvals_adj\"].iloc[i,])\n",
      "C:\\Users\\Larissa\\AppData\\Local\\Temp\\ipykernel_20368\\1923435211.py:49: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  anndataobject_markers_wilcoxon[\"tag\"].iloc[i,] = eval_pval(anndataobject_markers_wilcoxon[\"pvals_adj\"].iloc[i,])\n",
      "C:\\Users\\Larissa\\AppData\\Local\\Temp\\ipykernel_20368\\1923435211.py:58: FutureWarning: ChainedAssignmentError: behaviour will change in pandas 3.0!\n",
      "You are setting values through chained assignment. Currently this works in certain cases, but when using Copy-on-Write (which will become the default behaviour in pandas 3.0) this will never work to update the original DataFrame or Series, because the intermediate object on which we are setting values will behave as a copy.\n",
      "A typical example is when you are setting values in a column of a DataFrame, like:\n",
      "\n",
      "df[\"col\"][row_indexer] = value\n",
      "\n",
      "Use `df.loc[row_indexer, \"col\"] = values` instead, to perform the assignment in a single step and ensure this keeps updating the original `df`.\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "\n",
      "  anndataobject_markers_t_over[\"tag\"].iloc[i,] = eval_pval(anndataobject_markers_t_over[\"pvals_adj\"].iloc[i,])\n",
      "C:\\Users\\Larissa\\AppData\\Local\\Temp\\ipykernel_20368\\1923435211.py:58: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  anndataobject_markers_t_over[\"tag\"].iloc[i,] = eval_pval(anndataobject_markers_t_over[\"pvals_adj\"].iloc[i,])\n",
      "C:\\Users\\Larissa\\AppData\\Local\\Temp\\ipykernel_20368\\1923435211.py:68: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  res_wilcoxon[\"z_score\"] = 0\n"
     ]
    }
   ],
   "source": [
    "result = tf_activity_analysis(anndataobject= \"LR2TF_test_run/anndata_object.h5ad\", arguments_list= {\"out_path\" : \"script_test\", \"celltype\" : \"new_annotation\", \"condition\" : \"protocol\", \"organism\" : None, \"comparison_list\" : None, \"logfc\" : None, \"pval\" : None, \"reg\" : \"filterd_regulon.csv\", \"tf_activities\" : \"decoupler_results.csv\"})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [],
   "source": [
    "def csv_comparison (result_1, result_2, outpath, suffixes_df=(\"_py\", \"_r\")):\n",
    "    result1 = pd.read_csv(result_1)\n",
    "    result2 = pd.read_csv(result_2)\n",
    "\n",
    "\n",
    "    result1 = result1[result1[\"pvals_adj\"] < 0.05]\n",
    "    if \"p_val_adj\" in result2.columns:\n",
    "        result2 = result2[result2[\"p_val_adj\"] < 0.05]\n",
    "    else:\n",
    "        result2 = result2[result2[\"pvals_adj\"] < 0.05]\n",
    "\n",
    "    result1 = result1.rename(columns={\"names\": \"gene\", \"group\": \"cluster\"})\n",
    "    result2 = result2.rename(columns={\"names\": \"gene\", \"group\": \"cluster\"})\n",
    "\n",
    "\n",
    "    df_output_1 = pd.DataFrame()\n",
    "\n",
    "    for i in range(len(result1)):\n",
    "        a = result1[\"gene\"].iloc[i]\n",
    "        for j in range(len(result2)):\n",
    "            b = result2[\"gene\"].iloc[j]\n",
    "            if a == b:\n",
    "                df_output_1[i] = result1.iloc[i]\n",
    "            \n",
    "\n",
    "    df_output_1 = df_output_1.T\n",
    "\n",
    "    df_output_2 = pd.DataFrame()\n",
    "    for i in range(len(result2)):\n",
    "        a = result2[\"gene\"].iloc[i]\n",
    "        for j in range(len(result1)):\n",
    "            b = result1[\"gene\"].iloc[j]\n",
    "            if a == b:\n",
    "                df_output_2[i] = result2.iloc[i]\n",
    "\n",
    "\n",
    "    df_output_2 = df_output_2.T\n",
    "\n",
    "\n",
    "    df_output = pd.merge(df_output_1, df_output_2, on=\"gene\", suffixes=suffixes_df)\n",
    "\n",
    "    df_output_3 = pd.DataFrame()\n",
    "    for i in range(len(result1)):\n",
    "        a = result1[\"gene\"].iloc[i]\n",
    "        b = list(result2[\"gene\"])\n",
    "        if a not in b:\n",
    "            df_output_3[i] = result1.iloc[i]\n",
    "            \n",
    "    df_output_3 = df_output_3.T\n",
    "    df_output.rename(columns={\"Unnamed: 0\": \"gene_r\"}, inplace=True)\n",
    "    df_output_3.rename(columns={\"cluster\": \"cluster\" + suffixes_df[0]}, inplace=True)\n",
    "    if suffixes_df[0] == \"_py_wilcox\":\n",
    "        df_output_3.rename(columns={\"scores\": \"scores\" + suffixes_df[0], \"logfoldchanges\": \"logfoldchanges\" + suffixes_df[0], \"pvals\": \"pvals\" + suffixes_df[0], \"pvals_adj\": \"pvals_adj\" + suffixes_df[0]}, inplace=True)\n",
    "        df_output_4 = pd.DataFrame()\n",
    "        for i in range(len(result2)):\n",
    "            a = result2[\"gene\"].iloc[i]\n",
    "            b = list(result1[\"gene\"])\n",
    "            if a not in b:\n",
    "                df_output_4[i] = result2.iloc[i]\n",
    "        df_output_4 = df_output_4.T\n",
    "        df_output_4.rename(columns={\"cluster\": \"cluster\" + suffixes_df[1], \"scores\": \"scores\" + suffixes_df[1], \"logfoldchanges\": \"logfoldchanges\" + suffixes_df[1], \"pvals\": \"pvals\" + suffixes_df[1], \"pvals_adj\": \"pvals_adj\" + suffixes_df[1]}, inplace=True)\n",
    "        df_output_3 = pd.concat([df_output_3, df_output_4])\n",
    "        \n",
    "\n",
    "    df_output = pd.concat([df_output, df_output_3])\n",
    "\n",
    "    df_output.to_csv(outpath, index=0)\n",
    "    print(df_output_3.columns)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Larissa\\AppData\\Local\\Temp\\ipykernel_20368\\1777656135.py:23: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_output_1[i] = result1.iloc[i]\n",
      "C:\\Users\\Larissa\\AppData\\Local\\Temp\\ipykernel_20368\\1777656135.py:23: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_output_1[i] = result1.iloc[i]\n",
      "C:\\Users\\Larissa\\AppData\\Local\\Temp\\ipykernel_20368\\1777656135.py:23: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_output_1[i] = result1.iloc[i]\n",
      "C:\\Users\\Larissa\\AppData\\Local\\Temp\\ipykernel_20368\\1777656135.py:23: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_output_1[i] = result1.iloc[i]\n",
      "C:\\Users\\Larissa\\AppData\\Local\\Temp\\ipykernel_20368\\1777656135.py:23: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_output_1[i] = result1.iloc[i]\n",
      "C:\\Users\\Larissa\\AppData\\Local\\Temp\\ipykernel_20368\\1777656135.py:23: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_output_1[i] = result1.iloc[i]\n",
      "C:\\Users\\Larissa\\AppData\\Local\\Temp\\ipykernel_20368\\1777656135.py:23: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_output_1[i] = result1.iloc[i]\n",
      "C:\\Users\\Larissa\\AppData\\Local\\Temp\\ipykernel_20368\\1777656135.py:23: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_output_1[i] = result1.iloc[i]\n",
      "C:\\Users\\Larissa\\AppData\\Local\\Temp\\ipykernel_20368\\1777656135.py:23: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_output_1[i] = result1.iloc[i]\n",
      "C:\\Users\\Larissa\\AppData\\Local\\Temp\\ipykernel_20368\\1777656135.py:23: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_output_1[i] = result1.iloc[i]\n",
      "C:\\Users\\Larissa\\AppData\\Local\\Temp\\ipykernel_20368\\1777656135.py:23: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_output_1[i] = result1.iloc[i]\n",
      "C:\\Users\\Larissa\\AppData\\Local\\Temp\\ipykernel_20368\\1777656135.py:23: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_output_1[i] = result1.iloc[i]\n",
      "C:\\Users\\Larissa\\AppData\\Local\\Temp\\ipykernel_20368\\1777656135.py:23: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_output_1[i] = result1.iloc[i]\n",
      "C:\\Users\\Larissa\\AppData\\Local\\Temp\\ipykernel_20368\\1777656135.py:23: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_output_1[i] = result1.iloc[i]\n",
      "C:\\Users\\Larissa\\AppData\\Local\\Temp\\ipykernel_20368\\1777656135.py:23: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_output_1[i] = result1.iloc[i]\n",
      "C:\\Users\\Larissa\\AppData\\Local\\Temp\\ipykernel_20368\\1777656135.py:23: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_output_1[i] = result1.iloc[i]\n",
      "C:\\Users\\Larissa\\AppData\\Local\\Temp\\ipykernel_20368\\1777656135.py:23: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_output_1[i] = result1.iloc[i]\n",
      "C:\\Users\\Larissa\\AppData\\Local\\Temp\\ipykernel_20368\\1777656135.py:23: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_output_1[i] = result1.iloc[i]\n",
      "C:\\Users\\Larissa\\AppData\\Local\\Temp\\ipykernel_20368\\1777656135.py:23: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_output_1[i] = result1.iloc[i]\n",
      "C:\\Users\\Larissa\\AppData\\Local\\Temp\\ipykernel_20368\\1777656135.py:23: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_output_1[i] = result1.iloc[i]\n",
      "C:\\Users\\Larissa\\AppData\\Local\\Temp\\ipykernel_20368\\1777656135.py:23: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_output_1[i] = result1.iloc[i]\n",
      "C:\\Users\\Larissa\\AppData\\Local\\Temp\\ipykernel_20368\\1777656135.py:23: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_output_1[i] = result1.iloc[i]\n",
      "C:\\Users\\Larissa\\AppData\\Local\\Temp\\ipykernel_20368\\1777656135.py:23: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_output_1[i] = result1.iloc[i]\n",
      "C:\\Users\\Larissa\\AppData\\Local\\Temp\\ipykernel_20368\\1777656135.py:23: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_output_1[i] = result1.iloc[i]\n",
      "C:\\Users\\Larissa\\AppData\\Local\\Temp\\ipykernel_20368\\1777656135.py:23: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_output_1[i] = result1.iloc[i]\n",
      "C:\\Users\\Larissa\\AppData\\Local\\Temp\\ipykernel_20368\\1777656135.py:23: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_output_1[i] = result1.iloc[i]\n",
      "C:\\Users\\Larissa\\AppData\\Local\\Temp\\ipykernel_20368\\1777656135.py:34: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_output_2[i] = result2.iloc[i]\n",
      "C:\\Users\\Larissa\\AppData\\Local\\Temp\\ipykernel_20368\\1777656135.py:34: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_output_2[i] = result2.iloc[i]\n",
      "C:\\Users\\Larissa\\AppData\\Local\\Temp\\ipykernel_20368\\1777656135.py:34: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_output_2[i] = result2.iloc[i]\n",
      "C:\\Users\\Larissa\\AppData\\Local\\Temp\\ipykernel_20368\\1777656135.py:34: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_output_2[i] = result2.iloc[i]\n",
      "C:\\Users\\Larissa\\AppData\\Local\\Temp\\ipykernel_20368\\1777656135.py:34: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_output_2[i] = result2.iloc[i]\n",
      "C:\\Users\\Larissa\\AppData\\Local\\Temp\\ipykernel_20368\\1777656135.py:34: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_output_2[i] = result2.iloc[i]\n",
      "C:\\Users\\Larissa\\AppData\\Local\\Temp\\ipykernel_20368\\1777656135.py:34: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_output_2[i] = result2.iloc[i]\n",
      "C:\\Users\\Larissa\\AppData\\Local\\Temp\\ipykernel_20368\\1777656135.py:34: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_output_2[i] = result2.iloc[i]\n",
      "C:\\Users\\Larissa\\AppData\\Local\\Temp\\ipykernel_20368\\1777656135.py:34: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_output_2[i] = result2.iloc[i]\n",
      "C:\\Users\\Larissa\\AppData\\Local\\Temp\\ipykernel_20368\\1777656135.py:34: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_output_2[i] = result2.iloc[i]\n",
      "C:\\Users\\Larissa\\AppData\\Local\\Temp\\ipykernel_20368\\1777656135.py:34: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_output_2[i] = result2.iloc[i]\n",
      "C:\\Users\\Larissa\\AppData\\Local\\Temp\\ipykernel_20368\\1777656135.py:34: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_output_2[i] = result2.iloc[i]\n",
      "C:\\Users\\Larissa\\AppData\\Local\\Temp\\ipykernel_20368\\1777656135.py:34: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_output_2[i] = result2.iloc[i]\n",
      "C:\\Users\\Larissa\\AppData\\Local\\Temp\\ipykernel_20368\\1777656135.py:34: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_output_2[i] = result2.iloc[i]\n",
      "C:\\Users\\Larissa\\AppData\\Local\\Temp\\ipykernel_20368\\1777656135.py:34: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_output_2[i] = result2.iloc[i]\n",
      "C:\\Users\\Larissa\\AppData\\Local\\Temp\\ipykernel_20368\\1777656135.py:34: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_output_2[i] = result2.iloc[i]\n",
      "C:\\Users\\Larissa\\AppData\\Local\\Temp\\ipykernel_20368\\1777656135.py:34: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_output_2[i] = result2.iloc[i]\n",
      "C:\\Users\\Larissa\\AppData\\Local\\Temp\\ipykernel_20368\\1777656135.py:34: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_output_2[i] = result2.iloc[i]\n",
      "C:\\Users\\Larissa\\AppData\\Local\\Temp\\ipykernel_20368\\1777656135.py:34: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_output_2[i] = result2.iloc[i]\n",
      "C:\\Users\\Larissa\\AppData\\Local\\Temp\\ipykernel_20368\\1777656135.py:34: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_output_2[i] = result2.iloc[i]\n",
      "C:\\Users\\Larissa\\AppData\\Local\\Temp\\ipykernel_20368\\1777656135.py:34: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_output_2[i] = result2.iloc[i]\n",
      "C:\\Users\\Larissa\\AppData\\Local\\Temp\\ipykernel_20368\\1777656135.py:34: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_output_2[i] = result2.iloc[i]\n",
      "C:\\Users\\Larissa\\AppData\\Local\\Temp\\ipykernel_20368\\1777656135.py:47: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_output_3[i] = result1.iloc[i]\n",
      "C:\\Users\\Larissa\\AppData\\Local\\Temp\\ipykernel_20368\\1777656135.py:47: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_output_3[i] = result1.iloc[i]\n",
      "C:\\Users\\Larissa\\AppData\\Local\\Temp\\ipykernel_20368\\1777656135.py:47: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_output_3[i] = result1.iloc[i]\n",
      "C:\\Users\\Larissa\\AppData\\Local\\Temp\\ipykernel_20368\\1777656135.py:47: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_output_3[i] = result1.iloc[i]\n",
      "C:\\Users\\Larissa\\AppData\\Local\\Temp\\ipykernel_20368\\1777656135.py:47: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_output_3[i] = result1.iloc[i]\n",
      "C:\\Users\\Larissa\\AppData\\Local\\Temp\\ipykernel_20368\\1777656135.py:47: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_output_3[i] = result1.iloc[i]\n",
      "C:\\Users\\Larissa\\AppData\\Local\\Temp\\ipykernel_20368\\1777656135.py:47: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_output_3[i] = result1.iloc[i]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['cluster_py', 'gene', 'scores', 'logfoldchanges', 'pvals', 'pvals_adj',\n",
      "       'tag'],\n",
      "      dtype='object')\n",
      "Index(['cluster_py', 'gene', 'scores', 'logfoldchanges', 'pvals', 'pvals_adj',\n",
      "       'tag'],\n",
      "      dtype='object')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Larissa\\AppData\\Local\\Temp\\ipykernel_20368\\1777656135.py:23: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_output_1[i] = result1.iloc[i]\n",
      "C:\\Users\\Larissa\\AppData\\Local\\Temp\\ipykernel_20368\\1777656135.py:23: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_output_1[i] = result1.iloc[i]\n",
      "C:\\Users\\Larissa\\AppData\\Local\\Temp\\ipykernel_20368\\1777656135.py:23: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_output_1[i] = result1.iloc[i]\n",
      "C:\\Users\\Larissa\\AppData\\Local\\Temp\\ipykernel_20368\\1777656135.py:23: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_output_1[i] = result1.iloc[i]\n",
      "C:\\Users\\Larissa\\AppData\\Local\\Temp\\ipykernel_20368\\1777656135.py:23: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_output_1[i] = result1.iloc[i]\n",
      "C:\\Users\\Larissa\\AppData\\Local\\Temp\\ipykernel_20368\\1777656135.py:23: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_output_1[i] = result1.iloc[i]\n",
      "C:\\Users\\Larissa\\AppData\\Local\\Temp\\ipykernel_20368\\1777656135.py:23: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_output_1[i] = result1.iloc[i]\n",
      "C:\\Users\\Larissa\\AppData\\Local\\Temp\\ipykernel_20368\\1777656135.py:23: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_output_1[i] = result1.iloc[i]\n",
      "C:\\Users\\Larissa\\AppData\\Local\\Temp\\ipykernel_20368\\1777656135.py:23: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_output_1[i] = result1.iloc[i]\n",
      "C:\\Users\\Larissa\\AppData\\Local\\Temp\\ipykernel_20368\\1777656135.py:23: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_output_1[i] = result1.iloc[i]\n",
      "C:\\Users\\Larissa\\AppData\\Local\\Temp\\ipykernel_20368\\1777656135.py:23: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_output_1[i] = result1.iloc[i]\n",
      "C:\\Users\\Larissa\\AppData\\Local\\Temp\\ipykernel_20368\\1777656135.py:23: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_output_1[i] = result1.iloc[i]\n",
      "C:\\Users\\Larissa\\AppData\\Local\\Temp\\ipykernel_20368\\1777656135.py:23: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_output_1[i] = result1.iloc[i]\n",
      "C:\\Users\\Larissa\\AppData\\Local\\Temp\\ipykernel_20368\\1777656135.py:23: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_output_1[i] = result1.iloc[i]\n",
      "C:\\Users\\Larissa\\AppData\\Local\\Temp\\ipykernel_20368\\1777656135.py:23: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_output_1[i] = result1.iloc[i]\n",
      "C:\\Users\\Larissa\\AppData\\Local\\Temp\\ipykernel_20368\\1777656135.py:23: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_output_1[i] = result1.iloc[i]\n",
      "C:\\Users\\Larissa\\AppData\\Local\\Temp\\ipykernel_20368\\1777656135.py:23: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_output_1[i] = result1.iloc[i]\n",
      "C:\\Users\\Larissa\\AppData\\Local\\Temp\\ipykernel_20368\\1777656135.py:23: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_output_1[i] = result1.iloc[i]\n",
      "C:\\Users\\Larissa\\AppData\\Local\\Temp\\ipykernel_20368\\1777656135.py:23: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_output_1[i] = result1.iloc[i]\n",
      "C:\\Users\\Larissa\\AppData\\Local\\Temp\\ipykernel_20368\\1777656135.py:23: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_output_1[i] = result1.iloc[i]\n",
      "C:\\Users\\Larissa\\AppData\\Local\\Temp\\ipykernel_20368\\1777656135.py:23: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_output_1[i] = result1.iloc[i]\n",
      "C:\\Users\\Larissa\\AppData\\Local\\Temp\\ipykernel_20368\\1777656135.py:23: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_output_1[i] = result1.iloc[i]\n",
      "C:\\Users\\Larissa\\AppData\\Local\\Temp\\ipykernel_20368\\1777656135.py:23: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_output_1[i] = result1.iloc[i]\n",
      "C:\\Users\\Larissa\\AppData\\Local\\Temp\\ipykernel_20368\\1777656135.py:23: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_output_1[i] = result1.iloc[i]\n",
      "C:\\Users\\Larissa\\AppData\\Local\\Temp\\ipykernel_20368\\1777656135.py:23: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_output_1[i] = result1.iloc[i]\n",
      "C:\\Users\\Larissa\\AppData\\Local\\Temp\\ipykernel_20368\\1777656135.py:23: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_output_1[i] = result1.iloc[i]\n",
      "C:\\Users\\Larissa\\AppData\\Local\\Temp\\ipykernel_20368\\1777656135.py:23: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_output_1[i] = result1.iloc[i]\n",
      "C:\\Users\\Larissa\\AppData\\Local\\Temp\\ipykernel_20368\\1777656135.py:23: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_output_1[i] = result1.iloc[i]\n",
      "C:\\Users\\Larissa\\AppData\\Local\\Temp\\ipykernel_20368\\1777656135.py:23: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_output_1[i] = result1.iloc[i]\n",
      "C:\\Users\\Larissa\\AppData\\Local\\Temp\\ipykernel_20368\\1777656135.py:23: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_output_1[i] = result1.iloc[i]\n",
      "C:\\Users\\Larissa\\AppData\\Local\\Temp\\ipykernel_20368\\1777656135.py:23: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_output_1[i] = result1.iloc[i]\n",
      "C:\\Users\\Larissa\\AppData\\Local\\Temp\\ipykernel_20368\\1777656135.py:23: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_output_1[i] = result1.iloc[i]\n",
      "C:\\Users\\Larissa\\AppData\\Local\\Temp\\ipykernel_20368\\1777656135.py:23: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_output_1[i] = result1.iloc[i]\n",
      "C:\\Users\\Larissa\\AppData\\Local\\Temp\\ipykernel_20368\\1777656135.py:23: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_output_1[i] = result1.iloc[i]\n",
      "C:\\Users\\Larissa\\AppData\\Local\\Temp\\ipykernel_20368\\1777656135.py:34: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_output_2[i] = result2.iloc[i]\n",
      "C:\\Users\\Larissa\\AppData\\Local\\Temp\\ipykernel_20368\\1777656135.py:34: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_output_2[i] = result2.iloc[i]\n",
      "C:\\Users\\Larissa\\AppData\\Local\\Temp\\ipykernel_20368\\1777656135.py:34: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_output_2[i] = result2.iloc[i]\n",
      "C:\\Users\\Larissa\\AppData\\Local\\Temp\\ipykernel_20368\\1777656135.py:34: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_output_2[i] = result2.iloc[i]\n",
      "C:\\Users\\Larissa\\AppData\\Local\\Temp\\ipykernel_20368\\1777656135.py:34: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_output_2[i] = result2.iloc[i]\n",
      "C:\\Users\\Larissa\\AppData\\Local\\Temp\\ipykernel_20368\\1777656135.py:34: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_output_2[i] = result2.iloc[i]\n",
      "C:\\Users\\Larissa\\AppData\\Local\\Temp\\ipykernel_20368\\1777656135.py:34: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_output_2[i] = result2.iloc[i]\n",
      "C:\\Users\\Larissa\\AppData\\Local\\Temp\\ipykernel_20368\\1777656135.py:34: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_output_2[i] = result2.iloc[i]\n",
      "C:\\Users\\Larissa\\AppData\\Local\\Temp\\ipykernel_20368\\1777656135.py:34: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_output_2[i] = result2.iloc[i]\n",
      "C:\\Users\\Larissa\\AppData\\Local\\Temp\\ipykernel_20368\\1777656135.py:34: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_output_2[i] = result2.iloc[i]\n",
      "C:\\Users\\Larissa\\AppData\\Local\\Temp\\ipykernel_20368\\1777656135.py:34: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_output_2[i] = result2.iloc[i]\n",
      "C:\\Users\\Larissa\\AppData\\Local\\Temp\\ipykernel_20368\\1777656135.py:34: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_output_2[i] = result2.iloc[i]\n",
      "C:\\Users\\Larissa\\AppData\\Local\\Temp\\ipykernel_20368\\1777656135.py:34: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_output_2[i] = result2.iloc[i]\n",
      "C:\\Users\\Larissa\\AppData\\Local\\Temp\\ipykernel_20368\\1777656135.py:34: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_output_2[i] = result2.iloc[i]\n",
      "C:\\Users\\Larissa\\AppData\\Local\\Temp\\ipykernel_20368\\1777656135.py:34: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_output_2[i] = result2.iloc[i]\n",
      "C:\\Users\\Larissa\\AppData\\Local\\Temp\\ipykernel_20368\\1777656135.py:34: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_output_2[i] = result2.iloc[i]\n",
      "C:\\Users\\Larissa\\AppData\\Local\\Temp\\ipykernel_20368\\1777656135.py:34: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_output_2[i] = result2.iloc[i]\n",
      "C:\\Users\\Larissa\\AppData\\Local\\Temp\\ipykernel_20368\\1777656135.py:34: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_output_2[i] = result2.iloc[i]\n",
      "C:\\Users\\Larissa\\AppData\\Local\\Temp\\ipykernel_20368\\1777656135.py:34: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_output_2[i] = result2.iloc[i]\n",
      "C:\\Users\\Larissa\\AppData\\Local\\Temp\\ipykernel_20368\\1777656135.py:34: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_output_2[i] = result2.iloc[i]\n",
      "C:\\Users\\Larissa\\AppData\\Local\\Temp\\ipykernel_20368\\1777656135.py:34: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_output_2[i] = result2.iloc[i]\n",
      "C:\\Users\\Larissa\\AppData\\Local\\Temp\\ipykernel_20368\\1777656135.py:34: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_output_2[i] = result2.iloc[i]\n",
      "C:\\Users\\Larissa\\AppData\\Local\\Temp\\ipykernel_20368\\1777656135.py:34: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_output_2[i] = result2.iloc[i]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['cluster_py_wilcox', 'gene', 'scores_py_wilcox',\n",
      "       'logfoldchanges_py_wilcox', 'pvals_py_wilcox', 'pvals_adj_py_wilcox',\n",
      "       'tag', 'cluster_py_t_test', 'scores_py_t_test',\n",
      "       'logfoldchanges_py_t_test', 'pvals_py_t_test', 'pvals_adj_py_t_test'],\n",
      "      dtype='object')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Larissa\\AppData\\Local\\Temp\\ipykernel_20368\\1777656135.py:23: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_output_1[i] = result1.iloc[i]\n",
      "C:\\Users\\Larissa\\AppData\\Local\\Temp\\ipykernel_20368\\1777656135.py:23: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_output_1[i] = result1.iloc[i]\n",
      "C:\\Users\\Larissa\\AppData\\Local\\Temp\\ipykernel_20368\\1777656135.py:23: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_output_1[i] = result1.iloc[i]\n",
      "C:\\Users\\Larissa\\AppData\\Local\\Temp\\ipykernel_20368\\1777656135.py:23: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_output_1[i] = result1.iloc[i]\n",
      "C:\\Users\\Larissa\\AppData\\Local\\Temp\\ipykernel_20368\\1777656135.py:23: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_output_1[i] = result1.iloc[i]\n",
      "C:\\Users\\Larissa\\AppData\\Local\\Temp\\ipykernel_20368\\1777656135.py:23: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_output_1[i] = result1.iloc[i]\n",
      "C:\\Users\\Larissa\\AppData\\Local\\Temp\\ipykernel_20368\\1777656135.py:23: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_output_1[i] = result1.iloc[i]\n",
      "C:\\Users\\Larissa\\AppData\\Local\\Temp\\ipykernel_20368\\1777656135.py:34: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_output_2[i] = result2.iloc[i]\n",
      "C:\\Users\\Larissa\\AppData\\Local\\Temp\\ipykernel_20368\\1777656135.py:34: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_output_2[i] = result2.iloc[i]\n",
      "C:\\Users\\Larissa\\AppData\\Local\\Temp\\ipykernel_20368\\1777656135.py:34: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_output_2[i] = result2.iloc[i]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['cluster_py', 'gene', 'scores', 'logfoldchanges', 'pvals', 'pvals_adj',\n",
      "       'tag'],\n",
      "      dtype='object')\n",
      "Index(['cluster_py', 'gene', 'scores', 'logfoldchanges', 'pvals', 'pvals_adj',\n",
      "       'tag'],\n",
      "      dtype='object')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Larissa\\AppData\\Local\\Temp\\ipykernel_20368\\1777656135.py:23: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_output_1[i] = result1.iloc[i]\n",
      "C:\\Users\\Larissa\\AppData\\Local\\Temp\\ipykernel_20368\\1777656135.py:23: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_output_1[i] = result1.iloc[i]\n",
      "C:\\Users\\Larissa\\AppData\\Local\\Temp\\ipykernel_20368\\1777656135.py:23: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_output_1[i] = result1.iloc[i]\n",
      "C:\\Users\\Larissa\\AppData\\Local\\Temp\\ipykernel_20368\\1777656135.py:23: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_output_1[i] = result1.iloc[i]\n",
      "C:\\Users\\Larissa\\AppData\\Local\\Temp\\ipykernel_20368\\1777656135.py:23: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_output_1[i] = result1.iloc[i]\n",
      "C:\\Users\\Larissa\\AppData\\Local\\Temp\\ipykernel_20368\\1777656135.py:23: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_output_1[i] = result1.iloc[i]\n",
      "C:\\Users\\Larissa\\AppData\\Local\\Temp\\ipykernel_20368\\1777656135.py:23: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_output_1[i] = result1.iloc[i]\n",
      "C:\\Users\\Larissa\\AppData\\Local\\Temp\\ipykernel_20368\\1777656135.py:23: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_output_1[i] = result1.iloc[i]\n",
      "C:\\Users\\Larissa\\AppData\\Local\\Temp\\ipykernel_20368\\1777656135.py:23: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_output_1[i] = result1.iloc[i]\n",
      "C:\\Users\\Larissa\\AppData\\Local\\Temp\\ipykernel_20368\\1777656135.py:23: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_output_1[i] = result1.iloc[i]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['cluster_py_wilcox', 'gene', 'scores_py_wilcox',\n",
      "       'logfoldchanges_py_wilcox', 'pvals_py_wilcox', 'pvals_adj_py_wilcox',\n",
      "       'tag', 'cluster_py_t_test', 'scores_py_t_test',\n",
      "       'logfoldchanges_py_t_test', 'pvals_py_t_test', 'pvals_adj_py_t_test'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "#CONTROL\n",
    "#comparison python wilcoxon and r wilcoxon control\n",
    "csv_comparison(\"script_test\\\\TF_results\\\\control\\\\control_specific_markers_wilcoxon_test.csv\", \"LR2TF_test_run\\\\results\\\\TF_results\\\\control\\\\all_specificmarker__control.csv\",\n",
    "                \"tf_comparison_r_py\\\\py_wilcoxon_r_same_genes_control_filtered.csv\", suffixes_df=(\"_py\", \"_r\"))\n",
    "\n",
    "#comparison python t test and r wilcoxon control\n",
    "csv_comparison(\"script_test\\\\TF_results\\\\control\\\\control_specific_markers_t_test_overestim_test.csv\", \"LR2TF_test_run\\\\results\\\\TF_results\\\\control\\\\all_specificmarker__control.csv\",\n",
    "                \"tf_comparison_r_py\\\\py_t_test_r_same_genes_control_filtered.csv\", suffixes_df=(\"_py\", \"_r\"))\n",
    "\n",
    "# py wilcox vs py t test control\n",
    "\n",
    "csv_comparison(\"script_test\\\\TF_results\\\\control\\\\control_specific_markers_wilcoxon_test.csv\", \"script_test\\\\TF_results\\\\control\\\\control_specific_markers_t_test_overestim_test.csv\",\n",
    "                \"tf_comparison_r_py\\\\py_wilcox_py_t_test_same_genes_control_filtered.csv\", suffixes_df=(\"_py_wilcox\", \"_py_t_test\"))\n",
    "################################################################################################################################################################################################\n",
    "#PMF MF2\n",
    "#python wilcox vs r wilcox PMF MF2\n",
    "csv_comparison(\"script_test\\\\TF_results\\\\PMF_MF2\\\\PMF_MF2_specific_markers_wilcoxon_test.csv\", \"LR2TF_test_run\\\\results\\\\TF_results\\\\PMF_MF2\\\\all_specificmarker__PMF_MF2.csv\",\n",
    "                \"tf_comparison_r_py\\\\py_wilcoxon_r_same_genes_PMF_MF2_filtered.csv\", suffixes_df=(\"_py\", \"_r\"))\n",
    "\n",
    "#comparison python t test and r wilcoxon PMF MF2\n",
    "csv_comparison(\"script_test\\\\TF_results\\\\PMF_MF2\\\\PMF_MF2_specific_markers_t_test_overestim_test.csv\", \"LR2TF_test_run\\\\results\\\\TF_results\\\\PMF_MF2\\\\all_specificmarker__PMF_MF2.csv\",\n",
    "                \"tf_comparison_r_py\\\\py_t_test_r_same_genes_PMF_MF2_filtered.csv\", suffixes_df=(\"_py\", \"_r\"))\n",
    "\n",
    "csv_comparison(\"script_test\\\\TF_results\\\\PMF_MF2\\\\PMF_MF2_specific_markers_wilcoxon_test.csv\", \"script_test\\\\TF_results\\\\PMF_MF2\\\\PMF_MF2_specific_markers_t_test_overestim_test.csv\",\n",
    "                \"tf_comparison_r_py\\\\py_wilcox_py_t_test_same_genes_PMF_MF2_filtered.csv\", suffixes_df=(\"_py_wilcox\", \"_py_t_test\"))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
