{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import anndata as ad\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import scanpy as sc\n",
    "import decoupler as dc\n",
    "import os\n",
    "import re\n",
    "import statistics\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def validate_input_arguments (arguments_list):\n",
    "    if arguments_list[\"out_path\"] is None:\n",
    "        print(\"Please provide an output path\")\n",
    "    elif arguments_list[\"out_path\"][-1] != \"/\":\n",
    "        arguments_list[\"out_path\"] = arguments_list[\"out_path\"] + \"/\"\n",
    "\n",
    "    if arguments_list[\"celltype\"] is None:\n",
    "        print(\"Please provide the name of the metadata field containing cell type annotations\")\n",
    "\n",
    "    if arguments_list[\"condition\"] is None:\n",
    "        print(\"Please provide the name of the metadata field containing condition annotations\")\n",
    "\n",
    "    if arguments_list[\"organism\"] is None:\n",
    "        arguments_list[\"organism\"] = \"human\"\n",
    "\n",
    "    if arguments_list[\"comparison_list\"] is None:\n",
    "        arguments_list[\"comparison_list\"] = np.nan\n",
    "\n",
    "    if arguments_list[\"logfc\"] is None:\n",
    "        arguments_list[\"logfc\"] = 0.0\n",
    "\n",
    "    if arguments_list [\"pval\"] is None:\n",
    "        arguments_list[\"pval\"] = 0.05\n",
    "\n",
    "    if arguments_list[\"reg\"] is None:\n",
    "        arguments_list[\"reg\"] = load_dorothea_regulon(arguments_list[\"organism\"])\n",
    "\n",
    "    elif isinstance(arguments_list[\"reg\"], str):\n",
    "        arguments_list[\"reg\"] = pd.read_csv(arguments_list[\"reg\"], index_col=0)\n",
    "        arguments_list[\"reg\"] = pd.DataFrame.rename(arguments_list[\"reg\"], columns={\"source\" : \"tf\"})\n",
    "\n",
    "    if not \"tf\" in arguments_list[\"reg\"] and \"target\" in arguments_list[\"reg\"] and \"weight\"in arguments_list[\"reg\"]:\n",
    "        raise Exception(\"Not all necessary columns found in regulon table! Please make sure that the regulon has the columns source, target and weight!\")\n",
    "    \n",
    " \n",
    "   \n",
    "    return(arguments_list)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TFObj:\n",
    "    def __init__(self,\n",
    "    tf_activities_condition : list,\n",
    "    tf_activities_cluster : list,\n",
    "    average_gene_expression : list,\n",
    "    regulon : pd.DataFrame,\n",
    "    CTR_input_condition : list,\n",
    "    CTR_input_cluster : list,\n",
    "    intracellular_network_condition : list,\n",
    "    intracellular_network_cluster : list):\n",
    "\n",
    "        self.tf_activities_condition = tf_activities_condition\n",
    "        self.tf_activities_cluster = tf_activities_cluster\n",
    "        self.average_gene_expression = average_gene_expression\n",
    "        self.regulon = regulon\n",
    "        self.CTR_input_condition = CTR_input_condition\n",
    "        self.CTR_input_cluster = CTR_input_cluster\n",
    "        self.intracellular_network_condition = intracellular_network_condition\n",
    "        self.intracellular_network_cluster = intracellular_network_cluster\n",
    "\n",
    "def make_TFOBj(tf_activities_condition : list,\n",
    "    tf_activities_cluster : list,\n",
    "    average_gene_expression : list,\n",
    "    regulon : pd.DataFrame,\n",
    "    CTR_input_condition : list,\n",
    "    CTR_input_cluster : list,\n",
    "    intracellular_network_condition : list,\n",
    "    intracellular_network_cluster : list):\n",
    "\n",
    "        tf = TFObj(tf_activities_condition,\n",
    "            tf_activities_cluster,\n",
    "            average_gene_expression,\n",
    "            regulon,\n",
    "            CTR_input_condition,\n",
    "            CTR_input_cluster,\n",
    "            intracellular_network_condition,\n",
    "            intracellular_network_cluster)\n",
    "\n",
    "        return tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def AverageExpression(sub_object, celltype = None, name_iterable = None, outpath = None):\n",
    "    gene_ids = sub_object.var.index.values\n",
    "    #cluster line even necessary if not returned?\n",
    "    #clusters = anndataobject.obs[celltype].cat.categories\n",
    "    obs = sub_object[:,gene_ids].X.toarray()\n",
    "    obs = np.expm1(obs)\n",
    "    avg_df = pd.DataFrame(obs,columns=gene_ids,index= sub_object.obs[celltype])\n",
    "    avg_df = avg_df.groupby(level=0, observed=False).mean()\n",
    "    avg_df.T.to_csv(outpath + name_iterable + \"_average_gene_expression_by_cluster_exp.csv\")\n",
    "\n",
    "    return avg_df.T\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def eval_pval(p_val):\n",
    "    p_val = float(p_val)\n",
    "    if p_val < 0.001: \n",
    "      txt = \"***\"\n",
    "    elif p_val < 0.01: \n",
    "      txt = \"**\"\n",
    "    elif p_val < 0.05: \n",
    "      txt = \"*\"\n",
    "    else:\n",
    "      txt = \"ns\"\n",
    "    return(txt)\n",
    "\n",
    "\n",
    "def eval_log_fc_tag(log_fc):\n",
    "    if log_fc >= 1.0: \n",
    "      txt = \"***\"\n",
    "    elif log_fc > 0.5: \n",
    "      txt = \"**\"\n",
    "    elif log_fc > 0.0: \n",
    "      txt = \"*\"\n",
    "    else:\n",
    "      txt = \"ns\"\n",
    "    return(txt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_unfiltered_tf_scores(tf_scores_df, condition, celltype, out_path):   \n",
    "    summarized_tf_scores_df = tf_scores_df.groupby(celltype, observed = True).mean().T\n",
    "    #tf_scores_df.groupby(celltype, observed = True).apply(display)\n",
    "    #agg([\"mean\", \"var\"])\n",
    "    summarized_tf_scores_df.to_csv(out_path + \"/unfiltered_tf_scores_\" + condition + \".csv\")\n",
    "    return summarized_tf_scores_df\n",
    "\n",
    "#np.var() returns a value that is different from R's var(), whereas statistics.variance() is the same as R's var()\n",
    "def save_variable_tf_score(filtered_summarized_tf_scores_df, condition, out_path, plot):\n",
    "    filtered_summarized_tf_scores_df[\"var\"] = filtered_summarized_tf_scores_df.apply(statistics.variance, axis=1).unique()\n",
    "    filtered_summarized_tf_scores_df.to_csv(out_path + \"/variable_tf_scores_\" + condition + \".csv\")\n",
    "\n",
    "    if plot:\n",
    "        top_variable_tfs = filtered_summarized_tf_scores_df.sort_values(\"var\", ascending=False).head(n=20).drop(columns=\"var\")\n",
    "        fig, ax = plt.subplots(figsize=(8,7))   \n",
    "        ax = sns.heatmap(top_variable_tfs, cmap=\"vlag\", center=0, vmin=top_variable_tfs.min(axis=None), cbar_kws={\"label\": \"z-score\"})\n",
    "        ax.set(xlabel=\"Cell Type\", ylabel=\"Transcription Factor\")\n",
    "        ax.get_figure()\n",
    "        plt.savefig(out_path + \"/tf_activity_top20_variable_\" + condition + \".pdf\")\n",
    "        plt.close()\n",
    "\n",
    "    filtered_summarized_tf_scores_df_var = filtered_summarized_tf_scores_df\n",
    "    return filtered_summarized_tf_scores_df_var\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_tf_activity(filtered_summarized_tf_scores_df, tag_mapping, condition, out_path):\n",
    "    filtered_summarized_tf_scores_df = filtered_summarized_tf_scores_df.drop(columns=\"var\")\n",
    "    sns.clustermap(filtered_summarized_tf_scores_df, cbar_kws={\"label\": \"z-score\"}, figsize=(8,7), cmap=\"vlag\", center=0, yticklabels=False)\n",
    "    plt.savefig(out_path + \"/tf_activity_compressed_\" + condition + \".pdf\")\n",
    "    plt.close()\n",
    "\n",
    "    sns.clustermap(filtered_summarized_tf_scores_df, cbar_kws={\"label\": \"z-score\"}, figsize=(8,50), cmap=\"vlag\", center=0, annot= tag_mapping, fmt=\"\")\n",
    "    plt.savefig(out_path + \"/tf_activity_\" + condition + \".pdf\")\n",
    "    plt.close()\n",
    "\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def map_z_value_filtered(filtered_summarized_tf_scores_df, anndataobject_markers):\n",
    "    genes = []\n",
    "    clusters = []\n",
    "    z_scores = []  \n",
    "\n",
    "    anndataobject_markers = anndataobject_markers.set_index(\"gene\")\n",
    "    #print(filtered_summarized_tf_scores_df)\n",
    "    \n",
    "    for i in range(len(anndataobject_markers.index)):\n",
    "        a = anndataobject_markers.index[i]\n",
    "        for j in range(len(filtered_summarized_tf_scores_df.index)):\n",
    "            b = filtered_summarized_tf_scores_df.index[j]\n",
    "            if a == b:\n",
    "                c = anndataobject_markers.columns.get_loc(\"cluster\")\n",
    "                cluster = anndataobject_markers.iloc[i, c]\n",
    "                gene_rows = filtered_summarized_tf_scores_df.iloc[j]\n",
    "                if isinstance(gene_rows, pd.Series):\n",
    "                    gene_rows = gene_rows.to_frame().T\n",
    "\n",
    "                for _, gene_row in gene_rows.iterrows():\n",
    "                     score = gene_row[cluster]\n",
    "                     genes.append(a)\n",
    "                     clusters.append(cluster)\n",
    "                     z_scores.append(score)\n",
    "\n",
    "    z_score_df = pd.DataFrame({\n",
    "        'gene': genes,\n",
    "        'cluster': clusters,\n",
    "        'z_score': z_scores\n",
    "    })\n",
    "\n",
    "    return z_score_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_significant_tfs_single(tf_activities_sub, celltype, condition, out_path, pval, logfc, name, plot):\n",
    "    \n",
    "    #does not work if condition is None\n",
    "    renamed_condition = condition.replace(\",\", \"_\")\n",
    "    name = name.replace(\",\", \"_\")\n",
    "\n",
    "    single_result_path = out_path + renamed_condition \n",
    "    if not os.path.isdir(single_result_path):\n",
    "        os.mkdir(single_result_path)\n",
    "\n",
    "    tf_activities_scaled = sc.pp.scale(tf_activities_sub, copy= True)\n",
    "\n",
    "    #tf_activities_sub = sc.pp.normalize_total(tf_activities_scaled, copy=True)\n",
    "    #tf_activities_sub = sc.pp.log1p(tf_activities_sub, copy=True) \n",
    "    # \"warning: seems to be already log transformed\"\n",
    "\n",
    "    number_of_clusters = len(tf_activities_sub.obs[\"new_annotation\"].cat.categories) \n",
    "\n",
    "\n",
    "    sc.tl.rank_genes_groups(tf_activities_sub, groupby= \"new_annotation\", reference=\"rest\", method=\"wilcoxon\", key_added=\"wilcoxon_markers\", corr_method= \"bonferroni\")\n",
    "    #sc.tl.filter_rank_genes_groups(anndataobject, min_in_group_fraction=0, key=\"wilcoxon_markers\", key_added= \"wilcoxon_markers_filtered\")\n",
    "    \n",
    "\n",
    "    sc.tl.rank_genes_groups(tf_activities_sub, groupby= \"new_annotation\", reference=\"rest\", method=\"t-test_overestim_var\", key_added=\"t_test_overestim_var_markers\", corr_method= \"bonferroni\" )\n",
    "    #sc.tl.filter_rank_genes_groups(anndataobject, min_in_group_fraction=0, key=\"t_test_overestim_var_markers\", key_added=\"t_test_overestim_filtered\")\n",
    "\n",
    "\n",
    "    result1 = tf_activities_sub.uns['wilcoxon_markers']\n",
    "    groups = result1['names'].dtype.names\n",
    "    anndataobject_markers = pd.DataFrame(\n",
    "    {group + '_' + key[:1]: result1[key][group]\n",
    "    for group in groups for key in ['names','logfoldchanges','pvals','pvals_adj']})\n",
    "\n",
    "    result2 = tf_activities_sub.uns['t_test_overestim_var_markers']\n",
    "    groups = result2['names'].dtype.names\n",
    "    anndataobject_markers = pd.DataFrame(\n",
    "    {group + '_' + key[:1]: result2[key][group]\n",
    "    for group in groups for key in ['names','logfoldchanges','pvals','pvals_adj']})\n",
    "\n",
    "    anndataobject_markers_wilcoxon = sc.get.rank_genes_groups_df(tf_activities_sub, group = None, log2fc_min=0, key=\"wilcoxon_markers\")\n",
    "    \n",
    "    anndataobject_markers_wilcoxon.rename(columns={\"names\":\"gene\", \"group\": \"cluster\"}, inplace=True)\n",
    "    \n",
    "    #documentation says this won't update the main dataframe but will only overwrite a copy in future pandas versions (after v3)\n",
    "    anndataobject_markers_wilcoxon[\"tag\"] = None\n",
    "    anndataobject_markers_wilcoxon[\"log_fc_tag\"] = None\n",
    "    \n",
    "    for i in range(len(anndataobject_markers_wilcoxon[\"pvals_adj\"])):\n",
    "         anndataobject_markers_wilcoxon[\"tag\"].iloc[i,] = eval_pval(anndataobject_markers_wilcoxon[\"pvals_adj\"].iloc[i,])\n",
    "         anndataobject_markers_wilcoxon[\"log_fc_tag\"].iloc[i,] = eval_log_fc_tag(anndataobject_markers_wilcoxon[\"logfoldchanges\"].iloc[i,])\n",
    "     \n",
    "\n",
    "    anndataobject_markers_wilcoxon.to_csv(single_result_path + \"/\" + name + \"_specific_markers_wilcoxon_test.csv\",index=0)\n",
    "\n",
    "    anndataobject_markers_t_over = sc.get.rank_genes_groups_df(tf_activities_sub, group = None, log2fc_min=0, key=\"t_test_overestim_var_markers\")\n",
    " \n",
    "    anndataobject_markers_t_over.rename(columns={\"names\":\"gene\", \"group\": \"cluster\"}, inplace=True)\n",
    "\n",
    "    anndataobject_markers_t_over[\"tag\"] = None\n",
    "    anndataobject_markers_t_over[\"log_fc_tag\"] = None\n",
    "    for i in range(len(anndataobject_markers_t_over[\"pvals_adj\"])):\n",
    "         anndataobject_markers_t_over[\"tag\"].iloc[i,] = eval_pval(anndataobject_markers_t_over[\"pvals_adj\"].iloc[i,])\n",
    "         anndataobject_markers_t_over[\"log_fc_tag\"].iloc[i,] = eval_pval(anndataobject_markers_t_over[\"logfoldchanges\"].iloc[i,])\n",
    "\n",
    "    anndataobject_markers_t_over.to_csv(single_result_path + \"/\" + name + \"_specific_markers_t_test_overestim_test.csv\",index=0)\n",
    "\n",
    "   #tag mapping wilcoxon\n",
    "    tag_mapping_wilcox = anndataobject_markers_wilcoxon[[\"gene\", \"tag\", \"log_fc_tag\", \"cluster\", \"pvals_adj\", \"logfoldchanges\"]]\n",
    "    tag_mapping_wilcox = tag_mapping_wilcox[(tag_mapping_wilcox[\"pvals_adj\"] < float(pval)) & \n",
    "                              ((tag_mapping_wilcox[\"logfoldchanges\"] > float(logfc)) | \n",
    "                              (tag_mapping_wilcox[\"logfoldchanges\"] < -float(logfc)))]\n",
    "\n",
    "    tag_mapping_wilcox = tag_mapping_wilcox.pivot(index=\"gene\", columns=\"cluster\", values=\"tag\")\n",
    "    clusters = anndataobject_markers_wilcoxon[\"cluster\"].unique()\n",
    "\n",
    "    for cluster in clusters:\n",
    "        if cluster not in tag_mapping_wilcox.columns:\n",
    "            tag_mapping_wilcox[cluster] = np.nan\n",
    "\n",
    "    tag_mapping_wilcox.fillna(\"ns\", inplace=True)\n",
    "\n",
    "    tf_activities_scaled.obs_names = tf_activities_scaled.obs[celltype]\n",
    "    tf_scores_df = tf_activities_scaled.to_df()\n",
    "    tf_scores_df.columns.name = None\n",
    "    unfiltered_tf_scores = create_unfiltered_tf_scores(tf_scores_df, condition, celltype, single_result_path)\n",
    "   \n",
    "    #Filter to only include tfs that match the tag_mapping/are markers\n",
    "    col_num = tf_scores_df.columns.isin(tag_mapping_wilcox.index)  \n",
    "    filtered_tf_scores_df = tf_scores_df.loc[:, col_num] \n",
    "    \n",
    "    filtered_summarized_tf_scores_df = filtered_tf_scores_df.groupby(celltype, observed = False).mean().T\n",
    "    filtered_summarized_tf_scores_df.index.name = \"gene\"\n",
    "    filtered_summarized_tf_scores_df.to_csv(f'{single_result_path}/tf_scores_{condition}.csv')\n",
    "    tf_scores_variable_table = save_variable_tf_score(filtered_summarized_tf_scores_df, condition, single_result_path, plot)\n",
    "\n",
    "    if plot:\n",
    "        plot_tf_activity(filtered_summarized_tf_scores_df, tag_mapping_wilcox, condition, single_result_path)\n",
    "    \n",
    "    #filtered_summarized_tf_scores_df.index = re.sub((\".,\"), \"_\", filtered_summarized_tf_scores_df.index)\n",
    "    anndataobject_markers_wilcoxon_merged = anndataobject_markers_wilcoxon.merge(map_z_value_filtered(filtered_summarized_tf_scores_df, anndataobject_markers_wilcoxon),  on=['gene', 'cluster'], how='inner')\n",
    "    anndataobject_markers_wilcoxon_merged = anndataobject_markers_wilcoxon_merged[anndataobject_markers_wilcoxon_merged.tag != \"ns\"]\n",
    "    anndataobject_markers_wilcoxon_merged.dropna(inplace=True)\n",
    "    res_wilcoxon = anndataobject_markers_wilcoxon_merged[[\"gene\",\"tag\", \"cluster\", \"z_score\"]]\n",
    "\n",
    "    #anndataobject_markers_t_over_merged = anndataobject_markers_t_over.merge(map_z_value_filtered(filtered_summarized_tf_scores_df, anndataobject_markers_t_over),  on=['gene', 'cluster'], how='inner')\n",
    "    #anndataobject_markers_t_over_merged = anndataobject_markers_t_over_merged[anndataobject_markers_t_over_merged.tag != \"ns\"]\n",
    "    #anndataobject_markers_t_over_merged.dropna(inplace=True)\n",
    "    #res_t_test = anndataobject_markers_t_over[[\"gene\",\"tag\", \"cluster\", \"z_score\"]]\n",
    "\n",
    "    res_wilcoxon.to_csv(single_result_path + \"/\" + name + \"_significant_markers_wilcoxon.csv\", index=0)\n",
    "    #res_t_test.to_csv(single_result_path + \"/\" + name + \"_significant_markers_t_test.csv\", index=0)\n",
    "\n",
    "     #//TODO: \n",
    "    #delete one variant and put test type as a variable\n",
    "\n",
    "    res = {}\n",
    "    res[\"cluster\"] = res_wilcoxon\n",
    "    return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "#check if it's okay to not pre set the column type as string or float (maybe no problem in python but was problem in r)\n",
    "\n",
    "def create_empty_CTR_dataframe():\n",
    "  \n",
    "  empty_df = pd.DataFrame(\n",
    "    columns=[\n",
    "    \"source\",\n",
    "    \"target\",\n",
    "    \"gene_A\",\n",
    "    \"gene_B\",\n",
    "    \"type_gene_A\",\n",
    "    \"type_gene_B\",\n",
    "    \"MeanLR\"\n",
    "    ])\n",
    "  \n",
    "  return(empty_df)\n",
    "\n",
    "\n",
    "def add_entry_to_CTR_dataframe(source, target, gene_A, gene_B, type_gene_A, type_gene_B, MeanLR, row):\n",
    "  df = pd.DataFrame(\n",
    "      {\"source\" : source,\n",
    "      \"target\" : target,\n",
    "      \"gene_A\" : gene_A,\n",
    "      \"gene_B\" : gene_B,\n",
    "      \"type_gene_A\" : type_gene_A,\n",
    "      \"type_gene_B\" : type_gene_B,\n",
    "      \"MeanLR\" : MeanLR}, index=[row])\n",
    "\n",
    "  return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_CrossTalkeR_input(tf_activities, gene_expression, out_path, regulon = None, organism = \"human\"):\n",
    "\n",
    "  if organism == \"human\":\n",
    "    ligands = pd.read_csv(\"ligands_human.csv\")\n",
    "    R2TF = pd.read_csv(\"rtf_db.csv\")\n",
    "  else: \n",
    "    ligands = pd.read_csv(\"converted_ligands.csv\")\n",
    "    R2TF = pd.read_csv(\"rtf_db_mouse.csv\")\n",
    "\n",
    "  R2TF = R2TF.set_index(\"tf\")\n",
    "\n",
    "  sorted_regulon = regulon[[\"tf\", \"target\"]]\n",
    "  sorted_regulon = sorted_regulon.set_index(\"tf\")\n",
    "\n",
    "  output_df = create_empty_CTR_dataframe()\n",
    "\n",
    "  for row in range(len((tf_activities))):\n",
    "    \n",
    "    tf_l = create_empty_CTR_dataframe()\n",
    "    r_tf = create_empty_CTR_dataframe()\n",
    "\n",
    "    #if (tf_activities[\"z_score\"].iloc[row] > 0):\n",
    "    tf = str(tf_activities[\"gene\"].iloc[row])\n",
    "    if tf in sorted_regulon.index:\n",
    "      targets = sorted_regulon.loc[tf, \"target\"]\n",
    "\n",
    "    if tf in R2TF.index:\n",
    "        receptors = R2TF.loc[tf, \"receptor\"]\n",
    "\n",
    "    else:\n",
    "        receptors = []\n",
    "\n",
    "    tf_ligands = np.intersect1d(targets, ligands)\n",
    "\n",
    "    if organism == \"human\":\n",
    "      if len(tf_ligands) > 0:\n",
    "        for ligand in tf_ligands:\n",
    "            expressed = False\n",
    "            if ligand in gene_expression.index:\n",
    "              ex_value = gene_expression.loc[ligand, tf_activities.iloc[row, 2]]\n",
    "              if (ex_value != 0):\n",
    "                expressed = True\n",
    "\n",
    "            df_list_l = []\n",
    "            \n",
    "            if (expressed == True):\n",
    "              df_list_l = add_entry_to_CTR_dataframe(source = tf_activities.iloc[row, 2],\n",
    "                                                      target = tf_activities.iloc[row, 2],\n",
    "                                                      gene_A =tf_activities.iloc[row, 0],\n",
    "                                                      gene_B = ligand,\n",
    "                                                      type_gene_A = \"Transcription_Factor\",\n",
    "                                                      type_gene_B= \"Ligand\",\n",
    "                                                      MeanLR= tf_activities.iloc[row, 3],\n",
    "                                                      row= row)\n",
    "                \n",
    "              tf_l = pd.concat([tf_l, df_list_l], ignore_index=True)\n",
    "\n",
    "\n",
    "        if (len(receptors) > 0):\n",
    "          for receptor in receptors:\n",
    "            df_list_r = [] \n",
    "            df_list_r = add_entry_to_CTR_dataframe(tf_activities.iloc[row, 2],\n",
    "                                                tf_activities.iloc[row, 2],\n",
    "                                                receptor,\n",
    "                                                tf_activities.iloc[row, 0],\n",
    "                                                \"Receptor\",\n",
    "                                                \"Transcription Factor\",\n",
    "                                                tf_activities.iloc[row, 3],\n",
    "                                                row)\n",
    "\n",
    "            r_tf = pd.concat([r_tf, df_list_r], ignore_index=True)\n",
    "                \n",
    "          \n",
    "    else: \n",
    "      if len(tf_ligands) > 0:\n",
    "        for ligand in tf_ligands:\n",
    "            expressed = False\n",
    "            translations = ligand\n",
    "            if len(translations) > 0:\n",
    "              for l in translations:\n",
    "                print(gene_expression.index)\n",
    "                if l in gene_expression.index:\n",
    "                  ex_value = gene_expression.loc[l, tf_activities.iloc[row, 2]]\n",
    "                  if (ex_value != 0):\n",
    "                    expressed = True\n",
    "          \n",
    "                df_list_l = []\n",
    "            \n",
    "                if (expressed == True):\n",
    "                  df_list_l = add_entry_to_CTR_dataframe(source = tf_activities.iloc[row, 2],\n",
    "                                                      target = tf_activities.iloc[row, 2],\n",
    "                                                      gene_A =tf_activities.iloc[row, 0],\n",
    "                                                      gene_B = ligand,\n",
    "                                                      type_gene_A = \"Transcription_Factor\",\n",
    "                                                      type_gene_B= \"Ligand\",\n",
    "                                                      MeanLR= tf_activities.iloc[row, 3],\n",
    "                                                      row= row)\n",
    "                \n",
    "                  tf_l = pd.concat([tf_l, df_list_l], ignore_index=True)\n",
    "\n",
    "      \n",
    "              if (len(receptors) > 0):\n",
    "                for receptor in receptors:\n",
    "                  df_list_r = [] \n",
    "                  df_list_r = add_entry_to_CTR_dataframe(tf_activities.iloc[row, 2],\n",
    "                                                tf_activities.iloc[row, 2],\n",
    "                                                receptor,\n",
    "                                                tf_activities.iloc[row, 0],\n",
    "                                                \"Receptor\",\n",
    "                                                \"Transcription Factor\",\n",
    "                                                tf_activities.iloc[row, 3],\n",
    "                                                row)\n",
    "                                                \n",
    "                  r_tf = pd.concat([r_tf, df_list_r], ignore_index=True)\n",
    "\n",
    "        #tf_l.to_csv(single_result_path + \"/\" + renamed_condition + \"_ctr_test_l.csv\", index=0)\n",
    "        #r_tf.to_csv(single_result_path + \"/\" + renamed_condition + \"_ctr_test_r.csv\", index=0)\n",
    "\n",
    "    #    r_tf[\"gene_A\"] <- gsub(\"_\", \"+\", r_tf$gene_A, fixed = TRUE)\n",
    "    #   r_tf[\"gene_B\"] <- gsub(\"_\", \"+\", r_tf$gene_B, fixed = TRUE)\n",
    "    #   tf_l[\"gene_A\"] <- gsub(\"_\", \"+\", tf_l$gene_A, fixed = TRUE)\n",
    "    #   tf_l[\"gene_B\"] <- gsub(\"_\", \"+\", tf_l$gene_B, fixed = TRUE)\n",
    "\n",
    "    output_df = pd.concat([output_df, r_tf], ignore_index=True)\n",
    "    output_df = pd.concat([output_df, tf_l], ignore_index=True)\n",
    "    output_df.to_csv(\"tf_l_r.csv\", index=0)\n",
    "\n",
    "\n",
    "  return output_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_intracellular_network(tf_activities, gene_expression, outpath, regulon, organism = \"human\"):\n",
    "    \n",
    "    R2TF_h = pd.read_csv(\"rtf_db.csv\")\n",
    "    R2TF_m = pd.read_csv(\"rtf_db_mouse.csv\")\n",
    "    \n",
    "    if len(tf_activities.shape) > 0:\n",
    "        if organism == \"human\":\n",
    "            R2TF = R2TF_h.set_index(\"tf\")\n",
    "        else: \n",
    "            R2TF = R2TF_m.set_index(\"tf\")\n",
    "    \n",
    "    sorted_regulon = regulon[[\"tf\", \"target\"]]\n",
    "    #sorted_regulon.rename(columns={\"target\" : \"targets\"})\n",
    "    sorted_regulon = sorted_regulon.set_index(\"tf\")\n",
    "\n",
    "    RTF_df = pd.DataFrame({\"Receptor\": pd.Series(dtype=\"str\"), \"TF\": pd.Series(dtype=\"str\")})\n",
    "\n",
    "    TFTG_df = pd.DataFrame({\"celltype\": pd.Series(dtype=\"str\"), \"TF\": pd.Series(dtype=\"str\"),\n",
    "                            \"Target_Gene\" : pd.Series(dtype=\"str\"), \"TF_Score\" : pd.Series(dtype = \"float\")})\n",
    "\n",
    "    for row in range(len((tf_activities))):\n",
    "\n",
    "        tf = str(tf_activities[\"gene\"].iloc[row])\n",
    "        if tf in sorted_regulon.index:\n",
    "            targets = sorted_regulon.loc[tf, \"target\"]\n",
    "\n",
    "        if tf in R2TF.index:\n",
    "            receptors = R2TF.loc[tf, \"receptor\"]\n",
    "\n",
    "        else:\n",
    "            receptors = []\n",
    "\n",
    "        if len(targets) > 0:\n",
    "            if len(receptors) > 0:\n",
    "                for target in targets:\n",
    "                    expressed = False\n",
    "                    if target in gene_expression.index:\n",
    "                        ex_value = gene_expression.loc[target, tf_activities.iloc[row, 2]]\n",
    "                        if (ex_value != 0):\n",
    "                            expressed = True\n",
    "\n",
    "                    if (expressed == True):\n",
    "                        TFTG_tmp = pd.DataFrame({\"celltype\" : tf_activities.iloc[row, 2],\n",
    "                                                 \"TF\" : tf_activities.iloc[row, 0],\n",
    "                                                 \"Target_Gene\": target,\n",
    "                                                 \"TF_Score\" : tf_activities.iloc[row, 3]}, index = [row])\n",
    "        \n",
    "                        TFTG_df = pd.concat([TFTG_df, TFTG_tmp])  \n",
    "\n",
    "                for receptor in receptors:\n",
    "                    RTF_tmp = pd.DataFrame({\"Receptor\" : receptor, \"TF\" : tf_activities.iloc[row, 0]}, index = [row])\n",
    "                    \n",
    "                    RTF_df = pd.concat([RTF_df, RTF_tmp])  \n",
    "\n",
    "    recept_regulon = pd.merge(RTF_df, TFTG_df, on = \"TF\")\n",
    "\n",
    "    recept_regulon.to_csv(\"recept_regulon.csv\")\n",
    "\n",
    "    return recept_regulon\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import false_discovery_control\n",
    "\n",
    "def condition_comparison_significant(tf_activities, out_path, celltype, condition, comparison_list):\n",
    "\n",
    "    vs_df_list = list()\n",
    "\n",
    "    for vs in range(len(comparison_list)):\n",
    "        vs1 = comparison_list[0]\n",
    "        vs2 = comparison_list[1]\n",
    "\n",
    "        print(f\"vs: {vs1}, vs2: {vs2}\") \n",
    "\n",
    "        pws = tf_activities.var_names\n",
    "\n",
    "        res = pd.DataFrame()\n",
    "        for i in range(1): #tf_activities.obs:\n",
    "            a_sub = tf_activities[tf_activities.obs[condition].isin([vs1, vs2])]\n",
    "            if len(pd.unique(a_sub.obs[condition])) == 2:\n",
    "                condition_table = a_sub.obs[[condition]].copy()\n",
    "                condition_table.columns = [\"condition\"]\n",
    "                metadata_counts = condition_table.groupby(\"condition\", observed = False).size()\n",
    "                \n",
    "                if (metadata_counts[0] + metadata_counts[1]) > 10:\n",
    "                    g = a_sub.obs[condition].astype(\"category\")\n",
    "                    g = g.cat.set_categories([vs1, vs2])\n",
    "          \n",
    "                    sc.tl.rank_genes_groups(a_sub, groupby= celltype, #groups=[\"PMF,MF2\", \"control\"],\n",
    "                                         reference=\"rest\", method=\"wilcoxon\", key_added=\"wilcoxon_markers\", corr_method= \"bonferroni\")\n",
    "\n",
    "                    res_tmp = sc.get.rank_genes_groups_df(a_sub, group = None, log2fc_min=0, key=\"wilcoxon_markers\")\n",
    "                    print(res_tmp)\n",
    "                    res_tmp[\"FDR\"] = false_discovery_control(res_tmp[\"pvals\"])\n",
    "                    #res_tmp[\"r\"] =  \n",
    "\n",
    "                    res = pd.concat([res, res_tmp], ignore_index=True)\n",
    "\n",
    "        res_df = res.dropna()\n",
    "\n",
    "        def assign_significance_tag(fdr):\n",
    "            if fdr < 0.001:\n",
    "                return \"***\"\n",
    "            elif fdr < 0.01:\n",
    "                return \"**\"\n",
    "            elif fdr < 0.05:\n",
    "                return \"*\"\n",
    "            else:\n",
    "                return \"ns\"\n",
    "\n",
    "        res_df[\"tag\"] = res_df[\"FDR\"].apply(assign_significance_tag)\n",
    "\n",
    "        # Uncomment the following lines to filter for significant results\n",
    "        # significant_res = res_df[res_df[\"tag\"] == \"***\"]\n",
    "        # significant_genes = significant_res[\"tf\"].unique()\n",
    "        # end_res = res_df[res_df[\"tf\"].isin(significant_genes)]\n",
    "        end_res = res_df\n",
    "\n",
    "        end_res.to_csv(f\"{out_path}/all_tfs_{vs1}_vs_{vs2}.csv\", index=False)\n",
    "\n",
    "        # Save to vs_df_list\n",
    "        #comparison_key = f\"{vs1} vs {vs2}\"\n",
    "        #vs_df_list[comparison_key] = end_res\n",
    "\n",
    "    # Save the entire vs_df_list as a pickle file\n",
    "    #comparison_dfs_filepath = \"comparison_dfs.pkl\"\n",
    "    #pd.to_pickle(vs_df_list, comparison_dfs_filepath)\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "#ignore extra tfs from decoupler while writing script \n",
    "\n",
    "def tf_activity_analysis (anndataobject, arguments_list = None):\n",
    "    \n",
    "    if (isinstance(anndataobject, str)):\n",
    "        anndataobject = ad.read_h5ad(anndataobject)\n",
    "\n",
    "    arguments_list = validate_input_arguments(arguments_list)\n",
    "\n",
    "    if not os.path.isdir(arguments_list[\"out_path\"]):\n",
    "        os.mkdir(arguments_list[\"out_path\"])\n",
    "        tf_path = arguments_list[\"out_path\"] + \"TF_results/\"\n",
    "        os.mkdir(tf_path)\n",
    "    else:\n",
    "        tf_path = arguments_list[\"out_path\"] + \"TF_results/\"\n",
    "\n",
    "    #rename the arguments inserted into argument list (eg protocol to condition)(unfinished)\n",
    "    condition = anndataobject.obs[arguments_list[\"condition\"]]\n",
    "\n",
    "    #checks for tf activity csv, if nothing there, runs decoupler\n",
    "    if isinstance(arguments_list[\"tf_activities\"], str):\n",
    "         tf_activities = ad.read_csv(arguments_list[\"tf_activities\"])\n",
    "         tf_activities.obs = anndataobject.obs.reindex(tf_activities.obs.index)\n",
    "         tf_activities.obsm = anndataobject.obsm\n",
    "         tf_activities.uns = anndataobject.uns\n",
    "\n",
    "    elif arguments_list[\"tf_activities\"] is None:\n",
    "         dc.run_ulm(mat = anndataobject, net = (arguments_list[\"reg\"]), source ='tf', target ='target', weight ='weight', verbose = True, use_raw = False)\n",
    "         tf_activities = anndataobject.obsm['ulm_estimate']\n",
    "         tf_activities.to_csv(\"decoupler_results_test.csv\")\n",
    "         tf_activities = ad.read_csv(\"decoupler_results_test.csv\")\n",
    "         tf_activities.obs = anndataobject.obs.reindex(tf_activities.obs.index)\n",
    "         tf_activities.obsm = anndataobject.obsm\n",
    "         tf_activities.uns = anndataobject.uns\n",
    "        \n",
    "\n",
    "    #sets the stage for decision if single condition or comparison analysis is done\n",
    "\n",
    "    if not pd.isnull(all(arguments_list[\"comparison_list\"])):\n",
    "        if (len(arguments_list[\"comparison_list\"]) > 0) & (len(pd.unique(anndataobject.obs[arguments_list[\"condition\"]])) < 2):\n",
    "            arguments_list[\"comparison_list\"] = np.nan\n",
    "            print(\"Only one condition was found in the data, although a list of comparisons was provided. The analyses are performed only for the present condition!\")\n",
    "\n",
    "    #code for single condition  analysis\n",
    "\n",
    "    if pd.isnull(all(arguments_list[\"comparison_list\"])):\n",
    "\n",
    "        result_list = {}\n",
    "        gene_expression_list = {}\n",
    "        CTR_cluster_list = {}\n",
    "        intranet_cluster_list = {}\n",
    "\n",
    "        #creates loop until after tf activity score\n",
    "        \n",
    "        for name_iterable in anndataobject.obs.protocol.unique():\n",
    "            sub_object = anndataobject[anndataobject.obs.protocol == name_iterable]\n",
    "            tf_activities_sub = tf_activities[tf_activities.obs.protocol == name_iterable]\n",
    "\n",
    "            sub_object_avg = AverageExpression(sub_object, name_iterable= name_iterable, celltype = arguments_list[\"celltype\"], outpath= arguments_list[\"out_path\"])\n",
    "            \n",
    "            #check how sub object is returned by average expression (subobject.T) or rename return?\n",
    "            tf_activity_scores = get_significant_tfs_single(tf_activities_sub, celltype = arguments_list[\"celltype\"],condition = name_iterable, out_path= tf_path, pval = arguments_list[\"pval\"], logfc = arguments_list[\"logfc\"], name = name_iterable, plot = arguments_list[\"plot\"])\n",
    "\n",
    "            #result_condition_list[[name_iterable]] = tf_activity_scores[]\n",
    "            result_list[name_iterable] = tf_activity_scores\n",
    "            #turn them into dictionaries?\n",
    "            \n",
    "            gene_expression_list[name_iterable] = sub_object_avg\n",
    "            \n",
    "        \n",
    "    \n",
    "            CTR_cluster_list[name_iterable] = generate_CrossTalkeR_input(tf_activity_scores[\"cluster\"],\n",
    "                                                                            gene_expression_list[name_iterable],\n",
    "                                                                            arguments_list[\"out_path\"],                                             \n",
    "                                                                            arguments_list[\"reg\"],\n",
    "                                                                            arguments_list[\"organism\"])\n",
    "    \n",
    "              \n",
    "            intranet_cluster_list[name_iterable] = generate_intracellular_network(tf_activity_scores[\"cluster\"],\n",
    "                                                                                  gene_expression_list[name_iterable],\n",
    "                                                                                  arguments_list[\"out_path\"],\n",
    "                                                                                  arguments_list[\"reg\"],\n",
    "                                                                                  arguments_list[\"organism\"])\n",
    "            \n",
    "            #also return anndata object with avg expression and tf score as uns layer?\n",
    "\n",
    "            tf = make_TFOBj(\n",
    "                tf_activities_condition = list(),\n",
    "                tf_activities_cluster = result_list,\n",
    "                average_gene_expression = gene_expression_list,\n",
    "                regulon = arguments_list[\"reg\"],\n",
    "                CTR_input_condition = list(),\n",
    "                CTR_input_cluster = CTR_cluster_list,\n",
    "                intracellular_network_condition = list(),\n",
    "                intracellular_network_cluster = intranet_cluster_list)\n",
    "\n",
    "            with open((arguments_list[\"out_path\"] + \"tf.pickle\"), \"wb\") as file:\n",
    "                pickle.dump(tf, file)\n",
    "\n",
    "        return tf\n",
    "\n",
    "    else:\n",
    "        out_path_compared = (tf_path + \"compared\")\n",
    "        if not os.path.isdir(out_path_compared):\n",
    "            os.mkdir(out_path_compared)\n",
    "        compared_significant_tfs = condition_comparison_significant(tf_activities, out_path_compared, arguments_list[\"celltype\"], \n",
    "                                                                    arguments_list[\"condition\"], arguments_list[\"comparison_list\"])\n",
    "        \n",
    "        #plot_condition_tf_activities(compared_significant_tfs, out_path_compared)\n",
    "        #plot_condition_tf_activities_compressed(compared_significant_tfs, out_path_compared)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "vs: PMF,MF2, vs2: control\n",
      "       group  names     scores  logfoldchanges         pvals     pvals_adj\n",
      "0     Neural  FOXK1  11.401932        3.548184  4.089421e-30  1.468102e-27\n",
      "1     Neural   ATF1  10.885193        3.798266  1.356112e-27  4.868443e-25\n",
      "2     Neural  NR5A1  10.250755        3.420756  1.174219e-24  4.215446e-22\n",
      "3     Neural   MTF1   9.499879        2.641667  2.101342e-21  7.543816e-19\n",
      "4     Neural   PAX3   9.367075        3.330685  7.457021e-21  2.677070e-18\n",
      "..       ...    ...        ...             ...           ...           ...\n",
      "790  Myeloid   CTCF  -6.391936        0.402548  1.637979e-10  5.880346e-08\n",
      "791  Myeloid  GATA2  -6.826442        0.432296  8.704671e-12  3.124977e-09\n",
      "792  Myeloid  HNF4A  -6.887953        0.483918  5.660096e-12  2.031974e-09\n",
      "793  Myeloid    FOS  -7.357794        1.654423  1.869740e-13  6.712366e-11\n",
      "794  Myeloid   EGR1  -7.725553        1.724823  1.113687e-14  3.998138e-12\n",
      "\n",
      "[795 rows x 6 columns]\n",
      "vs: PMF,MF2, vs2: control\n",
      "       group  names     scores  logfoldchanges         pvals     pvals_adj\n",
      "0     Neural  FOXK1  11.401932        3.548184  4.089421e-30  1.468102e-27\n",
      "1     Neural   ATF1  10.885193        3.798266  1.356112e-27  4.868443e-25\n",
      "2     Neural  NR5A1  10.250755        3.420756  1.174219e-24  4.215446e-22\n",
      "3     Neural   MTF1   9.499879        2.641667  2.101342e-21  7.543816e-19\n",
      "4     Neural   PAX3   9.367075        3.330685  7.457021e-21  2.677070e-18\n",
      "..       ...    ...        ...             ...           ...           ...\n",
      "790  Myeloid   CTCF  -6.391936        0.402548  1.637979e-10  5.880346e-08\n",
      "791  Myeloid  GATA2  -6.826442        0.432296  8.704671e-12  3.124977e-09\n",
      "792  Myeloid  HNF4A  -6.887953        0.483918  5.660096e-12  2.031974e-09\n",
      "793  Myeloid    FOS  -7.357794        1.654423  1.869740e-13  6.712366e-11\n",
      "794  Myeloid   EGR1  -7.725553        1.724823  1.113687e-14  3.998138e-12\n",
      "\n",
      "[795 rows x 6 columns]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_2375288/424167439.py:23: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n",
      "  if (metadata_counts[0] + metadata_counts[1]) > 10:\n",
      "/home/larissa/miniconda3/envs/testpy/lib/python3.12/site-packages/scanpy/tools/_rank_genes_groups.py:640: ImplicitModificationWarning: Trying to modify attribute `._uns` of view, initializing view as actual.\n",
      "  adata.uns[key_added] = {}\n",
      "/home/larissa/miniconda3/envs/testpy/lib/python3.12/site-packages/scanpy/tools/_rank_genes_groups.py:455: RuntimeWarning: invalid value encountered in log2\n",
      "  self.stats[group_name, \"logfoldchanges\"] = np.log2(\n",
      "/home/larissa/miniconda3/envs/testpy/lib/python3.12/site-packages/scanpy/tools/_rank_genes_groups.py:455: RuntimeWarning: invalid value encountered in log2\n",
      "  self.stats[group_name, \"logfoldchanges\"] = np.log2(\n",
      "/home/larissa/miniconda3/envs/testpy/lib/python3.12/site-packages/scanpy/tools/_rank_genes_groups.py:455: RuntimeWarning: invalid value encountered in log2\n",
      "  self.stats[group_name, \"logfoldchanges\"] = np.log2(\n",
      "/home/larissa/miniconda3/envs/testpy/lib/python3.12/site-packages/scanpy/tools/_rank_genes_groups.py:455: RuntimeWarning: invalid value encountered in log2\n",
      "  self.stats[group_name, \"logfoldchanges\"] = np.log2(\n",
      "/home/larissa/miniconda3/envs/testpy/lib/python3.12/site-packages/scanpy/tools/_rank_genes_groups.py:455: RuntimeWarning: invalid value encountered in log2\n",
      "  self.stats[group_name, \"logfoldchanges\"] = np.log2(\n",
      "/tmp/ipykernel_2375288/424167439.py:23: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n",
      "  if (metadata_counts[0] + metadata_counts[1]) > 10:\n",
      "/home/larissa/miniconda3/envs/testpy/lib/python3.12/site-packages/scanpy/tools/_rank_genes_groups.py:640: ImplicitModificationWarning: Trying to modify attribute `._uns` of view, initializing view as actual.\n",
      "  adata.uns[key_added] = {}\n",
      "/home/larissa/miniconda3/envs/testpy/lib/python3.12/site-packages/scanpy/tools/_rank_genes_groups.py:455: RuntimeWarning: invalid value encountered in log2\n",
      "  self.stats[group_name, \"logfoldchanges\"] = np.log2(\n",
      "/home/larissa/miniconda3/envs/testpy/lib/python3.12/site-packages/scanpy/tools/_rank_genes_groups.py:455: RuntimeWarning: invalid value encountered in log2\n",
      "  self.stats[group_name, \"logfoldchanges\"] = np.log2(\n",
      "/home/larissa/miniconda3/envs/testpy/lib/python3.12/site-packages/scanpy/tools/_rank_genes_groups.py:455: RuntimeWarning: invalid value encountered in log2\n",
      "  self.stats[group_name, \"logfoldchanges\"] = np.log2(\n",
      "/home/larissa/miniconda3/envs/testpy/lib/python3.12/site-packages/scanpy/tools/_rank_genes_groups.py:455: RuntimeWarning: invalid value encountered in log2\n",
      "  self.stats[group_name, \"logfoldchanges\"] = np.log2(\n",
      "/home/larissa/miniconda3/envs/testpy/lib/python3.12/site-packages/scanpy/tools/_rank_genes_groups.py:455: RuntimeWarning: invalid value encountered in log2\n",
      "  self.stats[group_name, \"logfoldchanges\"] = np.log2(\n"
     ]
    }
   ],
   "source": [
    "result = tf_activity_analysis(anndataobject= \"LR2TF_test_run/anndata_object.h5ad\", arguments_list= {\"out_path\" : \"script_test\", \"celltype\" : \"new_annotation\", \"condition\" : \"protocol\", \"organism\" : \"human\", \"comparison_list\" : [\"PMF,MF2\", \"control\"], \"logfc\" : \"0\", \"pval\" : None, \"reg\" : \"filterd_regulon.csv\", \"tf_activities\" : \"decoupler_results.csv\", \"plot\" : False})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_node_type(df):\n",
    "  df = mutate(gene_A = ifelse(type_gene_A == \"Ligand\", paste0(gene_A, \"|L\"), gene_A))\n",
    "\n",
    "  df = mutate(gene_A = ifelse(type_gene_A == \"Receptor\", paste0(gene_A, \"|R\"), gene_A))\n",
    "\n",
    "  df = mutate(gene_A = ifelse(type_gene_A == \"Transcription Factor\", paste0(gene_A, \"|TF\"), gene_A))\n",
    "  \n",
    "  df = mutate(gene_B = ifelse(type_gene_B == \"Ligand\", paste0(gene_B, \"|L\"), gene_B))\n",
    "  df <- df %>%\n",
    "    mutate(gene_B = ifelse(type_gene_B == \"Receptor\", paste0(gene_B, \"|R\"), gene_B))\n",
    "  df <- df %>%\n",
    "    mutate(gene_B = ifelse(type_gene_B == \"Transcription Factor\", paste0(gene_B, \"|TF\"), gene_B))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def combine_LR_and_TF(tf_table, LR_prediction, out_path, condition, add_node_type = False):\n",
    "\n",
    "  if isinstance(LR_prediction, pd.DataFrame):\n",
    "    lr_table = LR_prediction\n",
    "  else: \n",
    "    #fix this\n",
    "    lr_table = read.csv(LR_prediction)\n",
    "    lr_table.rownames = lr_table.columns[\"X\"]\n",
    "    lr_table.columns[\"X\"] = None\n",
    "\n",
    "  lr_ligands = np.unique(lr_table[\"gene_A\"])\n",
    "  lr_receptors = np.unique(lr_table[\"gene_B\"])\n",
    "  \n",
    "  tf_receptor_interactions =  tf_table[tf_table['gene_A'].isin(lr_receptors)]\n",
    "  tf_ligand_interactions = tf_table[tf_table[\"gene_B\"].isin(lr_ligands)]\n",
    "\n",
    "  complete_interactions = pd.concat([tf_receptor_interactions, tf_ligand_interactions])\n",
    "  complete_interactions = pd.concat([complete_interactions, lr_table])\n",
    "  if (add_node_type):\n",
    "    complete_interactions = add_node_type(complete_interactions)\n",
    "    \n",
    "  complete_interactions.to_csv((out_path + \"CrossTalkeR_input_\" + condition + \".csv\"), index=0)\n",
    "  return(complete_interactions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#LINUX\n",
    "table_ctr = pd.read_csv(\"/home/larissa/Documents/LR2TF_HiWi/LR2TF_test_run/CTR_LR.csv\")\n",
    "table_exp = pd.read_csv(\"/home/larissa/Documents/LR2TF_HiWi/LR2TF_test_run/EXP_LR.csv\")\n",
    "\n",
    "ctr_input = combine_LR_and_TF(result.CTR_input_cluster[\"control\"], table_ctr, \"script_test/\", \"control\")\n",
    "exp_input = combine_LR_and_TF(result.CTR_input_cluster[\"PMF,MF2\"], table_exp, \"script_test/\", \"PMF_MF2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#WINDOWS\n",
    "table_ctr = pd.read_csv(\"LR2TF_test_run\\\\CTR_LR.csv\")\n",
    "table_exp = pd.read_csv(\"LR2TF_test_run\\\\EXP_LR.csv\")\n",
    "\n",
    "ctr_input = combine_LR_and_TF(result.CTR_input_cluster[\"control\"], table_ctr, \"script_test/\", \"control\")\n",
    "exp_input = combine_LR_and_TF(result.CTR_input_cluster[\"PMF,MF2\"], table_exp, \"script_test/\", \"PMF_MF2\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
