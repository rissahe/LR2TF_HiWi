{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import anndata as ad\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import scanpy as sc\n",
    "import decoupler as dc\n",
    "import os\n",
    "import statistics\n",
    "import seaborn as sns\n",
    "from scipy.stats import wilcoxon\n",
    "from scipy.stats import ranksums\n",
    "from scipy.spatial.distance import pdist\n",
    "from scipy.cluster.hierarchy import linkage\n",
    "from scipy.stats import false_discovery_control\n",
    "from itertools import combinations\n",
    "import matplotlib.pyplot as plt\n",
    "import pickle\n",
    "from statsmodels.stats.multitest import multipletests\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#%pip install --upgrade decoupler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def validate_input_arguments (arguments_list):\n",
    "    if arguments_list[\"out_path\"] is None:\n",
    "        print(\"Please provide an output path\")\n",
    "    elif arguments_list[\"out_path\"][-1] != \"/\":\n",
    "        arguments_list[\"out_path\"] = arguments_list[\"out_path\"] + \"/\"\n",
    "\n",
    "    if arguments_list[\"celltype\"] is None:\n",
    "        print(\"Please provide the name of the metadata field containing cell type annotations\")\n",
    "\n",
    "    if arguments_list[\"condition\"] is None:\n",
    "        print(\"Please provide the name of the metadata field containing condition annotations\")\n",
    "\n",
    "    if arguments_list[\"organism\"] is None:\n",
    "        arguments_list[\"organism\"] = \"human\"\n",
    "\n",
    "    if arguments_list[\"comparison_list\"] is None:\n",
    "        arguments_list[\"comparison_list\"] = np.nan\n",
    "\n",
    "    if arguments_list[\"meanchange\"] is None:\n",
    "        arguments_list[\"meanchange\"] = 0.0\n",
    "\n",
    "    if arguments_list [\"pval\"] is None:\n",
    "        arguments_list[\"pval\"] = 0.05\n",
    "\n",
    "    if arguments_list [\"num_cell_filter\"] is None:\n",
    "        arguments_list[\"num_cell_filter\"] = 0\n",
    "\n",
    "    if arguments_list[\"reg\"] is None:\n",
    "        arguments_list[\"reg\"] = load_dorothea_regulon(arguments_list[\"organism\"])\n",
    "\n",
    "    elif isinstance(arguments_list[\"reg\"], str):\n",
    "        arguments_list[\"reg\"] = pd.read_csv(arguments_list[\"reg\"], index_col=0)\n",
    "        arguments_list[\"reg\"] = pd.DataFrame.rename(arguments_list[\"reg\"], columns={\"source\" : \"tf\"})\n",
    "\n",
    "    #is the naming of tf fine like this?\n",
    "    if not \"tf\" in arguments_list[\"reg\"] and \"target\" in arguments_list[\"reg\"] and \"weight\" in arguments_list[\"reg\"]:\n",
    "        raise NameException(\"Not all necessary columns found in regulon table! Please make sure that the regulon has the columns 'source', 'target' and 'weight'!\")\n",
    "    \n",
    "    if arguments_list[\"plot\"] is None:\n",
    "        arguments_list[\"plot\"] = True\n",
    "    elif not isinstance(arguments_list[\"plot\"], (bool)):\n",
    "        raise ValueError(\"lot argument must be a boolean value.\")\n",
    "        \n",
    "   \n",
    "    return(arguments_list)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TFObj:\n",
    "    def __init__(self,\n",
    "    tf_activities_condition : list,\n",
    "    tf_activities_cluster : list,\n",
    "    average_gene_expression : list,\n",
    "    regulon : pd.DataFrame,\n",
    "    CTR_input_condition : list,\n",
    "    CTR_input_cluster : list,\n",
    "    intracellular_network_condition : list,\n",
    "    intracellular_network_cluster : list):\n",
    "\n",
    "        self.tf_activities_condition = tf_activities_condition\n",
    "        self.tf_activities_cluster = tf_activities_cluster\n",
    "        self.average_gene_expression = average_gene_expression\n",
    "        self.regulon = regulon\n",
    "        self.CTR_input_condition = CTR_input_condition\n",
    "        self.CTR_input_cluster = CTR_input_cluster\n",
    "        self.intracellular_network_condition = intracellular_network_condition\n",
    "        self.intracellular_network_cluster = intracellular_network_cluster\n",
    "\n",
    "def make_TFOBj(tf_activities_condition : list,\n",
    "    tf_activities_cluster : list,\n",
    "    average_gene_expression : list,\n",
    "    regulon : pd.DataFrame,\n",
    "    CTR_input_condition : list,\n",
    "    CTR_input_cluster : list,\n",
    "    intracellular_network_condition : list,\n",
    "    intracellular_network_cluster : list):\n",
    "\n",
    "        tf = TFObj(tf_activities_condition,\n",
    "            tf_activities_cluster,\n",
    "            average_gene_expression,\n",
    "            regulon,\n",
    "            CTR_input_condition,\n",
    "            CTR_input_cluster,\n",
    "            intracellular_network_condition,\n",
    "            intracellular_network_cluster)\n",
    "\n",
    "        return tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def AverageExpression(sub_object, celltype = None, name_iterable = None, outpath = None):\n",
    "    gene_ids = sub_object.var.index.values\n",
    "    #cluster line even necessary if not returned?\n",
    "    #clusters = anndataobject.obs[celltype].cat.categories\n",
    "    obs = sub_object[:,gene_ids].X.toarray()\n",
    "    obs = np.expm1(obs)\n",
    "    avg_df = pd.DataFrame(obs,columns=gene_ids,index= sub_object.obs[celltype])\n",
    "    avg_df = avg_df.groupby(level=0, observed=False).mean()\n",
    "    #avg_df.T.to_csv(outpath + name_iterable + \"_average_gene_expression_by_cluster_exp.csv\")\n",
    "\n",
    "    return avg_df.T\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def eval_pval(p_val):\n",
    "    p_val = float(p_val)\n",
    "    if p_val < 0.001: \n",
    "      txt = \"***\"\n",
    "    elif p_val < 0.01: \n",
    "      txt = \"**\"\n",
    "    elif p_val < 0.05: \n",
    "      txt = \"*\"\n",
    "    else:\n",
    "      txt = \"ns\"\n",
    "    return(txt)\n",
    "\n",
    "\n",
    "def eval_meanchange_tag(meanchange):\n",
    "    if meanchange >= 1.0: \n",
    "      txt = \"***\"\n",
    "    elif meanchange > 0.5: \n",
    "      txt = \"**\"\n",
    "    elif meanchange > 0.0: \n",
    "      txt = \"*\"\n",
    "    else:\n",
    "      txt = \"ns\"\n",
    "    return(txt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_unfiltered_tf_scores(tf_scores_df, condition, celltype, out_path):   \n",
    "    summarized_tf_scores_df = tf_scores_df.groupby(celltype, observed = True).mean().T\n",
    "    #tf_scores_df.groupby(celltype, observed = True).apply(display)\n",
    "    #agg([\"mean\", \"var\"])\n",
    "    summarized_tf_scores_df.to_csv(out_path + \"/unfiltered_tf_scores_\" + condition + \".csv\")\n",
    "    return summarized_tf_scores_df\n",
    "\n",
    "#np.var() returns a value that is different from R's var(), whereas statistics.variance() is the same as R's var()\n",
    "def save_variable_tf_score(filtered_summarized_tf_scores_df, condition, out_path, plot):\n",
    "    filtered_summarized_tf_scores_df[\"var\"] = filtered_summarized_tf_scores_df.apply(statistics.variance, axis=1).unique()\n",
    "    filtered_summarized_tf_scores_df.to_csv(out_path + \"/variable_tf_scores_\" + condition + \".csv\")\n",
    "\n",
    "    if plot:\n",
    "        top_variable_tfs = filtered_summarized_tf_scores_df.sort_values(\"var\", ascending=False).head(n=20).drop(columns=\"var\")\n",
    "        cluster_map = sns.clustermap(top_variable_tfs, cmap=\"vlag\", center=0, vmin=top_variable_tfs.min(axis=None), cbar_kws={\"label\": \"t-score\"},\n",
    "                                    cbar_pos=(1, 0.5, 0.02, 0.1), dendrogram_ratio=(0.2, 0.05))\n",
    "        cluster_map.ax_heatmap.set_xlabel(\"Cell Type\")\n",
    "        cluster_map.ax_heatmap.set_ylabel(\"Transcription Factor\")\n",
    "        plt.setp(cluster_map.ax_heatmap.get_xticklabels(), rotation=90) \n",
    "        plt.savefig(out_path + \"/tf_activity_top20_variable_\" + condition + \".pdf\", bbox_inches='tight')\n",
    "        plt.close()\n",
    "\n",
    "    filtered_summarized_tf_scores_df_var = filtered_summarized_tf_scores_df\n",
    "    return filtered_summarized_tf_scores_df_var\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_tf_activity(filtered_summarized_tf_scores_df, tag_mapping, condition, out_path):\n",
    "    filtered_summarized_tf_scores_df = filtered_summarized_tf_scores_df.drop(columns=\"var\")\n",
    "    calc_size = ((len(filtered_summarized_tf_scores_df.columns.unique()) * 1.5), (len(filtered_summarized_tf_scores_df) * 0.035))\n",
    "    cluster_map = sns.clustermap(filtered_summarized_tf_scores_df, cbar_kws={\"label\": \"t-score\"}, figsize=calc_size, cmap=\"vlag\", center=0, \n",
    "                                yticklabels=False, cbar_pos=(1, 0.5, 0.02, 0.1), dendrogram_ratio=(0.2, 0.05))\n",
    "    cluster_map.ax_heatmap.set_xlabel(\"Cell Type\")\n",
    "    cluster_map.ax_heatmap.set_ylabel(\"Transcription Factor\")\n",
    "    plt.setp(cluster_map.ax_heatmap.get_xticklabels(), rotation=90) \n",
    "    \n",
    "    plt.savefig(out_path + \"/tf_activity_compressed_\" + condition + \".pdf\", bbox_inches='tight')\n",
    "    plt.close()\n",
    "\n",
    "    calc_size = ((len(filtered_summarized_tf_scores_df.columns.unique()) * 1.5), (len(filtered_summarized_tf_scores_df) * 0.2))\n",
    "    cluster_map = sns.clustermap(filtered_summarized_tf_scores_df, cbar_kws={\"label\": \"t-score\"}, figsize=calc_size, cmap=\"vlag\", center=0, annot= tag_mapping, fmt=\"\", \n",
    "                                yticklabels=True, cbar_pos=(1, 0.5, 0.03, 0.05), dendrogram_ratio=(0.2, 0.05))\n",
    "    cluster_map.ax_heatmap.set_xlabel(\"Cell Type\")\n",
    "    cluster_map.ax_heatmap.set_ylabel(\"Transcription Factor\")\n",
    "    plt.setp(cluster_map.ax_heatmap.get_xticklabels(), rotation=90) \n",
    "\n",
    "    plt.savefig(out_path + \"/tf_activity_\" + condition + \".pdf\", bbox_inches='tight')\n",
    "    plt.close()\n",
    "\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def h_clust(data):\n",
    "            dist_matrix = pdist(data.T)\n",
    "            linkage_matrix = linkage(dist_matrix, method = \"average\")   \n",
    "            return linkage_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_condition_tf_activities(tf_activity_tables, out_path):\n",
    "       \n",
    "   for result_name, df in tf_activity_tables.items():\n",
    "        name_df = pd.DataFrame(df)\n",
    "        significant_res = name_df[name_df[\"tag\"] == \"***\"]\n",
    "        significant_genes = np.unique(significant_res[\"tf\"])\n",
    "        name_df = name_df[name_df['tf'].isin(significant_genes)]\n",
    "        \n",
    "\n",
    "        tag_mapping = name_df[[\"tf\", \"tag\", \"CellType\"]]\n",
    "        #print(tag_mapping)\n",
    "        tag_mapping = tag_mapping.pivot(index=\"tf\", columns=\"CellType\", values=\"tag\")\n",
    "        tag_mapping.fillna(\"ns\", inplace=True)\n",
    "    \n",
    "        name_df_r = name_df[[\"r\", \"tf\", \"CellType\"]]\n",
    "        name_df_cluster = name_df_r.pivot_table(index = \"tf\", columns = \"CellType\", values = \"r\", aggfunc = \"mean\")\n",
    "        name_df_cluster.fillna(0, inplace=True) \n",
    "        \n",
    "        h_clust_matrix = h_clust(name_df_cluster)\n",
    "      \n",
    "        calc_size = ((len(name_df[\"CellType\"].unique()) * 1.5), (len(name_df_cluster) * 0.2))\n",
    "      \n",
    "        cluster_map = sns.clustermap(name_df_cluster, cbar_kws={\"label\": \"r\"}, figsize=calc_size, cmap=\"vlag\", center=0, annot= tag_mapping,\n",
    "                      col_linkage= h_clust_matrix, fmt=\"\", yticklabels=True, cbar_pos=(1, 0.5, 0.03, 0.05), dendrogram_ratio=(0.2, 0.05))\n",
    "        plt.setp(cluster_map.ax_heatmap.get_xticklabels(), rotation=90)  \n",
    "\n",
    "        plt.savefig(out_path + \"/\" + result_name + \"_cluster_condition_activity_difference.pdf\", bbox_inches='tight')\n",
    "        plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_condition_tf_activities_compressed(tf_activity_tables, out_path):\n",
    " \n",
    "  \n",
    "    for result_name, df in tf_activity_tables.items():\n",
    "        name_df = pd.DataFrame(df)\n",
    "        \n",
    "        significant_res = name_df[name_df[\"tag\"] == \"***\"]\n",
    "        significant_genes = np.unique(significant_res[\"tf\"])\n",
    "        name_df = name_df[name_df['tf'].isin(significant_genes)]\n",
    "        \n",
    "        name_df_r = name_df[[\"r\", \"tf\", \"CellType\"]]\n",
    "        name_df_cluster = name_df_r.pivot_table(index = \"tf\", columns = \"CellType\", values = \"r\", aggfunc = \"mean\")\n",
    "        name_df_cluster.fillna(0, inplace=True) \n",
    "\n",
    "        h_clust_matrix = h_clust(name_df_cluster)\n",
    "        name_df_cluster.reset_index()\n",
    "\n",
    "        calc_size = ((len(name_df[\"CellType\"].unique()) * 1.5), (len(name_df_cluster) * 0.05))\n",
    "        cluster_map = sns.clustermap(name_df_cluster, cbar_kws={\"label\": \"r\"}, figsize=calc_size, cmap=\"vlag\", center=0, annot= None,\n",
    "                       yticklabels=False, col_linkage= h_clust_matrix, fmt=\"\", cbar_pos=(1, 0.5, 0.02, 0.1), dendrogram_ratio=(0.2, 0.05))\n",
    "        plt.setp(cluster_map.ax_heatmap.get_xticklabels(), rotation=90) \n",
    "        cluster_map.figure.suptitle(result_name)\n",
    "        \n",
    "        \n",
    "        plt.savefig(out_path + \"/\" + result_name +  \"_cluster_condition_activity_difference_compressed.pdf\", bbox_inches='tight')\n",
    "        plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def map_z_value(tf_scores_df, anndataobject_markers):\n",
    "    genes = []\n",
    "    clusters = []\n",
    "    t_values = []  \n",
    "\n",
    "    anndataobject_markers = anndataobject_markers.set_index(\"gene\")\n",
    "    \n",
    "    for i in range(len(anndataobject_markers.index)):\n",
    "        a = anndataobject_markers.index[i]\n",
    "        for j in range(len(tf_scores_df.index)):\n",
    "            b = tf_scores_df.index[j]\n",
    "            if a == b:\n",
    "                c = anndataobject_markers.columns.get_loc(\"cluster\")\n",
    "                cluster = anndataobject_markers.iloc[i, c]\n",
    "                gene_rows = tf_scores_df.iloc[j]\n",
    "                if isinstance(gene_rows, pd.Series):\n",
    "                    gene_rows = gene_rows.to_frame().T\n",
    "\n",
    "                for _, gene_row in gene_rows.iterrows():\n",
    "                     score = gene_row[cluster]\n",
    "                     genes.append(a)\n",
    "                     clusters.append(cluster)\n",
    "                     t_values.append(score)\n",
    "\n",
    "    t_value_df = pd.DataFrame({\n",
    "        'gene': genes,\n",
    "        'cluster': clusters,\n",
    "        't_value': t_values\n",
    "    })\n",
    "\n",
    "    return t_value_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_entry(source, target, gene_A, gene_B, type_gene_A, type_gene_B, MeanLR):\n",
    "  df = {\"source\" : source,\n",
    "      \"target\" : target,\n",
    "      \"gene_A\" : gene_A,\n",
    "      \"gene_B\" : gene_B,\n",
    "      \"type_gene_A\" : type_gene_A,\n",
    "      \"type_gene_B\" : type_gene_B,\n",
    "      \"MeanLR\" : MeanLR}\n",
    "\n",
    "  return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_CrossTalkeR_input(tf_activities, gene_expression, out_path, regulon = None, organism = \"human\"):\n",
    "\n",
    "  if organism == \"human\":\n",
    "    ligands = pd.read_csv(\"ligands_human.csv\")\n",
    "    R2TF = pd.read_csv(\"rtf_db_human.csv\")\n",
    "  elif organism == \"mouse\": \n",
    "    ligands = pd.read_csv(\"ligands_mouse.csv\")\n",
    "    R2TF = pd.read_csv(\"rtf_db_mouse.csv\")\n",
    "  else:\n",
    "    NameError(\"Invalid organism to generate CrossTalkeR input!\")\n",
    "\n",
    "  R2TF = R2TF.set_index(\"tf\")\n",
    "\n",
    "  sorted_regulon = regulon[[\"tf\", \"target\"]]\n",
    "  sorted_regulon = sorted_regulon.set_index(\"tf\")\n",
    "\n",
    "\n",
    "  output_list = []\n",
    "  #print(\"gene epr index\", gene_expression.index)\n",
    "\n",
    "  for row in range(len((tf_activities))):\n",
    "    \n",
    "    tf_l = []\n",
    "    r_tf = []\n",
    "\n",
    "    #if (tf_activities[\"t_value\"].iloc[row] > 0):\n",
    "    tf = str(tf_activities[\"gene\"].iloc[row])\n",
    "    #print(\"tf\", tf)\n",
    "    if tf in sorted_regulon.index:\n",
    "      targets = sorted_regulon.loc[tf, \"target\"]\n",
    "      #print(\"targets\", targets)\n",
    "   \n",
    "    if tf in R2TF.index:\n",
    "        receptors = R2TF.loc[tf, \"receptor\"]\n",
    "        if isinstance(receptors, str):\n",
    "          receptors = [receptors]\n",
    "       \n",
    "    else:\n",
    "        receptors = []\n",
    "\n",
    "    \n",
    "\n",
    "    tf_ligands = np.intersect1d(targets, ligands)\n",
    "    \n",
    "  #print(\"tf ligands\", tf_ligands)\n",
    "\n",
    "    if organism == \"human\":\n",
    "      if len(tf_ligands) > 0:\n",
    "        for ligand in tf_ligands:\n",
    "            #print(\"ligand\", ligand)\n",
    "            expressed = False\n",
    "            if ligand in gene_expression.index:\n",
    "              ex_value = gene_expression.loc[ligand, tf_activities.iloc[row, 2]]\n",
    "              #print(\"ex value\", ex_value)\n",
    "              if (ex_value != 0):\n",
    "                expressed = True\n",
    "\n",
    "            if (expressed == True):\n",
    "              df_list_l = add_entry(source = tf_activities.iloc[row, 2],\n",
    "                                                      target = tf_activities.iloc[row, 2],\n",
    "                                                      gene_A =tf_activities.iloc[row, 0],\n",
    "                                                      gene_B = ligand,\n",
    "                                                      type_gene_A = \"Transcription_Factor\",\n",
    "                                                      type_gene_B= \"Ligand\",\n",
    "                                                      MeanLR= tf_activities.iloc[row, 3]\n",
    "                                                      )\n",
    "              \n",
    "            #print(\"df list l\", df_list_l)  \n",
    "              output_list.append(df_list_l)\n",
    "              \n",
    "\n",
    "      if (len(receptors) > 0):\n",
    "        for receptor in receptors:\n",
    "          #print(\"receptor\", receptor)\n",
    "          df_list_r = add_entry(source = tf_activities.iloc[row, 2],\n",
    "                                                target = tf_activities.iloc[row, 2],\n",
    "                                                gene_A= receptor,\n",
    "                                                gene_B= tf_activities.iloc[row, 0],\n",
    "                                                type_gene_A= \"Receptor\",\n",
    "                                                type_gene_B= \"Transcription Factor\",\n",
    "                                                MeanLR= tf_activities.iloc[row, 3]\n",
    "                                                )\n",
    "          #print(\"df list r\", df_list_r)\n",
    "          output_list.append(df_list_r)\n",
    "\n",
    "      \n",
    "          \n",
    "    else: \n",
    "      if len(tf_ligands) > 0:\n",
    "        for ligand in tf_ligands:\n",
    "            expressed = False\n",
    "            translations = ligand\n",
    "            if len(translations) > 0:\n",
    "              for l in translations:\n",
    "                #print(gene_expression.index)\n",
    "                if l in gene_expression.index:\n",
    "                  ex_value = gene_expression.loc[l, tf_activities.iloc[row, 2]]\n",
    "                  if (ex_value != 0):\n",
    "                    expressed = True\n",
    "          \n",
    "                df_list_l = []\n",
    "            \n",
    "                if (expressed == True):\n",
    "                  df_list_l = add_entry(source = tf_activities.iloc[row, 2],\n",
    "                                                      target = tf_activities.iloc[row, 2],\n",
    "                                                      gene_A =tf_activities.iloc[row, 0],\n",
    "                                                      gene_B = ligand,\n",
    "                                                      type_gene_A = \"Transcription_Factor\",\n",
    "                                                      type_gene_B= \"Ligand\",\n",
    "                                                      MeanLR= tf_activities.iloc[row, 3]\n",
    "                                                      )\n",
    "                \n",
    "                  output_list.append(df_list_l)\n",
    "      \n",
    "      if (len(receptors) > 0):\n",
    "        for receptor in receptors:\n",
    "          df_list_r = [] \n",
    "          df_list_r = add_entry(tf_activities.iloc[row, 2],\n",
    "                                                tf_activities.iloc[row, 2],\n",
    "                                                receptor,\n",
    "                                                tf_activities.iloc[row, 0],\n",
    "                                                \"Receptor\",\n",
    "                                                \"Transcription Factor\",\n",
    "                                                tf_activities.iloc[row, 3]\n",
    "                                                )\n",
    "                                                \n",
    "          output_list.append(df_list_r)\n",
    "        #tf_l.to_csv(single_result_path + \"/\" + renamed_condition + \"_ctr_test_l.csv\", index=0)\n",
    "        #r_tf.to_csv(single_result_path + \"/\" + renamed_condition + \"_ctr_test_r.csv\", index=0)\n",
    "   \n",
    "\n",
    "  output_df = pd.DataFrame(output_list)\n",
    "  output_df[\"gene_A\"] = output_df[\"gene_A\"].apply(lambda x: re.sub(\"_\", \"+\", x))\n",
    "  output_df[\"gene_B\"] = output_df[\"gene_B\"].apply(lambda x: re.sub(\"_\", \"+\", x))\n",
    "  output_df.to_csv(\"tf_l_r.csv\", index=0)\n",
    "\n",
    "\n",
    "  return output_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_intracellular_network(tf_activities, gene_expression, outpath, regulon, organism=\"human\"):\n",
    "\n",
    "    if len(tf_activities.shape) > 0:\n",
    "        if organism == \"human\":\n",
    "            R2TF = pd.read_csv(\"rtf_db_human.csv\").set_index(\"tf\")\n",
    "        else:\n",
    "            R2TF = pd.read_csv(\"rtf_db_mouse.csv\").set_index(\"tf\")\n",
    "\n",
    "    sorted_regulon = regulon[[\"tf\", \"target\"]].set_index(\"tf\")\n",
    "\n",
    "    #preextract values\n",
    "    tf_genes = tf_activities[\"gene\"].values\n",
    "    tf_celltypes = tf_activities.iloc[:, 2].values\n",
    "    tf_scores = tf_activities.iloc[:, 3].values\n",
    "\n",
    "    TFTG_list = []\n",
    "    RTF_list = []\n",
    "\n",
    "    for row in range(len(tf_activities)):\n",
    "        tf = str(tf_genes[row])\n",
    "        celltype = tf_celltypes[row]\n",
    "        tf_score = tf_scores[row]\n",
    "\n",
    "        targets = sorted_regulon.loc[tf, \"target\"] if tf in sorted_regulon.index else []\n",
    "        receptors = R2TF.loc[tf, \"receptor\"] if tf in R2TF.index else []\n",
    "\n",
    "        if len(targets) > 0 and len(receptors) > 0:\n",
    "            for target in targets:\n",
    "                if target in gene_expression.index:\n",
    "                    ex_value = gene_expression.at[target, celltype]\n",
    "                    if ex_value != 0:\n",
    "                        TFTG_list.append({\n",
    "                            \"celltype\": celltype,\n",
    "                            \"TF\": tf,\n",
    "                            \"Target_Gene\": target,\n",
    "                            \"TF_Score\": tf_score\n",
    "                        })\n",
    "\n",
    "            for receptor in receptors:\n",
    "                RTF_list.append({\n",
    "                    \"TF\": tf,\n",
    "                    \"Receptor\": receptor\n",
    "                })\n",
    "\n",
    "    TFTG_df = pd.DataFrame(TFTG_list)\n",
    "    RTF_df = pd.DataFrame(RTF_list)\n",
    "\n",
    "    recept_regulon = pd.merge(RTF_df, TFTG_df, on=\"TF\")\n",
    "\n",
    "    return recept_regulon"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "#decoupler condition comparison\n",
    "def condition_comparison_significant(tf_activities, out_path, celltype, condition, comparison_list, num_cell_filter = 0):\n",
    "\n",
    "    tf_activities = sc.pp.scale(tf_activities, copy= True)\n",
    "    \n",
    "    vs_df_dic = {}\n",
    "\n",
    "    if isinstance(comparison_list[0], str):  \n",
    "        comparison_list = [comparison_list]\n",
    "    \n",
    "    for vs1, vs2 in comparison_list:\n",
    "\n",
    "        print(f\"vs1: {vs1}, vs2: {vs2}\") \n",
    "\n",
    "        all_tf_list = tf_activities.var_names\n",
    "\n",
    "        res = pd.DataFrame()\n",
    "        for i in tf_activities.obs[celltype].unique(): \n",
    "            comparison_sub = tf_activities[(tf_activities.obs[celltype] == i) & (tf_activities.obs[condition].isin([vs1, vs2]))]\n",
    "            if len(pd.unique(comparison_sub.obs[condition])) == 2:\n",
    "                condition_table = comparison_sub.obs[[condition]].copy()\n",
    "                condition_table.columns = [\"condition\"]\n",
    "                metadata_counts = condition_table.groupby(\"condition\", observed = False).size()\n",
    "                \n",
    "                if (metadata_counts.iloc[0] + metadata_counts.iloc[1]) > num_cell_filter:\n",
    "                    g = comparison_sub.obs[condition].astype(\"category\")\n",
    "                    g = g.cat.set_categories([vs1, vs2])\n",
    "                    \n",
    "                    #scanpy\n",
    "                    #sc.tl.rank_genes_groups(comparison_sub, groupby= condition,\n",
    "                     #                    reference=\"rest\", method=\"wilcoxon\", key_added=\"condition_comp_markers\", corr_method= \"bonferroni\")\n",
    "                    \n",
    "                    #sc.pl.rank_genes_groups_heatmap(comparison_sub, show_gene_labels=True, key=\"condition_comp_markers\")\n",
    "\n",
    "                    #res_tmp = sc.get.rank_genes_groups_df(comparison_sub, group = None, log2fc_min=0, key=\"condition_comp_markers\")\n",
    "                    #######\n",
    "\n",
    "                    #decoupler\n",
    "                    comparison_sub = sc.pp.scale(comparison_sub, copy= True)\n",
    "                    res_tmp = dc.rank_sources_groups(comparison_sub, groupby= condition, reference=\"rest\", method=\"wilcoxon\")\n",
    "                    res_tmp.rename(columns={\"group\": \"condition\", \"statistic\" : \"scores\"}, inplace=True)\n",
    "            \n",
    "               \n",
    "\n",
    "                    group1 = comparison_sub.X[g == vs1]\n",
    "                    group2 = comparison_sub.X[g == vs2]\n",
    "                        \n",
    "                    \n",
    "                    res_tmp[\"r\"] = res_tmp[\"scores\"] / np.sqrt(len(group1) + len(group2))\n",
    "                    res_tmp[\"CellType\"] = i\n",
    "                    _, res_tmp[\"FDR\"], _, _ = multipletests(res_tmp[\"pvals\"], alpha=0.05, method='fdr_bh')\n",
    "                    \n",
    "                    \n",
    "                    res_tmp[\"meanchange\"] = res_tmp[\"meanchange\"].where(res_tmp[\"meanchange\"] > 0, np.nan) \n",
    "                    \n",
    "\n",
    "                    res = pd.concat([res, res_tmp], ignore_index=True)\n",
    "\n",
    "        res_df = res.dropna()\n",
    "\n",
    "        def assign_significance_tag(fdr):\n",
    "            if fdr < 0.001:\n",
    "                return \"***\"\n",
    "            elif fdr < 0.01:\n",
    "                return \"**\"\n",
    "            elif fdr < 0.05:\n",
    "                return \"*\"\n",
    "            else:\n",
    "                return \"ns\"\n",
    "\n",
    "        res_df[\"tag\"] = res_df[\"FDR\"].apply(assign_significance_tag)\n",
    "        \n",
    "        res_df.rename(columns={\"names\":\"tf\", \"group\": \"condition\"}, inplace=True)\n",
    "        res_df.to_csv(f\"{out_path}/all_tfs_{vs1}_vs_{vs2}.csv\", index=False)\n",
    "\n",
    "        result_name = f\"{vs1}_{vs2}\"\n",
    "        vs_df_dic[result_name] = res_df\n",
    "        #print(vs_df_dic[result_name])\n",
    "    return vs_df_dic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "#decoupler significant tfs\n",
    "\n",
    "def get_significant_tfs(tf_activities_sub, condition, out_path, tf_condition_significant, celltype, pval, meanchange, plot, condition_comparison = False):\n",
    "    \n",
    "    renamed_condition = condition.replace(\",\", \"_\")\n",
    "\n",
    "    single_result_path = out_path + renamed_condition \n",
    "    if not os.path.isdir(single_result_path):\n",
    "        os.mkdir(single_result_path)\n",
    "        \n",
    "    tf_activities_scaled = sc.pp.scale(tf_activities_sub, copy= True)\n",
    "\n",
    "    #tf_activities_sub = sc.pp.normalize_total(tf_activities_scaled, copy=True)\n",
    "    #tf_activities_sub = sc.pp.log1p(tf_activities_sub, copy=True) \n",
    "    # \"warning: seems to be already log transformed\"\n",
    "\n",
    "    number_of_clusters = len(tf_activities_sub.obs[\"new_annotation\"].cat.categories) \n",
    "    anndataobject_markers_wilcoxon = dc.rank_sources_groups(tf_activities_sub, groupby= \"new_annotation\", reference=\"rest\", method=\"wilcoxon\")\n",
    "\n",
    "    anndataobject_markers_wilcoxon.rename(columns={\"names\" : \"gene\", \"group\": \"cluster\", \"statistic\" : \"scores\"}, inplace=True)\n",
    "    \n",
    "    #\n",
    "    anndataobject_markers_wilcoxon[\"tag\"] = None\n",
    "    anndataobject_markers_wilcoxon[\"meanchange_tag\"] = None\n",
    "    \n",
    "    #print(\"after concat\", anndataobject_markers_wilcoxon)\n",
    "    \n",
    "    anndataobject_markers_wilcoxon[\"tag\"] = anndataobject_markers_wilcoxon[\"pvals_adj\"].apply(eval_pval)\n",
    "    anndataobject_markers_wilcoxon[\"meanchange_tag\"] = anndataobject_markers_wilcoxon[\"meanchange\"].apply(eval_meanchange_tag)\n",
    "     \n",
    "\n",
    "    anndataobject_markers_wilcoxon.to_csv(single_result_path + \"/\" + renamed_condition + \"_specific_markers_wilcoxon_test.csv\",index=0)\n",
    "\n",
    "   #tag mapping wilcoxon\n",
    "    tag_mapping_wilcox = anndataobject_markers_wilcoxon[[\"gene\", \"tag\", \"meanchange_tag\", \"cluster\", \"pvals_adj\", \"meanchange\"]]\n",
    "    tag_mapping_wilcox = tag_mapping_wilcox[(tag_mapping_wilcox[\"pvals_adj\"] < float(pval))] \n",
    "    tag_mapping_wilcox = tag_mapping_wilcox[(tag_mapping_wilcox[\"meanchange\"] > float(meanchange)) | \n",
    "                              (tag_mapping_wilcox[\"meanchange\"] < -float(meanchange))]\n",
    "\n",
    "    tag_mapping_wilcox = tag_mapping_wilcox.pivot(index=\"gene\", columns=\"cluster\", values=\"tag\")\n",
    "    clusters = anndataobject_markers_wilcoxon[\"cluster\"].unique()\n",
    "\n",
    "    for cluster in clusters:\n",
    "        if cluster not in tag_mapping_wilcox.columns:\n",
    "            tag_mapping_wilcox[cluster] = np.nan\n",
    "\n",
    "    tag_mapping_wilcox = tag_mapping_wilcox.astype(\"object\")\n",
    "    tag_mapping_wilcox.fillna(\"ns\", inplace=True)\n",
    "    \n",
    "    #makes the index of the subobject not unique --- not possible to filter by index after this\n",
    "    tf_activities_scaled.obs_names = tf_activities_scaled.obs[celltype]\n",
    "    tf_scores_df = tf_activities_scaled.to_df()\n",
    "    tf_scores_df.columns.name = None\n",
    "    unfiltered_tf_scores = create_unfiltered_tf_scores(tf_scores_df, condition, celltype, single_result_path)\n",
    "   \n",
    "    #Filter to only include tfs that match the tag_mapping/are markers\n",
    "    #print(tag_mapping_wilcox)\n",
    "    col_num = tf_scores_df.columns.isin(tag_mapping_wilcox.index)  \n",
    "    #print(col_num)\n",
    "    filtered_tf_scores_df = tf_scores_df.loc[:, sorted(col_num)]\n",
    "\n",
    "\n",
    "    filtered_summarized_tf_scores_df = filtered_tf_scores_df.groupby(celltype, observed = False).mean().T\n",
    "    filtered_summarized_tf_scores_df.index.name = \"gene\"\n",
    "    filtered_summarized_tf_scores_df.to_csv(f\"{single_result_path}/tf_scores_{condition}.csv\")\n",
    "    tf_scores_variable_table = save_variable_tf_score(filtered_summarized_tf_scores_df, condition, single_result_path, plot)\n",
    "\n",
    "    if plot:\n",
    "        plot_tf_activity(filtered_summarized_tf_scores_df, tag_mapping_wilcox, condition, single_result_path)\n",
    "    \n",
    "    filtered_summarized_tf_scores_df.index = filtered_summarized_tf_scores_df.index.map(lambda x: re.sub(\".,\", \"_\", x))\n",
    "   \n",
    "    filtered_summarized_tf_scores_df = filtered_summarized_tf_scores_df.where(filtered_summarized_tf_scores_df > 0, np.nan) \n",
    "    \n",
    "    anndataobject_markers_wilcoxon_merged = anndataobject_markers_wilcoxon.merge(map_z_value(filtered_summarized_tf_scores_df, anndataobject_markers_wilcoxon),  on=['gene', 'cluster'], how='inner')\n",
    "    anndataobject_markers_wilcoxon_merged = anndataobject_markers_wilcoxon_merged[anndataobject_markers_wilcoxon_merged.tag != \"ns\"]\n",
    "    anndataobject_markers_wilcoxon_merged.dropna(inplace=True)\n",
    "    res_wilcoxon = anndataobject_markers_wilcoxon_merged[[\"gene\",\"tag\", \"cluster\", \"t_value\"]]\n",
    "\n",
    "    #anndataobject_markers_t_over_merged = anndataobject_markers_t_over.merge(map_z_value_filtered(filtered_summarized_tf_scores_df, anndataobject_markers_t_over),  on=['gene', 'cluster'], how='inner')\n",
    "    #anndataobject_markers_t_over_merged = anndataobject_markers_t_over_merged[anndataobject_markers_t_over_merged.tag != \"ns\"]\n",
    "    #anndataobject_markers_t_over_merged.dropna(inplace=True)\n",
    "    #res_t_test = anndataobject_markers_t_over[[\"gene\",\"tag\", \"cluster\", \"t_value\"]]\n",
    "\n",
    "    res_wilcoxon.to_csv(single_result_path + \"/significant_cluster_tf_results_wilcoxon_\" + renamed_condition + \".csv\", index=0)\n",
    "    #res_t_test.to_csv(single_result_path  + \"/_significant_cluster_tf_results_t_test_\" + renamed_condition + \".csv\", index=0)\n",
    "\n",
    "    res = {}\n",
    "    res[\"cluster\"] = res_wilcoxon\n",
    "    \n",
    "    tf_condition_significant[\"gene\"] = tf_condition_significant[\"gene\"].apply(lambda x: re.sub(\".,\", \"_\", x))\n",
    "\n",
    "    if condition_comparison:\n",
    "        unfiltered_tf_scores = unfiltered_tf_scores.where(unfiltered_tf_scores > 0, np.nan) \n",
    "        tf_condition_significant = tf_condition_significant.merge(map_z_value(unfiltered_tf_scores, tf_condition_significant), left_on=None, right_on=None, left_index=False, right_index=False)\n",
    "        tf_condition_significant.dropna(inplace=True)\n",
    "    \n",
    "        res[\"condition\"] = tf_condition_significant\n",
    "        res[\"condition\"].to_csv(f\"{single_result_path}/significant_condition_tf_results_{condition}.csv\", index=0)\n",
    "\n",
    "    return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def IntraTalker_analysis(anndataobject, tf_activities = None, arguments_list = None):\n",
    "    \n",
    "    if (isinstance(anndataobject, str)):\n",
    "        anndataobject = ad.read_h5ad(anndataobject)\n",
    "\n",
    "    arguments_list = validate_input_arguments(arguments_list)\n",
    "\n",
    "    if arguments_list[\"decoupler_matrix_format\"] == \"R\":\n",
    "        anndataobject = anndataobject.T\n",
    "\n",
    "    if not os.path.isdir(arguments_list[\"out_path\"]):\n",
    "        os.mkdir(arguments_list[\"out_path\"])\n",
    "        tf_path = arguments_list[\"out_path\"] + \"TF_results/\"\n",
    "        os.mkdir(tf_path)\n",
    "    else:\n",
    "        tf_path = arguments_list[\"out_path\"] + \"TF_results/\"\n",
    "\n",
    "\n",
    "    condition = anndataobject.obs[arguments_list[\"condition\"]]\n",
    "\n",
    "    if isinstance(tf_activities, str):\n",
    "         tf_activities = ad.read_csv(tf_activities)\n",
    "         tf_activities.obs = anndataobject.obs.reindex(tf_activities.obs.index)\n",
    "         tf_activities.obsm = anndataobject.obsm\n",
    "         tf_activities.uns = anndataobject.uns\n",
    "\n",
    "    elif tf_activities is None:\n",
    "         raise NameError(\"Please attach a csv file with the tf activity values. (For further clarification view the 'Decoupler' section of the vignette.)\")\n",
    "        \n",
    "\n",
    "    #sets the stage for decision if single condition or comparison analysis is done\n",
    "\n",
    "    if (len(arguments_list[\"comparison_list\"]) > 0) & (len(pd.unique(anndataobject.obs[arguments_list[\"condition\"]])) < 2):\n",
    "        arguments_list[\"comparison_list\"] = np.nan\n",
    "        print(\"Only one condition was found in the data, although a list of comparisons was provided. The analyses are performed only for the present condition!\")\n",
    "\n",
    "    #code for single condition  analysis\n",
    "\n",
    "    if pd.isnull(arguments_list[\"comparison_list\"][0]):\n",
    "\n",
    "        result_list = {}\n",
    "        gene_expression_list = {}\n",
    "        CTR_cluster_list = {}\n",
    "        intranet_cluster_list = {}\n",
    "\n",
    "        #creates loop until after tf activity score\n",
    "        \n",
    "        for name_iterable in anndataobject.obs[arguments_list[\"condition\"]].unique():\n",
    "            sub_object = anndataobject[anndataobject.obs[arguments_list[\"condition\"]] == name_iterable].copy()\n",
    "            tf_activities_sub = tf_activities[tf_activities.obs[arguments_list[\"condition\"]] == name_iterable].copy()\n",
    "\n",
    "            sub_object_avg = AverageExpression(sub_object, name_iterable= name_iterable, celltype = arguments_list[\"celltype\"], outpath= arguments_list[\"out_path\"])\n",
    "        \n",
    "            \n",
    "            tf_activity_scores = get_significant_tfs(tf_activities_sub,\n",
    "                                                        name_iterable,\n",
    "                                                        tf_path,\n",
    "                                                        None,\n",
    "                                                        celltype = arguments_list[\"celltype\"],\n",
    "                                                        pval = arguments_list[\"pval\"],\n",
    "                                                        meanchange = arguments_list[\"meanchange\"],\n",
    "                                                        plot = arguments_list[\"plot\"],\n",
    "                                                        condition_comparison= False)\n",
    "            \n",
    "\n",
    "            result_list[name_iterable] = tf_activity_scores\n",
    "            \n",
    "            gene_expression_list[name_iterable] = sub_object_avg\n",
    "            \n",
    "        \n",
    "    \n",
    "            CTR_cluster_list[name_iterable] = generate_CrossTalkeR_input(tf_activity_scores[\"cluster\"],\n",
    "                                                                            gene_expression_list[name_iterable],\n",
    "                                                                            arguments_list[\"out_path\"],                                             \n",
    "                                                                            arguments_list[\"reg\"],\n",
    "                                                                            arguments_list[\"organism\"])\n",
    "    \n",
    "              \n",
    "            intranet_cluster_list[name_iterable] = generate_intracellular_network(tf_activity_scores[\"cluster\"],\n",
    "                                                                                  gene_expression_list[name_iterable],\n",
    "                                                                                  arguments_list[\"out_path\"],\n",
    "                                                                                  arguments_list[\"reg\"],\n",
    "                                                                                  arguments_list[\"organism\"])\n",
    "            \n",
    "\n",
    "        tf = make_TFOBj(\n",
    "                tf_activities_condition = list(),\n",
    "                tf_activities_cluster = result_list,\n",
    "                average_gene_expression = gene_expression_list,\n",
    "                regulon = arguments_list[\"reg\"],\n",
    "                CTR_input_condition = list(),\n",
    "                CTR_input_cluster = CTR_cluster_list,\n",
    "                intracellular_network_condition = list(),\n",
    "                intracellular_network_cluster = intranet_cluster_list)\n",
    "\n",
    "        with open((arguments_list[\"out_path\"] + \"tf.pickle\"), \"wb\") as file:\n",
    "            pickle.dump(tf, file)\n",
    "\n",
    "        return tf\n",
    "\n",
    "    else:\n",
    "        out_path_compared = (tf_path + \"compared\")\n",
    "        if not os.path.isdir(out_path_compared):\n",
    "            os.mkdir(out_path_compared)\n",
    "\n",
    "        compared_significant_tfs = condition_comparison_significant(tf_activities, out_path_compared, arguments_list[\"celltype\"], \n",
    "                                                                    arguments_list[\"condition\"], arguments_list[\"comparison_list\"], \n",
    "                                                                    arguments_list[\"num_cell_filter\"])\n",
    "        \n",
    "        print(\"compared tfs done\")\n",
    "        \n",
    "        if arguments_list[\"plot\"] == True:\n",
    "            plot_condition_tf_activities(compared_significant_tfs, out_path_compared)\n",
    "            plot_condition_tf_activities_compressed(compared_significant_tfs, out_path_compared)\n",
    "\n",
    "    \n",
    "        result_condition_list = {}\n",
    "        result_cluster_list = {}\n",
    "        gene_expression_list = {}\n",
    "        CTR_condition_list = {}\n",
    "        CTR_cluster_list = {}\n",
    "        intranet_condition_list = {}\n",
    "        intranet_cluster_list = {}\n",
    "\n",
    "        for name_iterable in anndataobject.obs[arguments_list[\"condition\"]].unique():\n",
    "            sub_object = anndataobject[anndataobject.obs[arguments_list[\"condition\"]] == name_iterable]\n",
    "            tf_activities_sub = tf_activities[tf_activities.obs[arguments_list[\"condition\"]] == name_iterable]\n",
    "            \n",
    "\n",
    "            compared_tfs = pd.DataFrame({\"gene\" : pd.Series(dtype=\"str\"), \"tag\" : pd.Series(dtype=\"str\"), \"cluster\" : pd.Series(dtype=\"str\")})\n",
    "            #print(\"before\", compared_significant_tfs)\n",
    "        \n",
    "            for result_name, df in compared_significant_tfs.items(): \n",
    "                if name_iterable in result_name:\n",
    "                    tf_condition_significant = compared_significant_tfs[result_name]\n",
    "                    tf_condition_significant = tf_condition_significant[tf_condition_significant[\"FDR\"] < arguments_list[\"pval\"]]\n",
    "                    tf_condition_significant = tf_condition_significant[(tf_condition_significant[\"meanchange\"] > float(arguments_list[\"meanchange\"])) | (tf_condition_significant[\"meanchange\"] < (0 - float(arguments_list[\"meanchange\"])))]\n",
    "                    tf_condition_significant = tf_condition_significant[[\"tf\", \"tag\", \"CellType\"]]\n",
    "                    tf_condition_significant.rename(columns={\"tf\":\"gene\", \"CellType\": \"cluster\"}, inplace=True)\n",
    "                    compared_tfs = pd.concat([compared_tfs, tf_condition_significant])\n",
    "\n",
    "        \n",
    "            \n",
    "            re.sub(\"([,;.:-])\", \"_\", name_iterable)\n",
    "\n",
    "            sub_object_avg = AverageExpression(sub_object, name_iterable= name_iterable, celltype = arguments_list[\"celltype\"], \n",
    "                                               outpath= arguments_list[\"out_path\"])\n",
    "            \n",
    "            tf_activity_scores = get_significant_tfs(tf_activities_sub,\n",
    "                                               name_iterable,\n",
    "                                               tf_path,\n",
    "                                               compared_tfs,\n",
    "                                               celltype = arguments_list[\"celltype\"],\n",
    "                                               pval = arguments_list[\"pval\"],\n",
    "                                               meanchange = arguments_list[\"meanchange\"],\n",
    "                                               plot = arguments_list[\"plot\"],\n",
    "                                               condition_comparison= True)\n",
    "            \n",
    "            print(\"tf_activities done\")\n",
    "\n",
    "            result_condition_list[name_iterable] = tf_activity_scores[\"condition\"]\n",
    "            result_cluster_list[name_iterable] = tf_activity_scores[\"cluster\"]\n",
    "\n",
    "            #print(result_condition_list[name_iterable])\n",
    "            #print(result_cluster_list[name_iterable])\n",
    "\n",
    "            gene_expression_list[name_iterable] = sub_object_avg\n",
    "            \n",
    "        \n",
    "            CTR_condition_list[name_iterable] = generate_CrossTalkeR_input(tf_activity_scores[\"condition\"],\n",
    "                                                                            gene_expression_list[name_iterable],\n",
    "                                                                           arguments_list[\"out_path\"],                                             \n",
    "                                                                           arguments_list[\"reg\"],\n",
    "                                                                           arguments_list[\"organism\"])\n",
    "            \n",
    "            print(\"CTR input condition done\")\n",
    "    \n",
    "            CTR_cluster_list[name_iterable] = generate_CrossTalkeR_input(tf_activity_scores[\"cluster\"],\n",
    "                                                                            gene_expression_list[name_iterable],\n",
    "                                                                            arguments_list[\"out_path\"],                                             \n",
    "                                                                            arguments_list[\"reg\"],\n",
    "                                                                            arguments_list[\"organism\"])\n",
    "    \n",
    "            print(\"CTR input cluster done\")\n",
    "\n",
    "            intranet_condition_list[name_iterable] = generate_intracellular_network(tf_activity_scores[\"condition\"],\n",
    "                                                                                  gene_expression_list[name_iterable],\n",
    "                                                                                  arguments_list[\"out_path\"],\n",
    "                                                                                  arguments_list[\"reg\"],\n",
    "                                                                                  arguments_list[\"organism\"])\n",
    "    \n",
    "            print(\"intranet input condition done\")\n",
    "\n",
    "            intranet_cluster_list[name_iterable] = generate_intracellular_network(tf_activity_scores[\"cluster\"],\n",
    "                                                                                  gene_expression_list[name_iterable],\n",
    "                                                                                  arguments_list[\"out_path\"],\n",
    "                                                                                  arguments_list[\"reg\"],\n",
    "                                                                                  arguments_list[\"organism\"])\n",
    "            print(\"intranet input cluster done\")\n",
    "            #print(CTR_cluster_list[name_iterable])\n",
    "            #print(CTR_condition_list[name_iterable])\n",
    "        tf = make_TFOBj(\n",
    "                tf_activities_condition = result_condition_list,\n",
    "                tf_activities_cluster = result_cluster_list,\n",
    "                average_gene_expression = gene_expression_list,\n",
    "                regulon = arguments_list[\"reg\"],\n",
    "                CTR_input_condition = CTR_condition_list,\n",
    "                CTR_input_cluster = CTR_cluster_list,\n",
    "                intracellular_network_condition = intranet_condition_list,\n",
    "                intracellular_network_cluster = intranet_cluster_list)\n",
    "\n",
    "        with open((arguments_list[\"out_path\"] + \"tf.pickle\"), \"wb\") as file:\n",
    "            pickle.dump(tf, file)\n",
    "        \n",
    "        return tf\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "vs1: PMF,MF2, vs2: control\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Larissa\\AppData\\Local\\Temp\\ipykernel_32364\\4068952423.py:71: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  res_df[\"tag\"] = res_df[\"FDR\"].apply(assign_significance_tag)\n",
      "C:\\Users\\Larissa\\AppData\\Local\\Temp\\ipykernel_32364\\4068952423.py:73: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  res_df.rename(columns={\"names\":\"tf\", \"group\": \"condition\"}, inplace=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "compared tfs done\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\studium\\LR2TF_HiWi\\.venv\\Lib\\site-packages\\anndata\\_core\\anndata.py:841: UserWarning: \n",
      "AnnData expects .obs.index to contain strings, but got values like:\n",
      "    ['Megakaryocyte', 'Fibroblast', 'MSC', 'Megakaryocyte', 'Megakaryocyte']\n",
      "\n",
      "    Inferred to be: categorical\n",
      "\n",
      "  names = self._prep_dim_index(names, \"obs\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf_activities done\n",
      "CTR input condition done\n",
      "CTR input cluster done\n",
      "intranet input condition done\n",
      "intranet input cluster done\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\studium\\LR2TF_HiWi\\.venv\\Lib\\site-packages\\anndata\\_core\\anndata.py:841: UserWarning: \n",
      "AnnData expects .obs.index to contain strings, but got values like:\n",
      "    ['Neural', 'MSC', 'Megakaryocyte', 'Neural', 'Neural']\n",
      "\n",
      "    Inferred to be: categorical\n",
      "\n",
      "  names = self._prep_dim_index(names, \"obs\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf_activities done\n",
      "CTR input condition done\n",
      "CTR input cluster done\n",
      "intranet input condition done\n",
      "intranet input cluster done\n"
     ]
    }
   ],
   "source": [
    "result = IntraTalker_analysis(anndataobject= \"LR2TF_test_run/anndata_object.h5ad\", \n",
    "                              tf_activities= \"decoupler_results.csv\",\n",
    "                              arguments_list= {\"out_path\" : \"script_test\", \n",
    "                                                \"celltype\" : \"new_annotation\",\n",
    "                                                \"condition\" : \"protocol\", \n",
    "                                                \"organism\" : \"human\", \n",
    "                                                \"comparison_list\" : [\"PMF,MF2\", \"control\"], #[\"control\", \"PMF,MF2\"]], \n",
    "                                                \"meanchange\" : \"0.5\",\n",
    "                                                \"pval\" : None, \n",
    "                                                \"num_cell_filter\": None,\n",
    "                                                \"reg\" : \"filterd_regulon.csv\",                                                                                              \n",
    "                                                \"plot\" : True,\n",
    "                                                \"decoupler_matrix_format\" : \"Python\"})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "result.CTR_input_condition[\"control\"].to_csv(\"py_ctr_input_wo_ctr_exp_tables.csv\")\n",
    "result.intracellular_network_condition[\"control\"].to_csv(\"py_intra_network_ctrl.csv\")\n",
    "result.intracellular_network_condition[\"PMF,MF2\"].to_csv(\"py_intra_network_PMF.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_node_type(df):\n",
    "    \n",
    "    df['gene_A'] = np.where(df['type_gene_A'] == 'Ligand', df['gene_A'] + '|L', df['gene_A'])\n",
    "    df['gene_A'] = np.where(df['type_gene_A'] == 'Receptor', df['gene_A'] + '|R', df['gene_A'])\n",
    "    df['gene_A'] = np.where(df['type_gene_A'] == 'Transcription Factor', df['gene_A'] + '|TF', df['gene_A'])\n",
    "    df['gene_B'] = np.where(df['type_gene_B'] == 'Ligand', df['gene_B'] + '|L', df['gene_B'])\n",
    "    df['gene_B'] = np.where(df['type_gene_B'] == 'Receptor', df['gene_B'] + '|R', df['gene_B'])\n",
    "    df['gene_B'] = np.where(df['type_gene_B'] == 'Transcription Factor', df['gene_B'] + '|TF', df['gene_B'])\n",
    "    return df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def combine_LR_and_TF(tf_table, LR_prediction, out_path, condition, add_nodetype = False):\n",
    "\n",
    "  if isinstance(LR_prediction, pd.DataFrame):\n",
    "    lr_table = LR_prediction\n",
    "  else: \n",
    "    lr_table = pd.read_csv(LR_prediction, index_col=0)\n",
    "  \n",
    "\n",
    "  intra_connections = pd.DataFrame()\n",
    "  for celltype in np.unique([lr_table[\"source\"], lr_table[\"target\"]]):\n",
    "    lr_filtered_ligands = lr_table[lr_table[\"source\"] == celltype]\n",
    "    lr_filtered_receptors = lr_table[lr_table[\"target\"] == celltype]\n",
    "    lr_ligands = np.unique(lr_filtered_ligands[\"gene_A\"])\n",
    "    lr_receptors = np.unique(lr_filtered_receptors[\"gene_B\"])\n",
    "    \n",
    "    tf_table_receptors = tf_table[(tf_table[\"target\"] == celltype) & (tf_table[\"type_gene_A\"] == \"Receptor\")]\n",
    "    tf_table_ligands = tf_table[(tf_table[\"source\"] == celltype) & (tf_table[\"type_gene_B\"] == \"Ligand\")]\n",
    "\n",
    "    tf_receptor_interactions =  tf_table_receptors[tf_table_receptors[\"gene_A\"].isin(lr_receptors)]\n",
    "    tf_ligand_interactions = tf_table_ligands[tf_table_ligands[\"gene_B\"].isin(lr_ligands)]\n",
    "\n",
    "    intra_connections = pd.concat([intra_connections, tf_receptor_interactions, tf_ligand_interactions])\n",
    "  intra_connections[\"all_pair\"] = (intra_connections[\"source\"] + \"/\" \n",
    "                                    + intra_connections[\"gene_A\"] + \"/\"\n",
    "                                    + intra_connections[\"target\"] + \"/\"\n",
    "                                    + intra_connections[\"gene_B\"])\n",
    "    \n",
    "  intra_connections = intra_connections.drop_duplicates(subset=[\"all_pair\"])\n",
    "  intra_connections.drop(columns=[\"all_pair\"], inplace=True)\n",
    "\n",
    "  complete_interactions = pd.concat([intra_connections, lr_table])\n",
    "\n",
    "  if add_nodetype:\n",
    "    complete_interactions = add_node_type(complete_interactions)\n",
    "      \n",
    "  complete_interactions.to_csv((out_path + \"CrossTalkeR_input_\" + condition + \".csv\"), index=0)\n",
    "  return(complete_interactions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def combine_LR_and_TF_unfiltered(tf_table, LR_prediction, out_path, condition, add_nodetype = False):\n",
    "\n",
    "  if isinstance(LR_prediction, pd.DataFrame):\n",
    "    lr_table = LR_prediction\n",
    "  else: \n",
    "    lr_table = pd.read_csv(LR_prediction, index_col=0)\n",
    "  \n",
    "\n",
    "\n",
    "  complete_interactions = pd.concat([tf_table, lr_table])\n",
    "\n",
    "  if add_nodetype:\n",
    "    complete_interactions = add_node_type(complete_interactions)\n",
    "      \n",
    "  complete_interactions.to_csv((out_path + \"CrossTalkeR_input_\" + condition + \"_unfiltered.csv\"), index=0)\n",
    "  return(complete_interactions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def combine_LR_and_TF_complexes(tf_table, LR_prediction, out_path, condition, add_nodetype = False):\n",
    "\n",
    "  if isinstance(LR_prediction, pd.DataFrame):\n",
    "    lr_table = LR_prediction\n",
    "  else: \n",
    "    lr_table = pd.read_csv(LR_prediction, index_col=0)\n",
    "  \n",
    "\n",
    "  intra_connections = pd.DataFrame()\n",
    "  for celltype in np.unique([lr_table[\"source\"], lr_table[\"target\"]]):\n",
    "    lr_filtered_ligands = lr_table[lr_table[\"source\"] == celltype]\n",
    "    lr_filtered_receptors = lr_table[lr_table[\"target\"] == celltype]\n",
    "    lr_ligands = np.unique(lr_filtered_ligands[\"gene_A\"])\n",
    "    lr_receptors = np.unique(lr_filtered_receptors[\"gene_B\"])\n",
    "    print(lr_receptors)\n",
    "\n",
    "    lr_receptors = pd.Series(lr_receptors)\n",
    "    contains_complex = lr_receptors.str.contains(\"_\", na=False)\n",
    "    \n",
    "    R_with_complex = lr_receptors[contains_complex]\n",
    "    print(\"R_with_complex\", R_with_complex)\n",
    "    R_without_complex = lr_receptors[(~contains_complex)]\n",
    "  \n",
    "    tf_table_receptors = tf_table[(tf_table[\"target\"] == celltype) & (tf_table[\"type_gene_A\"] == \"Receptor\")]\n",
    "    tf_receptor_interactions =  tf_table_receptors[tf_table_receptors[\"gene_A\"].isin(R_without_complex)]\n",
    "\n",
    "    c_receptors = tf_table_receptors[tf_table_receptors[\"gene_A\"].apply(lambda x: any(gene in x.split(\"+\") for gene in lr_receptors))]\n",
    "    print(c_receptors)\n",
    "\n",
    "    complex_df = pd.DataFrame()\n",
    "    if len(R_with_complex) > 0:\n",
    "      for complex in R_with_complex:\n",
    "        print(\"complex\", complex)\n",
    "        receptors = complex.split(\"_\")\n",
    "        print(\"split\", receptors)\n",
    "        R_TF_with_complex = tf_table_receptors[tf_table_receptors[\"gene_A\"].isin(receptors)]\n",
    "        print(\"this here\", R_TF_with_complex)\n",
    "    \n",
    "        if len(R_TF_with_complex) == 0:\n",
    "          continue\n",
    "        \n",
    "        R_TF_with_complex.drop_duplicates()\n",
    "        #R_TF_with_complex[\"gene_A\"] = complex\n",
    "        print(\"R_TF_with_complex\", R_TF_with_complex)\n",
    "        complex_df = pd.concat([complex_df, R_TF_with_complex])\n",
    "\n",
    "      complex_df.drop_duplicates()\n",
    "\n",
    "    tf_receptor_interactions = pd.concat([tf_receptor_interactions, complex_df])\n",
    "    #print(\"tf_receptor_interactions\", tf_receptor_interactions)\n",
    "    \n",
    "    tf_table_ligands = tf_table[(tf_table[\"source\"] == celltype) & (tf_table[\"type_gene_B\"] == \"Ligand\")]\n",
    "\n",
    "    \n",
    "    tf_ligand_interactions = tf_table_ligands[tf_table_ligands[\"gene_B\"].isin(lr_ligands)]\n",
    "\n",
    "    intra_connections = pd.concat([intra_connections, tf_receptor_interactions, c_receptors, tf_ligand_interactions])\n",
    "  intra_connections[\"all_pair\"] = (intra_connections[\"source\"] + \"/\" \n",
    "                                    + intra_connections[\"gene_A\"] + \"/\"\n",
    "                                    + intra_connections[\"target\"] + \"/\"\n",
    "                                    + intra_connections[\"gene_B\"])\n",
    "  #print(\"intra_connections\", intra_connections)\n",
    "  intra_connections = intra_connections.drop_duplicates(subset=[\"all_pair\"])\n",
    "  intra_connections.drop(columns=[\"all_pair\"], inplace=True)\n",
    "\n",
    "  complete_interactions = pd.concat([intra_connections, lr_table])\n",
    "\n",
    "  if add_nodetype:\n",
    "    complete_interactions = add_node_type(complete_interactions)\n",
    "      \n",
    "  complete_interactions.to_csv((out_path + \"CrossTalkeR_input_\" + condition + \".csv\"), index=0)\n",
    "  return(complete_interactions)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['ACTR2' 'AMFR' 'AXL' 'BTN3A2' 'CANX' 'CAP1' 'CAV1' 'CCBE1' 'CD44' 'CD63'\n",
      " 'CD79A' 'CD81' 'CSF3R' 'CXCR4' 'DDR2' 'ENG' 'FGFR1' 'GPC1' 'ITGA10'\n",
      " 'ITGA11' 'ITGA5' 'ITGB1' 'LRP1' 'LRP10' 'LSR' 'MCFD2' 'MET' 'MYLK' 'NCL'\n",
      " 'NOTCH2' 'NOTCH3' 'NRP2' 'NT5E' 'PDGFRB' 'PECAM1' 'PTPRD' 'PVR' 'RGMB'\n",
      " 'RPSA' 'RXRA' 'SDC1' 'SDC2' 'SLC1A5' 'SMAD3' 'TFR2' 'TFRC' 'THY1'\n",
      " 'TNFRSF12A' 'TNFRSF14' 'TNFRSF1A']\n",
      "R_with_complex Series([], dtype: object)\n",
      "      Unnamed: 0      source      target    gene_A  gene_B type_gene_A  \\\n",
      "635          635  Fibroblast  Fibroblast       AXL   HNF1A    Receptor   \n",
      "643          643  Fibroblast  Fibroblast       MET   HNF1A    Receptor   \n",
      "681          681  Fibroblast  Fibroblast     ITGB1   TEAD1    Receptor   \n",
      "697          697  Fibroblast  Fibroblast    PDGFRB   TEAD1    Receptor   \n",
      "783          783  Fibroblast  Fibroblast     ITGB1   TEAD4    Receptor   \n",
      "799          799  Fibroblast  Fibroblast    PDGFRB   TEAD4    Receptor   \n",
      "903          903  Fibroblast  Fibroblast     ITGB1  TWIST1    Receptor   \n",
      "935          935  Fibroblast  Fibroblast       MET  TWIST1    Receptor   \n",
      "941          941  Fibroblast  Fibroblast    PDGFRB  TWIST1    Receptor   \n",
      "1042        1042  Fibroblast  Fibroblast       AXL   SMAD3    Receptor   \n",
      "1099        1099  Fibroblast  Fibroblast     FGFR1   SMAD3    Receptor   \n",
      "1135        1135  Fibroblast  Fibroblast     ITGA5   SMAD3    Receptor   \n",
      "1136        1136  Fibroblast  Fibroblast     ITGB1   SMAD3    Receptor   \n",
      "1188        1188  Fibroblast  Fibroblast       MET   SMAD3    Receptor   \n",
      "1202        1202  Fibroblast  Fibroblast    PDGFRB   SMAD3    Receptor   \n",
      "1371        1371  Fibroblast  Fibroblast     ITGB1   RUNX2    Receptor   \n",
      "1407        1407  Fibroblast  Fibroblast       MET   RUNX2    Receptor   \n",
      "1416        1416  Fibroblast  Fibroblast    PDGFRB   RUNX2    Receptor   \n",
      "1509        1509  Fibroblast  Fibroblast     ITGB1   EPAS1    Receptor   \n",
      "1622        1622  Fibroblast  Fibroblast    PDGFRB   MYOD1    Receptor   \n",
      "1700        1700  Fibroblast  Fibroblast     ITGB1     SRF    Receptor   \n",
      "1824        1824  Fibroblast  Fibroblast     ITGB1    TCF4    Receptor   \n",
      "1919        1919  Fibroblast  Fibroblast     ITGB1     SP3    Receptor   \n",
      "2019        2019  Fibroblast  Fibroblast     ITGB1     MAX    Receptor   \n",
      "2091        2091  Fibroblast  Fibroblast     ITGB1    ARNT    Receptor   \n",
      "2228        2228  Fibroblast  Fibroblast     ITGB1     MAZ    Receptor   \n",
      "2296        2296  Fibroblast  Fibroblast     ITGB1    CREM    Receptor   \n",
      "2307        2307  Fibroblast  Fibroblast      MYLK    CREM    Receptor   \n",
      "2407        2407  Fibroblast  Fibroblast     FGFR1   SMAD1    Receptor   \n",
      "2423        2423  Fibroblast  Fibroblast     ITGB1   SMAD1    Receptor   \n",
      "2461        2461  Fibroblast  Fibroblast    PDGFRB   SMAD1    Receptor   \n",
      "2513        2513  Fibroblast  Fibroblast  TNFRSF14   SMAD1    Receptor   \n",
      "2560        2560  Fibroblast  Fibroblast     ITGB1   SNAI1    Receptor   \n",
      "2576        2576  Fibroblast  Fibroblast       MET   SNAI1    Receptor   \n",
      "2713        2713  Fibroblast  Fibroblast     ITGB1   HIF1A    Receptor   \n",
      "2807        2807  Fibroblast  Fibroblast     ITGB1   ZC3H8    Receptor   \n",
      "2856        2856  Fibroblast  Fibroblast     ITGB1   HOXB7    Receptor   \n",
      "\n",
      "               type_gene_B    MeanLR  \n",
      "635   Transcription Factor  0.026491  \n",
      "643   Transcription Factor  0.026491  \n",
      "681   Transcription Factor  0.214835  \n",
      "697   Transcription Factor  0.214835  \n",
      "783   Transcription Factor  0.211239  \n",
      "799   Transcription Factor  0.211239  \n",
      "903   Transcription Factor  0.160044  \n",
      "935   Transcription Factor  0.160044  \n",
      "941   Transcription Factor  0.160044  \n",
      "1042  Transcription Factor  0.119463  \n",
      "1099  Transcription Factor  0.119463  \n",
      "1135  Transcription Factor  0.119463  \n",
      "1136  Transcription Factor  0.119463  \n",
      "1188  Transcription Factor  0.119463  \n",
      "1202  Transcription Factor  0.119463  \n",
      "1371  Transcription Factor  0.250424  \n",
      "1407  Transcription Factor  0.250424  \n",
      "1416  Transcription Factor  0.250424  \n",
      "1509  Transcription Factor  0.365121  \n",
      "1622  Transcription Factor  0.063088  \n",
      "1700  Transcription Factor  0.234372  \n",
      "1824  Transcription Factor  0.054986  \n",
      "1919  Transcription Factor  0.501266  \n",
      "2019  Transcription Factor  0.192148  \n",
      "2091  Transcription Factor  0.117347  \n",
      "2228  Transcription Factor  0.183122  \n",
      "2296  Transcription Factor  0.212894  \n",
      "2307  Transcription Factor  0.212894  \n",
      "2407  Transcription Factor  0.276883  \n",
      "2423  Transcription Factor  0.276883  \n",
      "2461  Transcription Factor  0.276883  \n",
      "2513  Transcription Factor  0.276883  \n",
      "2560  Transcription Factor  0.600234  \n",
      "2576  Transcription Factor  0.600234  \n",
      "2713  Transcription Factor  0.325279  \n",
      "2807  Transcription Factor  0.392546  \n",
      "2856  Transcription Factor  0.250993  \n",
      "['ACTR2' 'ADGRG1' 'AMFR' 'ANTXR1' 'APLP2' 'AXL' 'BTN3A2' 'C1QBP' 'CANX'\n",
      " 'CAP1' 'CAV1' 'CCBE1' 'CD36' 'CD4' 'CD40' 'CD44' 'CD46' 'CD47' 'CD63'\n",
      " 'CD68' 'CD74' 'CD81' 'CDH11' 'CHL1' 'CXCR4' 'DDR2' 'DIP2A' 'ENG' 'EPOR'\n",
      " 'FAS' 'FGFR1' 'FZD5' 'GPC1' 'IGF2R' 'INSR' 'ITGA1' 'ITGA10' 'ITGA11'\n",
      " 'ITGA5' 'ITGB1' 'ITGB2' 'ITGB5' 'KIT' 'LAMP1' 'LEPR' 'LIFR' 'LPP' 'LRP1'\n",
      " 'LRP10' 'LRP6' 'LSR' 'LY96' 'MCFD2' 'MRC2' 'MYLK' 'NCL' 'NCSTN' 'NOTCH2'\n",
      " 'NOTCH3' 'NRP1' 'NRP2' 'NT5E' 'NTRK2' 'PDGFRB' 'PILRB' 'PLAUR' 'PLSCR1'\n",
      " 'PLXNA3' 'PLXNB2' 'PLXND1' 'PTGER4' 'PTPRA' 'PTPRD' 'PTPRF' 'PTPRS'\n",
      " 'RAMP2' 'RGMB' 'RXRA' 'RYK' 'SDC1' 'SDC2' 'SDC4' 'SLC1A5' 'SLC40A1'\n",
      " 'SMAD3' 'TFRC' 'TGFBR1' 'TGFBR3' 'THY1' 'TNFRSF14' 'TNFRSF1A' 'TNFRSF25'\n",
      " 'TSPAN14' 'TSPAN17' 'VASN']\n",
      "R_with_complex Series([], dtype: object)\n",
      "Empty DataFrame\n",
      "Columns: [Unnamed: 0, source, target, gene_A, gene_B, type_gene_A, type_gene_B, MeanLR]\n",
      "Index: []\n",
      "['ACTR2' 'AXL' 'BTN3A2' 'BTN3A3' 'C1QBP' 'CAP1' 'CD2' 'CD247' 'CD3D'\n",
      " 'CD3G' 'CD44' 'CD46' 'CD47' 'CD63' 'CD68' 'CD74' 'CLEC2D' 'CXCR3' 'CXCR4'\n",
      " 'DIP2A' 'HAVCR2' 'IGF2R' 'ITGA4' 'ITGAM' 'ITGB1' 'ITGB2' 'KLRB1' 'KLRC1'\n",
      " 'KLRD1' 'LAG3' 'LY96' 'NCL' 'NCR3' 'PILRB' 'PTGER2' 'PTGER4' 'PTPRA'\n",
      " 'PTPRC' 'RPSA' 'S1PR1' 'SELL' 'SLC40A1' 'SORL1' 'TNFRSF14' 'TNFRSF1B'\n",
      " 'TNFRSF25' 'TRADD' 'TSPAN14']\n",
      "R_with_complex Series([], dtype: object)\n",
      "     Unnamed: 0         source         target gene_A  gene_B type_gene_A  \\\n",
      "19           19  Megakaryocyte  Megakaryocyte  ITGB1   CREB3    Receptor   \n",
      "72           72  Megakaryocyte  Megakaryocyte  CXCR4   STAT2    Receptor   \n",
      "91           91  Megakaryocyte  Megakaryocyte    AXL   FOXO3    Receptor   \n",
      "106         106  Megakaryocyte  Megakaryocyte  CD247   FOXO3    Receptor   \n",
      "174         174  Megakaryocyte  Megakaryocyte  ITGB1   FOXO3    Receptor   \n",
      "368         368  Megakaryocyte  Megakaryocyte  ITGB1  ZBTB16    Receptor   \n",
      "526         526  Megakaryocyte  Megakaryocyte  ITGB1   STAT4    Receptor   \n",
      "\n",
      "              type_gene_B    MeanLR  \n",
      "19   Transcription Factor  0.244712  \n",
      "72   Transcription Factor  0.433046  \n",
      "91   Transcription Factor  0.089760  \n",
      "106  Transcription Factor  0.089760  \n",
      "174  Transcription Factor  0.089760  \n",
      "368  Transcription Factor  0.542983  \n",
      "526  Transcription Factor  1.554844  \n",
      "['ACTR2' 'CANX' 'CD46' 'CD63' 'CLEC2D' 'CSF3R' 'CXCR4' 'DIP2A' 'ITGA4'\n",
      " 'ITGAM' 'ITGB2' 'NCL' 'PILRB' 'PLSCR1' 'PTGER2' 'PTPRC' 'S1PR4'\n",
      " 'TNFRSF14' 'TNFRSF1A']\n",
      "R_with_complex Series([], dtype: object)\n",
      "Empty DataFrame\n",
      "Columns: []\n",
      "Index: []\n",
      "['APLP2' 'CANX' 'CD9' 'CDH11' 'LRP6' 'NCL' 'NRP1' 'PTPRA' 'PTPRD' 'PTPRF'\n",
      " 'SMAP1' 'VLDLR' 'dia' 'ruby' 'test_test2']\n",
      "R_with_complex 14    test_test2\n",
      "dtype: object\n",
      "      Unnamed: 0  source  target    gene_A  gene_B type_gene_A  \\\n",
      "3042        3042  Neural  Neural     PTPRF   GATA1    Receptor   \n",
      "3116        3116  Neural  Neural     PTPRF    IRF2    Receptor   \n",
      "3268        3268  Neural  Neural     PTPRF    HHEX    Receptor   \n",
      "3338        3338  Neural  Neural     PTPRF   IKZF1    Receptor   \n",
      "3420        3420  Neural  Neural     PTPRF    ATF1    Receptor   \n",
      "3555        3555  Neural  Neural      LRP6   STAT1    Receptor   \n",
      "3628        3628  Neural  Neural     PTPRF   STAT1    Receptor   \n",
      "3687        3687  Neural  Neural      LRP6    GLI3    Receptor   \n",
      "3806        3806  Neural  Neural     PTPRF   HMGA1    Receptor   \n",
      "3888        3888  Neural  Neural      LRP6   MEF2D    Receptor   \n",
      "3932        3932  Neural  Neural     PTPRF   MEF2D    Receptor   \n",
      "3991        3991  Neural  Neural     PTPRF    PDX1    Receptor   \n",
      "4140        4140  Neural  Neural     PTPRF    SOX2    Receptor   \n",
      "4323        4323  Neural  Neural     PTPRF   FOXA2    Receptor   \n",
      "4632        4632  Neural  Neural     PTPRF   TERF1    Receptor   \n",
      "4732        4732  Neural  Neural     PTPRF   TEAD4    Receptor   \n",
      "4925        4925  Neural  Neural     PTPRF  POU5F1    Receptor   \n",
      "5259        5259  Neural  Neural     PTPRF    TAL1    Receptor   \n",
      "5435        5435  Neural  Neural     PTPRF   NR4A1    Receptor   \n",
      "5615        5615  Neural  Neural     PTPRF  TWIST1    Receptor   \n",
      "5708        5708  Neural  Neural     PTPRF   MEF2A    Receptor   \n",
      "5807        5807  Neural  Neural     PTPRF  TFAP2A    Receptor   \n",
      "5946        5946  Neural  Neural     PTPRF    E2F1    Receptor   \n",
      "6057        6057  Neural  Neural     PTPRF    TP63    Receptor   \n",
      "6210        6210  Neural  Neural     PTPRF    EGR1    Receptor   \n",
      "6289        6289  Neural  Neural      LRP6    SPIB    Receptor   \n",
      "6315        6315  Neural  Neural     PTPRF    SPIB    Receptor   \n",
      "6390        6390  Neural  Neural     PTPRF    HSF1    Receptor   \n",
      "6523        6523  Neural  Neural     PTPRF   NFKB2    Receptor   \n",
      "6695        6695  Neural  Neural     PTPRF   GATA2    Receptor   \n",
      "6795        6795  Neural  Neural     PTPRF   ASCL1    Receptor   \n",
      "6892        6892  Neural  Neural      LRP6   FOXO1    Receptor   \n",
      "6964        6964  Neural  Neural     PTPRF   FOXO1    Receptor   \n",
      "7102        7102  Neural  Neural     PTPRF    TP73    Receptor   \n",
      "7231        7231  Neural  Neural      LRP6     JUN    Receptor   \n",
      "7320        7320  Neural  Neural     PTPRF     JUN    Receptor   \n",
      "7528        7528  Neural  Neural     PTPRF    RBPJ    Receptor   \n",
      "7548        7548  Neural  Neural  ruby+dia     idk    Receptor   \n",
      "\n",
      "               type_gene_B    MeanLR  \n",
      "3042  Transcription Factor  0.624358  \n",
      "3116  Transcription Factor  0.232476  \n",
      "3268  Transcription Factor  0.023651  \n",
      "3338  Transcription Factor  0.328054  \n",
      "3420  Transcription Factor  0.540962  \n",
      "3555  Transcription Factor  0.019727  \n",
      "3628  Transcription Factor  0.019727  \n",
      "3687  Transcription Factor  0.137115  \n",
      "3806  Transcription Factor  0.999499  \n",
      "3888  Transcription Factor  0.171358  \n",
      "3932  Transcription Factor  0.171358  \n",
      "3991  Transcription Factor  0.518292  \n",
      "4140  Transcription Factor  0.743678  \n",
      "4323  Transcription Factor  0.308429  \n",
      "4632  Transcription Factor  0.551694  \n",
      "4732  Transcription Factor  0.136310  \n",
      "4925  Transcription Factor  0.289745  \n",
      "5259  Transcription Factor  0.756023  \n",
      "5435  Transcription Factor  0.168319  \n",
      "5615  Transcription Factor  0.000265  \n",
      "5708  Transcription Factor  0.100144  \n",
      "5807  Transcription Factor  0.168195  \n",
      "5946  Transcription Factor  0.685096  \n",
      "6057  Transcription Factor  0.167873  \n",
      "6210  Transcription Factor  0.442805  \n",
      "6289  Transcription Factor  0.251366  \n",
      "6315  Transcription Factor  0.251366  \n",
      "6390  Transcription Factor  0.766589  \n",
      "6523  Transcription Factor  0.450124  \n",
      "6695  Transcription Factor  0.579438  \n",
      "6795  Transcription Factor  0.542877  \n",
      "6892  Transcription Factor  0.193875  \n",
      "6964  Transcription Factor  0.193875  \n",
      "7102  Transcription Factor  0.233338  \n",
      "7231  Transcription Factor  0.026780  \n",
      "7320  Transcription Factor  0.026780  \n",
      "7528  Transcription Factor  0.061884  \n",
      "7548         Transcription  0.131864  \n",
      "complex test_test2\n",
      "split ['test', 'test2']\n",
      "this here       Unnamed: 0  source  target gene_A gene_B type_gene_A  \\\n",
      "7546        7546  Neural  Neural   test   TLN1    Receptor   \n",
      "\n",
      "               type_gene_B    MeanLR  \n",
      "7546  Transcription_Factor  0.131864  \n",
      "R_TF_with_complex       Unnamed: 0  source  target gene_A gene_B type_gene_A  \\\n",
      "7546        7546  Neural  Neural   test   TLN1    Receptor   \n",
      "\n",
      "               type_gene_B    MeanLR  \n",
      "7546  Transcription_Factor  0.131864  \n"
     ]
    }
   ],
   "source": [
    "#WINDOWS\n",
    "table_ctr = pd.read_csv(\"LR2TF_test_run\\\\CTR_LR_complex_edited.csv\")\n",
    "table_exp = pd.read_csv(\"LR2TF_test_run\\\\EXP_LR.csv\")\n",
    "\n",
    "tmp= pd.read_csv(\"py_ctr_input_wo_ctr_exp_tables.csv\", index_col= None)\n",
    "\n",
    "ctr_input = combine_LR_and_TF_complexes(tmp, table_ctr, \"script_test/\", \"control\")\n",
    "exp_input = combine_LR_and_TF(result.CTR_input_condition[\"PMF,MF2\"], table_exp, \"script_test/\", \"PMF_MF2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: '/home/larissa/Documents/LR2TF_HiWi/LR2TF_test_run/CTR_LR.csv'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[27], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m#LINUX\u001b[39;00m\n\u001b[1;32m----> 2\u001b[0m table_ctr \u001b[38;5;241m=\u001b[39m \u001b[43mpd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread_csv\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m/home/larissa/Documents/LR2TF_HiWi/LR2TF_test_run/CTR_LR.csv\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m      3\u001b[0m table_exp \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mread_csv(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m/home/larissa/Documents/LR2TF_HiWi/LR2TF_test_run/EXP_LR.csv\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m      5\u001b[0m tmp\u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mread_csv(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpy_ctr_input_wo_ctr_exp_tables.csv\u001b[39m\u001b[38;5;124m\"\u001b[39m, index_col\u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m)\n",
      "File \u001b[1;32md:\\studium\\LR2TF_HiWi\\.venv\\Lib\\site-packages\\pandas\\io\\parsers\\readers.py:1026\u001b[0m, in \u001b[0;36mread_csv\u001b[1;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, date_format, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options, dtype_backend)\u001b[0m\n\u001b[0;32m   1013\u001b[0m kwds_defaults \u001b[38;5;241m=\u001b[39m _refine_defaults_read(\n\u001b[0;32m   1014\u001b[0m     dialect,\n\u001b[0;32m   1015\u001b[0m     delimiter,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1022\u001b[0m     dtype_backend\u001b[38;5;241m=\u001b[39mdtype_backend,\n\u001b[0;32m   1023\u001b[0m )\n\u001b[0;32m   1024\u001b[0m kwds\u001b[38;5;241m.\u001b[39mupdate(kwds_defaults)\n\u001b[1;32m-> 1026\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_read\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilepath_or_buffer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32md:\\studium\\LR2TF_HiWi\\.venv\\Lib\\site-packages\\pandas\\io\\parsers\\readers.py:620\u001b[0m, in \u001b[0;36m_read\u001b[1;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[0;32m    617\u001b[0m _validate_names(kwds\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnames\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m))\n\u001b[0;32m    619\u001b[0m \u001b[38;5;66;03m# Create the parser.\u001b[39;00m\n\u001b[1;32m--> 620\u001b[0m parser \u001b[38;5;241m=\u001b[39m \u001b[43mTextFileReader\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilepath_or_buffer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    622\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m chunksize \u001b[38;5;129;01mor\u001b[39;00m iterator:\n\u001b[0;32m    623\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m parser\n",
      "File \u001b[1;32md:\\studium\\LR2TF_HiWi\\.venv\\Lib\\site-packages\\pandas\\io\\parsers\\readers.py:1620\u001b[0m, in \u001b[0;36mTextFileReader.__init__\u001b[1;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[0;32m   1617\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptions[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhas_index_names\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m kwds[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhas_index_names\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[0;32m   1619\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles: IOHandles \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m-> 1620\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_engine \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_make_engine\u001b[49m\u001b[43m(\u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mengine\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32md:\\studium\\LR2TF_HiWi\\.venv\\Lib\\site-packages\\pandas\\io\\parsers\\readers.py:1880\u001b[0m, in \u001b[0;36mTextFileReader._make_engine\u001b[1;34m(self, f, engine)\u001b[0m\n\u001b[0;32m   1878\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m mode:\n\u001b[0;32m   1879\u001b[0m         mode \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m-> 1880\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles \u001b[38;5;241m=\u001b[39m \u001b[43mget_handle\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1881\u001b[0m \u001b[43m    \u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1882\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1883\u001b[0m \u001b[43m    \u001b[49m\u001b[43mencoding\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mencoding\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1884\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcompression\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcompression\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1885\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmemory_map\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmemory_map\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1886\u001b[0m \u001b[43m    \u001b[49m\u001b[43mis_text\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mis_text\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1887\u001b[0m \u001b[43m    \u001b[49m\u001b[43merrors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mencoding_errors\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mstrict\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1888\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstorage_options\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mstorage_options\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1889\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1890\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m   1891\u001b[0m f \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles\u001b[38;5;241m.\u001b[39mhandle\n",
      "File \u001b[1;32md:\\studium\\LR2TF_HiWi\\.venv\\Lib\\site-packages\\pandas\\io\\common.py:873\u001b[0m, in \u001b[0;36mget_handle\u001b[1;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[0;32m    868\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(handle, \u001b[38;5;28mstr\u001b[39m):\n\u001b[0;32m    869\u001b[0m     \u001b[38;5;66;03m# Check whether the filename is to be opened in binary mode.\u001b[39;00m\n\u001b[0;32m    870\u001b[0m     \u001b[38;5;66;03m# Binary mode does not support 'encoding' and 'newline'.\u001b[39;00m\n\u001b[0;32m    871\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m ioargs\u001b[38;5;241m.\u001b[39mencoding \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m ioargs\u001b[38;5;241m.\u001b[39mmode:\n\u001b[0;32m    872\u001b[0m         \u001b[38;5;66;03m# Encoding\u001b[39;00m\n\u001b[1;32m--> 873\u001b[0m         handle \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mopen\u001b[39;49m\u001b[43m(\u001b[49m\n\u001b[0;32m    874\u001b[0m \u001b[43m            \u001b[49m\u001b[43mhandle\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    875\u001b[0m \u001b[43m            \u001b[49m\u001b[43mioargs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    876\u001b[0m \u001b[43m            \u001b[49m\u001b[43mencoding\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mioargs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mencoding\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    877\u001b[0m \u001b[43m            \u001b[49m\u001b[43merrors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43merrors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    878\u001b[0m \u001b[43m            \u001b[49m\u001b[43mnewline\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m    879\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    880\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    881\u001b[0m         \u001b[38;5;66;03m# Binary mode\u001b[39;00m\n\u001b[0;32m    882\u001b[0m         handle \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mopen\u001b[39m(handle, ioargs\u001b[38;5;241m.\u001b[39mmode)\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '/home/larissa/Documents/LR2TF_HiWi/LR2TF_test_run/CTR_LR.csv'"
     ]
    }
   ],
   "source": [
    "#LINUX\n",
    "table_ctr = pd.read_csv(\"/home/larissa/Documents/LR2TF_HiWi/LR2TF_test_run/CTR_LR.csv\")\n",
    "table_exp = pd.read_csv(\"/home/larissa/Documents/LR2TF_HiWi/LR2TF_test_run/EXP_LR.csv\")\n",
    "\n",
    "\n",
    "ctr_input = combine_LR_and_TF_complexes(result.CTR_input_condition[\"control\"], table_ctr, \"script_test/\", \"control\")\n",
    "exp_input = combine_LR_and_TF_complexes(result.CTR_input_condition[\"PMF,MF2\"], table_exp, \"script_test/\", \"PMF_MF2\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
