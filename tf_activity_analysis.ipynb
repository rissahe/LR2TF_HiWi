{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1203,
   "metadata": {},
   "outputs": [],
   "source": [
    "import anndata as ad\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import scanpy as sc\n",
    "import decoupler as dc\n",
    "import os\n",
    "import statistics\n",
    "import seaborn as sns\n",
    "from scipy.stats import wilcoxon\n",
    "from scipy.stats import ranksums\n",
    "from scipy.spatial.distance import pdist\n",
    "from scipy.cluster.hierarchy import linkage\n",
    "from scipy.stats import false_discovery_control\n",
    "from itertools import combinations\n",
    "import matplotlib.pyplot as plt\n",
    "#import pickle\n",
    "from scipy.stats import binomtest\n",
    "from statsmodels.stats.multitest import multipletests\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1204,
   "metadata": {},
   "outputs": [],
   "source": [
    "#%pip install --upgrade decoupler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1205,
   "metadata": {},
   "outputs": [],
   "source": [
    "def validate_input_arguments (arguments_list):\n",
    "    if arguments_list[\"out_path\"] is None:\n",
    "        print(\"Please provide an output path\")\n",
    "    elif arguments_list[\"out_path\"][-1] != \"/\":\n",
    "        arguments_list[\"out_path\"] = arguments_list[\"out_path\"] + \"/\"\n",
    "\n",
    "    if arguments_list[\"celltype\"] is None:\n",
    "        print(\"Please provide the name of the metadata field containing cell type annotations\")\n",
    "\n",
    "    if arguments_list[\"condition\"] is None:\n",
    "        print(\"Please provide the name of the metadata field containing condition annotations\")\n",
    "\n",
    "    if arguments_list[\"organism\"] is None:\n",
    "        arguments_list[\"organism\"] = \"human\"\n",
    "\n",
    "    #if arguments_list[\"comparison_list\"] is None:\n",
    "    #    arguments_list[\"comparison_list\"] = np.nan\n",
    "\n",
    "    if arguments_list[\"meanchange\"] is None:\n",
    "        arguments_list[\"meanchange\"] = 0.0\n",
    "\n",
    "    if arguments_list [\"pval\"] is None:\n",
    "        arguments_list[\"pval\"] = 0.05\n",
    "\n",
    "    if arguments_list [\"num_cell_filter\"] is None:\n",
    "        arguments_list[\"num_cell_filter\"] = 0\n",
    "\n",
    "    if arguments_list[\"reg\"] is None:\n",
    "        arguments_list[\"reg\"] = load_dorothea_regulon(arguments_list[\"organism\"])\n",
    "\n",
    "    elif isinstance(arguments_list[\"reg\"], str):\n",
    "        arguments_list[\"reg\"] = pd.read_csv(arguments_list[\"reg\"], index_col=0)\n",
    "        arguments_list[\"reg\"] = pd.DataFrame.rename(arguments_list[\"reg\"], columns={\"source\" : \"tf\"})\n",
    "\n",
    "    #is the naming of tf fine like this?\n",
    "    if not \"tf\" in arguments_list[\"reg\"] and \"target\" in arguments_list[\"reg\"] and \"weight\" in arguments_list[\"reg\"]:\n",
    "        raise NameException(\"Not all necessary columns found in regulon table! Please make sure that the regulon has the columns 'source', 'target' and 'weight'!\")\n",
    "    \n",
    "    if arguments_list[\"plot\"] is None:\n",
    "        arguments_list[\"plot\"] = True\n",
    "    elif not isinstance(arguments_list[\"plot\"], (bool)):\n",
    "        raise ValueError(\"lot argument must be a boolean value.\")\n",
    "        \n",
    "   \n",
    "    return(arguments_list)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1206,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TFObj:\n",
    "    def __init__(self,\n",
    "    tf_activities_condition : list,\n",
    "    tf_activities_cluster : list,\n",
    "    average_gene_expression : list,\n",
    "    regulon : pd.DataFrame,\n",
    "    CTR_input_condition : list,\n",
    "    CTR_input_cluster : list,\n",
    "    intracellular_network_condition : list,\n",
    "    intracellular_network_cluster : list):\n",
    "\n",
    "        self.tf_activities_condition = tf_activities_condition\n",
    "        self.tf_activities_cluster = tf_activities_cluster\n",
    "        self.average_gene_expression = average_gene_expression\n",
    "        self.regulon = regulon\n",
    "        self.CTR_input_condition = CTR_input_condition\n",
    "        self.CTR_input_cluster = CTR_input_cluster\n",
    "        self.intracellular_network_condition = intracellular_network_condition\n",
    "        self.intracellular_network_cluster = intracellular_network_cluster\n",
    "\n",
    "def make_TFOBj(tf_activities_condition : list,\n",
    "    tf_activities_cluster : list,\n",
    "    average_gene_expression : list,\n",
    "    regulon : pd.DataFrame,\n",
    "    CTR_input_condition : list,\n",
    "    CTR_input_cluster : list,\n",
    "    intracellular_network_condition : list,\n",
    "    intracellular_network_cluster : list):\n",
    "\n",
    "        tf = TFObj(tf_activities_condition,\n",
    "            tf_activities_cluster,\n",
    "            average_gene_expression,\n",
    "            regulon,\n",
    "            CTR_input_condition,\n",
    "            CTR_input_cluster,\n",
    "            intracellular_network_condition,\n",
    "            intracellular_network_cluster)\n",
    "\n",
    "        return tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1207,
   "metadata": {},
   "outputs": [],
   "source": [
    "def AverageExpression(sub_object, celltype = None, name_iterable = None, outpath = None):\n",
    "    gene_ids = sub_object.var.index.values\n",
    "    #cluster line even necessary if not returned?\n",
    "    #clusters = anndataobject.obs[celltype].cat.categories\n",
    "    obs = sub_object[:,gene_ids].X.toarray()\n",
    "    obs = np.expm1(obs)\n",
    "    avg_df = pd.DataFrame(obs,columns=gene_ids,index= sub_object.obs[celltype])\n",
    "    avg_df = avg_df.groupby(level=0, observed=False).mean()\n",
    "    #avg_df.T.to_csv(outpath + name_iterable + \"_average_gene_expression_by_cluster_exp.csv\")\n",
    "\n",
    "    return avg_df.T\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1208,
   "metadata": {},
   "outputs": [],
   "source": [
    "def eval_pval(p_val):\n",
    "    p_val = float(p_val)\n",
    "    if p_val < 0.001: \n",
    "      txt = \"***\"\n",
    "    elif p_val < 0.01: \n",
    "      txt = \"**\"\n",
    "    elif p_val < 0.05: \n",
    "      txt = \"*\"\n",
    "    else:\n",
    "      txt = \"ns\"\n",
    "    return(txt)\n",
    "\n",
    "\n",
    "def eval_meanchange_tag(meanchange):\n",
    "    if meanchange >= 1.0: \n",
    "      txt = \"***\"\n",
    "    elif meanchange > 0.5: \n",
    "      txt = \"**\"\n",
    "    elif meanchange > 0.0: \n",
    "      txt = \"*\"\n",
    "    else:\n",
    "      txt = \"ns\"\n",
    "    return(txt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1209,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_unfiltered_tf_scores(tf_scores_df, condition, celltype, out_path):   \n",
    "    summarized_tf_scores_df = tf_scores_df.groupby(celltype, observed = True).mean().T\n",
    "    #tf_scores_df.groupby(celltype, observed = True).apply(display)\n",
    "    #agg([\"mean\", \"var\"])\n",
    "    summarized_tf_scores_df.to_csv(out_path + \"/unfiltered_tf_scores_\" + condition + \".csv\")\n",
    "    return summarized_tf_scores_df\n",
    "\n",
    "#np.var() returns a value that is different from R's var(), whereas statistics.variance() is the same as R's var()\n",
    "def save_variable_tf_score(filtered_summarized_tf_scores_df, condition, out_path, plot):\n",
    "    filtered_summarized_tf_scores_df[\"var\"] = filtered_summarized_tf_scores_df.apply(statistics.variance, axis=1).unique()\n",
    "    filtered_summarized_tf_scores_df.to_csv(out_path + \"/variable_tf_scores_\" + condition + \".csv\")\n",
    "\n",
    "    if plot:\n",
    "        top_variable_tfs = filtered_summarized_tf_scores_df.sort_values(\"var\", ascending=False).head(n=20).drop(columns=\"var\")\n",
    "        cluster_map = sns.clustermap(top_variable_tfs, cmap=\"vlag\", center=0, vmin=top_variable_tfs.min(axis=None), cbar_kws={\"label\": \"t-score\"},\n",
    "                                    cbar_pos=(1, 0.5, 0.02, 0.1), dendrogram_ratio=(0.2, 0.05))\n",
    "        cluster_map.ax_heatmap.set_xlabel(\"Cell Type\")\n",
    "        cluster_map.ax_heatmap.set_ylabel(\"Transcription Factor\")\n",
    "        plt.setp(cluster_map.ax_heatmap.get_xticklabels(), rotation=90) \n",
    "        plt.savefig(out_path + \"/tf_activity_top20_variable_\" + condition + \".pdf\", bbox_inches='tight')\n",
    "        plt.close()\n",
    "\n",
    "    filtered_summarized_tf_scores_df_var = filtered_summarized_tf_scores_df\n",
    "    return filtered_summarized_tf_scores_df_var\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1210,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_tf_activity(filtered_summarized_tf_scores_df, tag_mapping, condition, out_path):\n",
    "    filtered_summarized_tf_scores_df = filtered_summarized_tf_scores_df.drop(columns=\"var\")\n",
    "    calc_size = ((len(filtered_summarized_tf_scores_df.columns.unique()) * 1.5), (len(filtered_summarized_tf_scores_df) * 0.02))\n",
    "    cluster_map = sns.clustermap(filtered_summarized_tf_scores_df, cbar_kws={\"label\": \"t-score\"}, figsize=calc_size, cmap=\"vlag\", center=0, \n",
    "                                yticklabels=False, cbar_pos=(1, 0.5, 0.02, 0.1), dendrogram_ratio=(0.2, 0.05))\n",
    "    cluster_map.ax_heatmap.set_xlabel(\"Cell Type\")\n",
    "    cluster_map.ax_heatmap.set_ylabel(\"Transcription Factor\")\n",
    "    plt.setp(cluster_map.ax_heatmap.get_xticklabels(), rotation=90) \n",
    "    \n",
    "    plt.savefig(out_path + \"/tf_activity_compressed_\" + condition + \".pdf\", bbox_inches='tight')\n",
    "    plt.close()\n",
    "\n",
    "\n",
    "    #tag_mapping = tag_mapping.where(filtered_summarized_tf_scores_df > 0, np.nan) \n",
    "    #tag_mapping.fillna(\"ns\", inplace=True)\n",
    "    \n",
    "    calc_size = ((len(filtered_summarized_tf_scores_df.columns.unique()) * 1.5), (len(filtered_summarized_tf_scores_df) * 0.2))\n",
    "    cluster_map = sns.clustermap(filtered_summarized_tf_scores_df, cbar_kws={\"label\": \"t-score\"}, figsize=calc_size, cmap=\"vlag\", center=0, annot= tag_mapping, fmt=\"\", \n",
    "                                yticklabels=True, cbar_pos=(1, 0.5, 0.03, 0.05), dendrogram_ratio=(0.2, 0.05))\n",
    "    cluster_map.ax_heatmap.set_xlabel(\"Cell Type\")\n",
    "    cluster_map.ax_heatmap.set_ylabel(\"Transcription Factor\")\n",
    "    plt.setp(cluster_map.ax_heatmap.get_xticklabels(), rotation=90) \n",
    "\n",
    "    plt.savefig(out_path + \"/tf_activity_\" + condition + \".pdf\", bbox_inches='tight')\n",
    "    plt.close()\n",
    "\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1211,
   "metadata": {},
   "outputs": [],
   "source": [
    "def h_clust(data):\n",
    "            dist_matrix = pdist(data.T)\n",
    "            linkage_matrix = linkage(dist_matrix, method = \"average\")   \n",
    "            return linkage_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1212,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_condition_tf_activities(tf_activity_tables, out_path):\n",
    "       \n",
    "   for result_name, df in tf_activity_tables.items():\n",
    "        name_df = pd.DataFrame(df)\n",
    "        significant_res = name_df[name_df[\"tag\"] == \"***\"]\n",
    "        significant_genes = np.unique(significant_res[\"tf\"])\n",
    "        name_df = name_df[name_df['tf'].isin(significant_genes)]\n",
    "        \n",
    "\n",
    "        tag_mapping = name_df[[\"tf\", \"tag\", \"CellType\"]]\n",
    "        tag_mapping = tag_mapping.pivot(index=\"tf\", columns=\"CellType\", values=\"tag\")\n",
    "        #print(\"tag_mapping\", tag_mapping)\n",
    "        tag_mapping.fillna(\"ns\", inplace=True)\n",
    "    \n",
    "        name_df_r = name_df[[\"r\", \"tf\", \"CellType\"]]\n",
    "        name_df_cluster = name_df_r.pivot_table(index = \"tf\", columns = \"CellType\", values = \"r\", aggfunc = \"mean\")\n",
    "        name_df_cluster.fillna(0, inplace=True) \n",
    "        #print(\"name df cluster\", name_df_cluster)\n",
    "        h_clust_matrix = h_clust(name_df_cluster)\n",
    "      \n",
    "        calc_size = ((len(name_df[\"CellType\"].unique()) * 1.5), (len(name_df_cluster) * 0.2))\n",
    "      \n",
    "        cluster_map = sns.clustermap(name_df_cluster, cbar_kws={\"label\": \"r\"}, figsize=calc_size, cmap=\"vlag\", center=0, annot= tag_mapping,\n",
    "                      col_linkage= h_clust_matrix, fmt=\"\", yticklabels=True, cbar_pos=(1, 0.5, 0.03, 0.05), dendrogram_ratio=(0.2, 0.05))\n",
    "        plt.setp(cluster_map.ax_heatmap.get_xticklabels(), rotation=90)  \n",
    "\n",
    "        plt.savefig(out_path + \"/\" + result_name + \"_cluster_condition_activity_difference.pdf\", bbox_inches='tight')\n",
    "        plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1213,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_condition_tf_activities_compressed(tf_activity_tables, out_path):\n",
    " \n",
    "  \n",
    "    for result_name, df in tf_activity_tables.items():\n",
    "        name_df = pd.DataFrame(df)\n",
    "        \n",
    "        significant_res = name_df[name_df[\"tag\"] == \"***\"]\n",
    "        significant_genes = np.unique(significant_res[\"tf\"])\n",
    "        name_df = name_df[name_df['tf'].isin(significant_genes)]\n",
    "        \n",
    "        name_df_r = name_df[[\"r\", \"tf\", \"CellType\"]]\n",
    "        name_df_cluster = name_df_r.pivot_table(index = \"tf\", columns = \"CellType\", values = \"r\", aggfunc = \"mean\")\n",
    "        name_df_cluster.fillna(0, inplace=True) \n",
    "\n",
    "        h_clust_matrix = h_clust(name_df_cluster)\n",
    "        name_df_cluster.reset_index()\n",
    "\n",
    "        calc_size = ((len(name_df[\"CellType\"].unique()) * 1.5\n",
    "        ), (len(name_df_cluster) * 0.02))\n",
    "        cluster_map = sns.clustermap(name_df_cluster, cbar_kws={\"label\": \"r\"}, figsize=calc_size, cmap=\"vlag\", center=0, annot= None,\n",
    "                       yticklabels=False, col_linkage= h_clust_matrix, fmt=\"\", cbar_pos=(1, 0.5, 0.02, 0.1), dendrogram_ratio=(0.2, 0.05))\n",
    "        plt.setp(cluster_map.ax_heatmap.get_xticklabels(), rotation=90) \n",
    "        #cluster_map.figure.suptitle(result_name)\n",
    "        \n",
    "        \n",
    "        plt.savefig(out_path + \"/\" + result_name +  \"_cluster_condition_activity_difference_compressed.pdf\", bbox_inches='tight')\n",
    "        plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1214,
   "metadata": {},
   "outputs": [],
   "source": [
    "def map_z_value(tf_scores_df, anndataobject_markers):\n",
    "    genes = []\n",
    "    clusters = []\n",
    "    t_values = []  \n",
    "    print(tf_scores_df)\n",
    "    anndataobject_markers = anndataobject_markers.set_index(\"gene\")\n",
    "    \n",
    "    for i in range(len(anndataobject_markers.index)):\n",
    "        a = anndataobject_markers.index[i]\n",
    "        for j in range(len(tf_scores_df.index)):\n",
    "            b = tf_scores_df.index[j]\n",
    "            if a == b:\n",
    "                c = anndataobject_markers.columns.get_loc(\"cluster\")\n",
    "                cluster = anndataobject_markers.iloc[i, c]\n",
    "                gene_rows = tf_scores_df.iloc[j]\n",
    "                if isinstance(gene_rows, pd.Series):\n",
    "                    gene_rows = gene_rows.to_frame().T\n",
    "\n",
    "                for _, gene_row in gene_rows.iterrows():\n",
    "                     score = gene_row[cluster]\n",
    "                     genes.append(a)\n",
    "                     clusters.append(cluster)\n",
    "                     t_values.append(score)\n",
    "\n",
    "    t_value_df = pd.DataFrame({\n",
    "        'gene': genes,\n",
    "        'cluster': clusters,\n",
    "        't_value': t_values\n",
    "    })\n",
    "\n",
    "    return t_value_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1215,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_entry(source, target, gene_A, gene_B, type_gene_A, type_gene_B, MeanLR):\n",
    "  df = {\"source\" : source,\n",
    "      \"target\" : target,\n",
    "      \"gene_A\" : gene_A,\n",
    "      \"gene_B\" : gene_B,\n",
    "      \"type_gene_A\" : type_gene_A,\n",
    "      \"type_gene_B\" : type_gene_B,\n",
    "      \"MeanLR\" : MeanLR}\n",
    "\n",
    "  return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_CrossTalkeR_input(tf_activities, gene_expression, out_path, regulon = None, organism = \"human\"):\n",
    "\n",
    "  if organism == \"human\":\n",
    "    ligands = pd.read_csv(\"ligands_human.csv\")\n",
    "    R2TF = pd.read_csv(\"rtf_db_human.csv\")\n",
    "  elif organism == \"mouse\": \n",
    "    ligands = pd.read_csv(\"ligands_mouse.csv\")\n",
    "    R2TF = pd.read_csv(\"rtf_db_mouse.csv\")\n",
    "  else:\n",
    "    NameError(\"Invalid organism to generate CrossTalkeR input!\")\n",
    "\n",
    "  #tf_activities = tf_activities[tf_activities[\"cluster\"] == \"Fibroblast\"]\n",
    "  #print(tf_activities)\n",
    "  ligands = ligands.drop_duplicates()\n",
    "  #print(ligands)\n",
    "  R2TF = R2TF.set_index(\"tf\")\n",
    "\n",
    "  sorted_regulon = regulon[[\"tf\", \"target\"]]\n",
    "  sorted_regulon = sorted_regulon.set_index(\"tf\")\n",
    "\n",
    "  #print(\"ligands\", ligands)\n",
    "  tf_activities = tf_activities[tf_activities[\"t_value\"] > 0]\n",
    "  output_list = []\n",
    "  df_list_l = {}\n",
    "  df_list_r = {}\n",
    "  #print(\"gene epr index\", gene_expression.index)\n",
    "  #print(\"tf activities\", tf_activities)\n",
    "  tf_activities.reset_index(drop = True)\n",
    "\n",
    "  for row in range(len((tf_activities))):\n",
    "    \n",
    "    targets = []\n",
    "    tf_ligands = []\n",
    "    #if (tf_activities[\"t_value\"].iloc[row] > 0):\n",
    "    tf = str(tf_activities[\"gene\"].iloc[row])\n",
    "    #print(\"tf\", tf)\n",
    "    if tf in sorted_regulon.index:\n",
    "      targets = sorted_regulon.loc[tf, \"target\"]\n",
    "      if isinstance(targets, str):\n",
    "        targets = [targets]\n",
    "      #print(\"targets\", targets)\n",
    "   \n",
    "    if tf in R2TF.index:\n",
    "        receptors = R2TF.loc[tf, \"receptor\"]\n",
    "        if isinstance(receptors, str):\n",
    "          receptors = [receptors]\n",
    "          \n",
    "    else:\n",
    "        receptors = []\n",
    "\n",
    "    #print(\"receptors\", receptors)\n",
    "\n",
    "    if len(targets) > 0:\n",
    "      tf_ligands = np.intersect1d(targets, ligands)\n",
    "    \n",
    "    #print(\"tf ligands\", tf_ligands)\n",
    "\n",
    "    if organism == \"human\":\n",
    "      if len(tf_ligands) > 0:\n",
    "        existing_entries = set()\n",
    "        for ligand in tf_ligands:\n",
    "            #print(\"ligand\", ligand)\n",
    "            expressed = False\n",
    "            if ligand in gene_expression.index:\n",
    "              ex_value = gene_expression.loc[ligand, tf_activities.iloc[row, tf_activities.columns.get_loc(\"cluster\")]]\n",
    "              #print(\"ex value\", ex_value)\n",
    "              if (ex_value != 0):\n",
    "                expressed = True\n",
    "\n",
    "            if (expressed == True):\n",
    "              df_list_l = add_entry(source = tf_activities.iloc[row, tf_activities.columns.get_loc(\"cluster\")],\n",
    "                                                      target = tf_activities.iloc[row, tf_activities.columns.get_loc(\"cluster\")],\n",
    "                                                      gene_A =tf_activities.iloc[row, tf_activities.columns.get_loc(\"gene\")],\n",
    "                                                      gene_B = ligand,\n",
    "                                                      type_gene_A = \"Transcription_Factor\",\n",
    "                                                      type_gene_B= \"Ligand\",\n",
    "                                                      MeanLR= tf_activities.iloc[row, tf_activities.columns.get_loc(\"t_value\")]\n",
    "                                                      )\n",
    "              \n",
    "              #print(\"df list l\", df_list_l)  \n",
    "              if (ligand, tf) not in existing_entries:\n",
    "                existing_entries.add((ligand, tf))\n",
    "                output_list.append(df_list_l)\n",
    "              #output_list.append(df_list_l)\n",
    "              \n",
    "\n",
    "      if (len(receptors) > 0):\n",
    "        for receptor in receptors:\n",
    "          #print(\"receptor\", receptor)\n",
    "          df_list_r = add_entry(source =  tf_activities.iloc[row, tf_activities.columns.get_loc(\"cluster\")],\n",
    "                                                target = tf_activities.iloc[row, tf_activities.columns.get_loc(\"cluster\")],\n",
    "                                                gene_A= receptor,\n",
    "                                                gene_B= tf_activities.iloc[row, tf_activities.columns.get_loc(\"gene\")],\n",
    "                                                type_gene_A= \"Receptor\",\n",
    "                                                type_gene_B= \"Transcription Factor\",\n",
    "                                                MeanLR= tf_activities.iloc[row, tf_activities.columns.get_loc(\"t_value\")]\n",
    "                                                )\n",
    "          #print(\"df list r\", df_list_r)\n",
    "          output_list.append(df_list_r)\n",
    "\n",
    "      \n",
    "          \n",
    "    else: \n",
    "      if len(tf_ligands) > 0:\n",
    "        for ligand in tf_ligands:\n",
    "            expressed = False\n",
    "            translations = ligand\n",
    "            if len(translations) > 0:\n",
    "              for l in translations:\n",
    "                #print(gene_expression.index)\n",
    "                if l in gene_expression.index:\n",
    "                  ex_value = gene_expression.loc[l, tf_activities.iloc[row, 2]]\n",
    "                  if (ex_value != 0):\n",
    "                    expressed = True\n",
    "          \n",
    "                df_list_l = {}\n",
    "            \n",
    "                if (expressed == True):\n",
    "                  df_list_l = add_entry(source = tf_activities.iloc[row, tf_activities.columns.get_loc(\"cluster\")],\n",
    "                                                      target = tf_activities.iloc[row, tf_activities.columns.get_loc(\"cluster\")],\n",
    "                                                      gene_A =tf_activities.iloc[row, tf_activities.columns.get_loc(\"gene\")],\n",
    "                                                      gene_B = ligand,\n",
    "                                                      type_gene_A = \"Transcription_Factor\",\n",
    "                                                      type_gene_B= \"Ligand\",\n",
    "                                                      MeanLR= tf_activities.iloc[row, tf_activities.columns.get_loc(\"t_value\")]\n",
    "                                                      )\n",
    "                \n",
    "                  output_list.append(df_list_l)\n",
    "      \n",
    "      if (len(receptors) > 0):\n",
    "        for receptor in receptors:\n",
    "          df_list_r = {}\n",
    "          df_list_r = add_entry(source =  tf_activities.iloc[row, tf_activities.columns.get_loc(\"cluster\")],\n",
    "                                                target = tf_activities.iloc[row, tf_activities.columns.get_loc(\"cluster\")],\n",
    "                                                gene_A= receptor,\n",
    "                                                gene_B= tf_activities.iloc[row, tf_activities.columns.get_loc(\"gene\")],\n",
    "                                                type_gene_A= \"Receptor\",\n",
    "                                                type_gene_B= \"Transcription Factor\",\n",
    "                                                MeanLR= tf_activities.iloc[row, tf_activities.columns.get_loc(\"t_value\")]\n",
    "                                                )\n",
    "                                                \n",
    "          output_list.append(df_list_r)\n",
    "        #tf_l.to_csv(single_result_path + \"/\" + renamed_condition + \"_ctr_test_l.csv\", index=0)\n",
    "        #r_tf.to_csv(single_result_path + \"/\" + renamed_condition + \"_ctr_test_r.csv\", index=0)\n",
    "   \n",
    "\n",
    "  output_df = pd.DataFrame(output_list)\n",
    "  output_df[\"gene_A\"] = output_df[\"gene_A\"].apply(lambda x: re.sub(\"_\", \"+\", x))\n",
    "  output_df[\"gene_B\"] = output_df[\"gene_B\"].apply(lambda x: re.sub(\"_\", \"+\", x))\n",
    "  output_df.drop_duplicates(inplace=True)\n",
    "  output_df.to_csv(\"tf_l_r_R_data_cond_contr.csv\", index=0)\n",
    "\n",
    "\n",
    "  return output_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1217,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_intracellular_network(tf_activities, gene_expression, outpath, regulon, organism=\"human\"):\n",
    "\n",
    "    if len(tf_activities.shape) > 0:\n",
    "        if organism == \"human\":\n",
    "            R2TF = pd.read_csv(\"rtf_db_human.csv\").set_index(\"tf\")\n",
    "        else:\n",
    "            R2TF = pd.read_csv(\"rtf_db_mouse.csv\").set_index(\"tf\")\n",
    "\n",
    "    sorted_regulon = regulon[[\"tf\", \"target\"]].set_index(\"tf\")\n",
    "\n",
    "    #preextract values\n",
    "    tf_genes = tf_activities[\"gene\"].values\n",
    "    tf_celltypes = tf_activities.iloc[:, 2].values\n",
    "    tf_scores = tf_activities.iloc[:, 3].values\n",
    "\n",
    "    TFTG_list = []\n",
    "    RTF_list = []\n",
    "\n",
    "    tf_activities.reset_index(drop = True)\n",
    "    for row in range(len(tf_activities)):\n",
    "        tf = str(tf_genes[row])\n",
    "        celltype = tf_celltypes[row]\n",
    "        tf_score = tf_scores[row]\n",
    "\n",
    "        targets = sorted_regulon.loc[tf, \"target\"] if tf in sorted_regulon.index else []\n",
    "        if tf in R2TF.index:\n",
    "           receptors = R2TF.loc[tf, \"receptor\"]\n",
    "           receptors = [receptors] if isinstance(receptors, str) else receptors\n",
    "        else:\n",
    "           receptors = []\n",
    "\n",
    "        if len(targets) > 0 and len(receptors) > 0:\n",
    "            for target in targets:\n",
    "                if target in gene_expression.index:\n",
    "                    ex_value = gene_expression.at[target, celltype]\n",
    "                    if ex_value != 0:\n",
    "                        TFTG_list.append({\n",
    "                            \"celltype\": celltype,\n",
    "                            \"TF\": tf,\n",
    "                            \"Target_Gene\": target,\n",
    "                            \"TF_Score\": tf_score\n",
    "                        })\n",
    "\n",
    "            for receptor in receptors:\n",
    "                RTF_list.append({\n",
    "                    \"TF\": tf,\n",
    "                    \"Receptor\": receptor\n",
    "                })\n",
    "\n",
    "    TFTG_df = pd.DataFrame(TFTG_list)\n",
    "    RTF_df = pd.DataFrame(RTF_list)\n",
    "\n",
    "    recept_regulon = pd.merge(RTF_df, TFTG_df, on=\"TF\")\n",
    "\n",
    "    return recept_regulon"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1218,
   "metadata": {},
   "outputs": [],
   "source": [
    "#decoupler condition comparison\n",
    "def condition_comparison_significant(tf_activities, out_path, celltype, condition, comparison_list, num_cell_filter = 0):\n",
    "\n",
    "    vs_df_dic = {}\n",
    "\n",
    "    if isinstance(comparison_list[0], str):  \n",
    "        comparison_list = [comparison_list]\n",
    "    \n",
    "    for vs1, vs2 in comparison_list:\n",
    "\n",
    "        print(f\"vs1: {vs1}, vs2: {vs2}\") \n",
    "\n",
    "        all_tf_list = tf_activities.var_names\n",
    "\n",
    "        res = pd.DataFrame()\n",
    "        for i in tf_activities.obs[celltype].unique(): \n",
    "            comparison_sub = tf_activities[(tf_activities.obs[celltype] == i) & (tf_activities.obs[condition].isin([vs1, vs2]))]\n",
    "            if len(pd.unique(comparison_sub.obs[condition])) == 2:\n",
    "                condition_table = comparison_sub.obs[[condition]].copy()\n",
    "                condition_table.columns = [\"condition\"]\n",
    "                metadata_counts = condition_table.groupby(\"condition\", observed = False).size()\n",
    "                \n",
    "                if (metadata_counts.iloc[0] + metadata_counts.iloc[1]) > num_cell_filter:\n",
    "                    g = comparison_sub.obs[condition].astype(\"category\")\n",
    "                    g = g.cat.set_categories([vs1, vs2])\n",
    "                    \n",
    "\n",
    "                    #binomtest scipy stats\n",
    "                    \n",
    "                    \n",
    "\n",
    "                    ##############################################\n",
    "                    #decoupler\n",
    "      \n",
    "                    res_tmp = dc.rank_sources_groups(comparison_sub, groupby= condition, reference=\"rest\", method=\"wilcoxon\")\n",
    "                    res_tmp.rename(columns={\"group\": \"condition\", \"statistic\" : \"scores\"}, inplace=True)\n",
    "            \n",
    "               \n",
    "\n",
    "                    group1 = comparison_sub.X[g == vs1]\n",
    "                    group2 = comparison_sub.X[g == vs2]\n",
    "                        \n",
    "                    \n",
    "                    res_tmp[\"r\"] = res_tmp[\"scores\"] / np.sqrt(len(group1) + len(group2))\n",
    "                    res_tmp[\"CellType\"] = i\n",
    "                    _, res_tmp[\"FDR\"], _, _ = multipletests(res_tmp[\"pvals\"], alpha=0.05, method='fdr_bh')\n",
    "                    \n",
    "                    \n",
    "                    res_tmp[\"meanchange\"] = res_tmp[\"meanchange\"].where(res_tmp[\"meanchange\"] > 0, np.nan) \n",
    "                    \n",
    "\n",
    "                    res = pd.concat([res, res_tmp], ignore_index=True)\n",
    "\n",
    "        res_df = res.dropna()\n",
    "\n",
    "        def assign_significance_tag(fdr):\n",
    "            if fdr < 0.001:\n",
    "                return \"***\"\n",
    "            elif fdr < 0.01:\n",
    "                return \"**\"\n",
    "            elif fdr < 0.05:\n",
    "                return \"*\"\n",
    "            else:\n",
    "                return \"ns\"\n",
    "\n",
    "        #res_df.loc[:,\"tag\"] = res_df[\"FDR\"].apply(assign_significance_tag)\n",
    "        res_df = res_df.assign(tag=res_df[\"FDR\"].apply(assign_significance_tag))\n",
    "\n",
    "        res_df.rename(columns={\"names\":\"tf\", \"group\": \"condition\"}, inplace=True)\n",
    "        res_df.to_csv(f\"{out_path}/all_tfs_{vs1}_vs_{vs2}.csv\", index=False)\n",
    "\n",
    "        result_name = f\"{vs1}_{vs2}\"\n",
    "        vs_df_dic[result_name] = res_df\n",
    "        #print(vs_df_dic[result_name])\n",
    "    return vs_df_dic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1219,
   "metadata": {},
   "outputs": [],
   "source": [
    "#decoupler significant tfs\n",
    "\n",
    "def get_significant_tfs(tf_activities_sub, condition, out_path, tf_condition_significant, celltype, pval, meanchange, plot, condition_comparison = False):\n",
    "    \n",
    "\n",
    "    renamed_condition = condition.replace(\",\", \"_\")\n",
    "\n",
    "    single_result_path = out_path + renamed_condition \n",
    "    if not os.path.isdir(single_result_path):\n",
    "        os.mkdir(single_result_path)\n",
    "\n",
    "    number_of_clusters = len(tf_activities_sub.obs[celltype].cat.categories) \n",
    "\n",
    "    anndataobject_markers_wilcoxon = dc.rank_sources_groups(tf_activities_sub, groupby= celltype, reference=\"rest\", method=\"wilcoxon\")\n",
    "\n",
    "    anndataobject_markers_wilcoxon.rename(columns={\"names\" : \"gene\", \"group\": \"cluster\", \"statistic\" : \"scores\"}, inplace=True)\n",
    "    \n",
    "    \n",
    "    anndataobject_markers_wilcoxon[\"tag\"] = None\n",
    "    anndataobject_markers_wilcoxon[\"meanchange_tag\"] = None\n",
    "    \n",
    "    #print(\"after concat\", anndataobject_markers_wilcoxon)\n",
    "    \n",
    "    anndataobject_markers_wilcoxon[\"tag\"] = anndataobject_markers_wilcoxon[\"pvals_adj\"].apply(eval_pval)\n",
    "    anndataobject_markers_wilcoxon[\"meanchange_tag\"] = anndataobject_markers_wilcoxon[\"meanchange\"].apply(eval_meanchange_tag)\n",
    "     \n",
    "\n",
    "    anndataobject_markers_wilcoxon.to_csv(single_result_path + \"/\" + renamed_condition + \"_specific_markers_wilcoxon_test.csv\",index=0)\n",
    "\n",
    "   #tag mapping wilcoxon\n",
    "    clusters = sorted(anndataobject_markers_wilcoxon[\"cluster\"].unique())\n",
    "    tag_mapping_wilcox = anndataobject_markers_wilcoxon[[\"gene\", \"tag\", \"meanchange_tag\", \"cluster\", \"pvals_adj\", \"meanchange\"]]\n",
    "    tag_mapping_wilcox = tag_mapping_wilcox[(tag_mapping_wilcox[\"pvals_adj\"] < float(pval))] \n",
    "    tag_mapping_wilcox = tag_mapping_wilcox[(tag_mapping_wilcox[\"meanchange\"] > float(meanchange)) | \n",
    "                              (tag_mapping_wilcox[\"meanchange\"] < -float(meanchange))]\n",
    "\n",
    "    tag_mapping_wilcox = tag_mapping_wilcox.pivot(index=\"gene\", columns=\"cluster\", values=\"tag\")\n",
    "\n",
    "    for cluster in clusters:\n",
    "        if cluster not in tag_mapping_wilcox.columns:\n",
    "            tag_mapping_wilcox[cluster] = np.nan\n",
    "\n",
    "    tag_mapping_wilcox = tag_mapping_wilcox[clusters]\n",
    "    tag_mapping_wilcox = tag_mapping_wilcox.astype(\"object\")\n",
    "    tag_mapping_wilcox.fillna(\"ns\", inplace=True)\n",
    "\n",
    "    #tag_mapping_wilcox.to_csv(\"tag_mapping.csv\",index=0)\n",
    "\n",
    "    tf_activities_sub.obs_names = tf_activities_sub.obs[celltype].astype(str)\n",
    "    tf_scores_df = tf_activities_sub.to_df()\n",
    "    #tf_scores_df.columns.name = None\n",
    "    unfiltered_tf_scores = create_unfiltered_tf_scores(tf_scores_df, condition, celltype, single_result_path)\n",
    "   \n",
    "    #Filter to only include tfs that match the tag_mapping/are markers\n",
    "    #print(tag_mapping_wilcox)\n",
    "    col_num = tf_scores_df.columns.isin(tag_mapping_wilcox.index)  \n",
    "    print(\"col_num\", col_num)\n",
    "    filtered_tf_scores_df = tf_scores_df.loc[:, col_num]\n",
    "\n",
    "\n",
    "    filtered_summarized_tf_scores_df = filtered_tf_scores_df.groupby(celltype, observed = False).mean().T\n",
    "    filtered_summarized_tf_scores_df.sort_index(axis=1, inplace=True)\n",
    "    filtered_summarized_tf_scores_df.index.name = \"gene\"\n",
    "    filtered_summarized_tf_scores_df.to_csv(f\"{single_result_path}/tf_scores_{condition}.csv\")\n",
    "    tf_scores_variable_table = save_variable_tf_score(filtered_summarized_tf_scores_df, condition, single_result_path, plot)\n",
    "\n",
    "    if plot:\n",
    "        plot_tf_activity(filtered_summarized_tf_scores_df, tag_mapping_wilcox, condition, single_result_path)\n",
    "    \n",
    "    filtered_summarized_tf_scores_df.index = filtered_summarized_tf_scores_df.index.map(lambda x: re.sub(\".,\", \"_\", x))\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    anndataobject_markers_wilcoxon_merged = anndataobject_markers_wilcoxon.merge(map_z_value(filtered_summarized_tf_scores_df, anndataobject_markers_wilcoxon),  on=['gene', 'cluster'], how='inner')\n",
    "    anndataobject_markers_wilcoxon_merged = anndataobject_markers_wilcoxon_merged[anndataobject_markers_wilcoxon_merged.tag != \"ns\"]\n",
    "    anndataobject_markers_wilcoxon_merged = anndataobject_markers_wilcoxon_merged.where(anndataobject_markers_wilcoxon_merged[\"t_value\"] > 0, np.nan) \n",
    "    anndataobject_markers_wilcoxon_merged.dropna(inplace=True)\n",
    "    res_wilcoxon = anndataobject_markers_wilcoxon_merged[[\"gene\",\"tag\", \"cluster\", \"t_value\"]]\n",
    "\n",
    "\n",
    "    #anndataobject_markers_t_over_merged = anndataobject_markers_t_over.merge(map_z_value_filtered(filtered_summarized_tf_scores_df, anndataobject_markers_t_over),  on=['gene', 'cluster'], how='inner')\n",
    "    #anndataobject_markers_t_over_merged = anndataobject_markers_t_over_merged[anndataobject_markers_t_over_merged.tag != \"ns\"]\n",
    "    #anndataobject_markers_t_over_merged.dropna(inplace=True)\n",
    "    #res_t_test = anndataobject_markers_t_over[[\"gene\",\"tag\", \"cluster\", \"t_value\"]]\n",
    "\n",
    "    res_wilcoxon.to_csv(single_result_path + \"/significant_cluster_tf_results_wilcoxon_\" + renamed_condition + \".csv\", index=0)\n",
    "    #res_t_test.to_csv(single_result_path  + \"/_significant_cluster_tf_results_t_test_\" + renamed_condition + \".csv\", index=0)\n",
    "\n",
    "    res = {}\n",
    "    res[\"cluster\"] = res_wilcoxon\n",
    "    \n",
    "\n",
    "    if condition_comparison:\n",
    "        tf_condition_significant[\"gene\"] = tf_condition_significant[\"gene\"].apply(lambda x: re.sub(\".,\", \"_\", x))\n",
    "        tf_condition_significant = tf_condition_significant.merge(map_z_value(unfiltered_tf_scores, tf_condition_significant), left_on=None, right_on=None, left_index=False, right_index=False)\n",
    "        unfiltered_tf_scores = unfiltered_tf_scores.where(unfiltered_tf_scores > 0, np.nan) \n",
    "        tf_condition_significant.dropna(inplace=True)\n",
    "    \n",
    "        res[\"condition\"] = tf_condition_significant\n",
    "        res[\"condition\"].to_csv(f\"{single_result_path}/significant_condition_tf_results_{condition}.csv\", index=0)\n",
    "\n",
    "    return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1220,
   "metadata": {},
   "outputs": [],
   "source": [
    "def IntraTalker_analysis(anndataobject, tf_activities = None, arguments_list = None):\n",
    "    \n",
    "    if (isinstance(anndataobject, str)):\n",
    "        anndataobject = ad.read_h5ad(anndataobject)\n",
    "\n",
    "    arguments_list = validate_input_arguments(arguments_list)\n",
    "\n",
    "    if arguments_list[\"decoupler_matrix_format\"] == \"R\":\n",
    "        anndataobject = anndataobject.T\n",
    "\n",
    "    if not os.path.isdir(arguments_list[\"out_path\"]):\n",
    "        os.mkdir(arguments_list[\"out_path\"])\n",
    "        tf_path = arguments_list[\"out_path\"] + \"TF_results/\"\n",
    "        os.mkdir(tf_path)\n",
    "    else:\n",
    "        tf_path = arguments_list[\"out_path\"] + \"TF_results/\"\n",
    "\n",
    "\n",
    "    condition = anndataobject.obs[arguments_list[\"condition\"]]\n",
    "\n",
    "    if isinstance(tf_activities, str):\n",
    "         tf_activities = ad.read_csv(tf_activities)\n",
    "         tf_activities.obs = anndataobject.obs.reindex(tf_activities.obs.index)\n",
    "         tf_activities.obsm = anndataobject.obsm\n",
    "         tf_activities.uns = anndataobject.uns\n",
    "\n",
    "\n",
    "    elif tf_activities is None:\n",
    "         raise NameError(\"Please attach a csv file with the tf activity values. (For further clarification view the 'Decoupler' section of the vignette.)\")\n",
    "        \n",
    "    #sc.pp.scale(tf_activities)\n",
    "\n",
    "    #sets the stage for decision if single condition or comparison analysis is done\n",
    "    \n",
    "    if not arguments_list[\"comparison_list\"] is None:\n",
    "        if (len(arguments_list[\"comparison_list\"]) > 0) & (len(pd.unique(anndataobject.obs[arguments_list[\"condition\"]])) < 2):\n",
    "            arguments_list[\"comparison_list\"] = None\n",
    "            print(\"Only one condition was found in the data, although a list of comparisons was provided. The analyses are performed only for the present condition!\")\n",
    "\n",
    "    #code for single condition  analysis\n",
    "\n",
    "    if arguments_list[\"comparison_list\"] is None:\n",
    "\n",
    "        result_list = {}\n",
    "        gene_expression_list = {}\n",
    "        CTR_cluster_list = {}\n",
    "        intranet_cluster_list = {}\n",
    "\n",
    "        #creates loop until after tf activity score\n",
    "        \n",
    "        for name_iterable in anndataobject.obs[arguments_list[\"condition\"]].unique():\n",
    "            sub_object = anndataobject[anndataobject.obs[arguments_list[\"condition\"]] == name_iterable].copy()\n",
    "            tf_activities_sub = tf_activities[tf_activities.obs[arguments_list[\"condition\"]] == name_iterable].copy()\n",
    "\n",
    "            sub_object_avg = AverageExpression(sub_object, name_iterable= name_iterable, celltype = arguments_list[\"celltype\"], outpath= arguments_list[\"out_path\"])\n",
    "        \n",
    "            \n",
    "            tf_activity_scores = get_significant_tfs(tf_activities_sub,\n",
    "                                                        name_iterable,\n",
    "                                                        tf_path,\n",
    "                                                        None,\n",
    "                                                        celltype = arguments_list[\"celltype\"],\n",
    "                                                        pval = arguments_list[\"pval\"],\n",
    "                                                        meanchange = arguments_list[\"meanchange\"],\n",
    "                                                        plot = arguments_list[\"plot\"],\n",
    "                                                        condition_comparison= False)\n",
    "            \n",
    "\n",
    "            result_list[name_iterable] = tf_activity_scores\n",
    "            \n",
    "            gene_expression_list[name_iterable] = sub_object_avg\n",
    "            \n",
    "        \n",
    "    \n",
    "            CTR_cluster_list[name_iterable] = generate_CrossTalkeR_input(tf_activity_scores[\"cluster\"],\n",
    "                                                                            gene_expression_list[name_iterable],\n",
    "                                                                            arguments_list[\"out_path\"],                                             \n",
    "                                                                            arguments_list[\"reg\"],\n",
    "                                                                            arguments_list[\"organism\"])\n",
    "    \n",
    "              \n",
    "            intranet_cluster_list[name_iterable] = generate_intracellular_network(tf_activity_scores[\"cluster\"],\n",
    "                                                                                  gene_expression_list[name_iterable],\n",
    "                                                                                  arguments_list[\"out_path\"],\n",
    "                                                                                  arguments_list[\"reg\"],\n",
    "                                                                                  arguments_list[\"organism\"])\n",
    "            \n",
    "\n",
    "        tf = make_TFOBj(\n",
    "                tf_activities_condition = list(),\n",
    "                tf_activities_cluster = result_list,\n",
    "                average_gene_expression = gene_expression_list,\n",
    "                regulon = arguments_list[\"reg\"],\n",
    "                CTR_input_condition = list(),\n",
    "                CTR_input_cluster = CTR_cluster_list,\n",
    "                intracellular_network_condition = list(),\n",
    "                intracellular_network_cluster = intranet_cluster_list)\n",
    "\n",
    "        #with open((arguments_list[\"out_path\"] + \"tf.pickle\"), \"wb\") as file:\n",
    "        #    pickle.dump(tf, file)\n",
    "\n",
    "        return tf\n",
    "\n",
    "    else:\n",
    "        out_path_compared = (tf_path + \"compared\")\n",
    "        if not os.path.isdir(out_path_compared):\n",
    "            os.mkdir(out_path_compared)\n",
    "\n",
    "        compared_significant_tfs = condition_comparison_significant(tf_activities, out_path_compared, arguments_list[\"celltype\"], \n",
    "                                                                    arguments_list[\"condition\"], arguments_list[\"comparison_list\"], \n",
    "                                                                    arguments_list[\"num_cell_filter\"])\n",
    "        \n",
    "        print(\"compared tfs done\")\n",
    "        \n",
    "        if arguments_list[\"plot\"] == True:\n",
    "            plot_condition_tf_activities(compared_significant_tfs, out_path_compared)\n",
    "            plot_condition_tf_activities_compressed(compared_significant_tfs, out_path_compared)\n",
    "\n",
    "    \n",
    "        result_condition_list = {}\n",
    "        result_cluster_list = {}\n",
    "        gene_expression_list = {}\n",
    "        CTR_condition_list = {}\n",
    "        CTR_cluster_list = {}\n",
    "        intranet_condition_list = {}\n",
    "        intranet_cluster_list = {}\n",
    "\n",
    "        for name_iterable in anndataobject.obs[arguments_list[\"condition\"]].unique():\n",
    "            sub_object = anndataobject[anndataobject.obs[arguments_list[\"condition\"]] == name_iterable]\n",
    "            tf_activities_sub = tf_activities[tf_activities.obs[arguments_list[\"condition\"]] == name_iterable]\n",
    "            \n",
    "\n",
    "            compared_tfs = pd.DataFrame({\"gene\" : pd.Series(dtype=\"str\"), \"tag\" : pd.Series(dtype=\"str\"), \"cluster\" : pd.Series(dtype=\"str\")})\n",
    "            #print(\"before\", compared_significant_tfs)\n",
    "        \n",
    "            for result_name, df in compared_significant_tfs.items(): \n",
    "                if name_iterable in result_name:\n",
    "                    tf_condition_significant = compared_significant_tfs[result_name]\n",
    "                    tf_condition_significant = tf_condition_significant[tf_condition_significant[\"FDR\"] < arguments_list[\"pval\"]]\n",
    "                    tf_condition_significant = tf_condition_significant[(tf_condition_significant[\"meanchange\"] > float(arguments_list[\"meanchange\"])) | (tf_condition_significant[\"meanchange\"] < (0 - float(arguments_list[\"meanchange\"])))]\n",
    "                    tf_condition_significant = tf_condition_significant[[\"tf\", \"tag\", \"CellType\"]]\n",
    "                    tf_condition_significant.rename(columns={\"tf\":\"gene\", \"CellType\": \"cluster\"}, inplace=True)\n",
    "                    compared_tfs = pd.concat([compared_tfs, tf_condition_significant])\n",
    "\n",
    "        \n",
    "            \n",
    "            re.sub(\"([,;.:-])\", \"_\", name_iterable)\n",
    "\n",
    "            sub_object_avg = AverageExpression(sub_object, name_iterable= name_iterable, celltype = arguments_list[\"celltype\"], \n",
    "                                               outpath= arguments_list[\"out_path\"])\n",
    "            \n",
    "            tf_activity_scores = get_significant_tfs(tf_activities_sub,\n",
    "                                               name_iterable,\n",
    "                                               tf_path,\n",
    "                                               compared_tfs,\n",
    "                                               celltype = arguments_list[\"celltype\"],\n",
    "                                               pval = arguments_list[\"pval\"],\n",
    "                                               meanchange = arguments_list[\"meanchange\"],\n",
    "                                               plot = arguments_list[\"plot\"],\n",
    "                                               condition_comparison= True)\n",
    "            \n",
    "            print(\"tf_activities done\")\n",
    "\n",
    "            result_condition_list[name_iterable] = tf_activity_scores[\"condition\"]\n",
    "            result_cluster_list[name_iterable] = tf_activity_scores[\"cluster\"]\n",
    "\n",
    "            #print(result_condition_list[name_iterable])\n",
    "            #print(result_cluster_list[name_iterable])\n",
    "\n",
    "            gene_expression_list[name_iterable] = sub_object_avg\n",
    "            \n",
    "        \n",
    "            CTR_condition_list[name_iterable] = generate_CrossTalkeR_input(tf_activity_scores[\"condition\"],\n",
    "                                                                            gene_expression_list[name_iterable],\n",
    "                                                                           arguments_list[\"out_path\"],                                             \n",
    "                                                                           arguments_list[\"reg\"],\n",
    "                                                                           arguments_list[\"organism\"])\n",
    "            \n",
    "            print(\"CTR input condition done\")\n",
    "    \n",
    "            CTR_cluster_list[name_iterable] = generate_CrossTalkeR_input(tf_activity_scores[\"cluster\"],\n",
    "                                                                            gene_expression_list[name_iterable],\n",
    "                                                                            arguments_list[\"out_path\"],                                             \n",
    "                                                                            arguments_list[\"reg\"],\n",
    "                                                                            arguments_list[\"organism\"])\n",
    "    \n",
    "            print(\"CTR input cluster done\")\n",
    "\n",
    "            intranet_condition_list[name_iterable] = generate_intracellular_network(tf_activity_scores[\"condition\"],\n",
    "                                                                                  gene_expression_list[name_iterable],\n",
    "                                                                                  arguments_list[\"out_path\"],\n",
    "                                                                                  arguments_list[\"reg\"],\n",
    "                                                                                  arguments_list[\"organism\"])\n",
    "    \n",
    "            print(\"intranet input condition done\")\n",
    "\n",
    "            intranet_cluster_list[name_iterable] = generate_intracellular_network(tf_activity_scores[\"cluster\"],\n",
    "                                                                                  gene_expression_list[name_iterable],\n",
    "                                                                                  arguments_list[\"out_path\"],\n",
    "                                                                                  arguments_list[\"reg\"],\n",
    "                                                                                  arguments_list[\"organism\"])\n",
    "            print(\"intranet input cluster done\")\n",
    "            #print(CTR_cluster_list[name_iterable])\n",
    "            #print(CTR_condition_list[name_iterable])\n",
    "            \n",
    "        tf = make_TFOBj(\n",
    "                tf_activities_condition = result_condition_list,\n",
    "                tf_activities_cluster = result_cluster_list,\n",
    "                average_gene_expression = gene_expression_list,\n",
    "                regulon = arguments_list[\"reg\"],\n",
    "                CTR_input_condition = CTR_condition_list,\n",
    "                CTR_input_cluster = CTR_cluster_list,\n",
    "                intracellular_network_condition = intranet_condition_list,\n",
    "                intracellular_network_cluster = intranet_cluster_list)\n",
    "\n",
    "        #with open((arguments_list[\"out_path\"] + \"tf.pickle\"), \"wb\") as file:\n",
    "        #    pickle.dump(tf, file)\n",
    "        \n",
    "        return tf\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1221,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "vs1: PMF,MF2, vs2: control\n",
      "compared tfs done\n",
      "col_num [False  True  True  True  True False  True  True  True  True  True False\n",
      "  True  True  True False False  True  True False False  True False  True\n",
      " False  True  True  True  True False  True False  True  True  True  True\n",
      " False  True  True  True  True  True False False  True  True  True False\n",
      " False  True False  True  True False  True False False  True  True  True\n",
      "  True  True  True  True  True  True  True  True  True  True  True  True\n",
      "  True  True  True  True  True  True  True  True False  True  True  True\n",
      "  True  True  True  True  True False  True  True False  True  True  True\n",
      "  True False  True False False False  True False  True  True  True  True\n",
      "  True  True False  True False  True  True  True False False  True  True\n",
      "  True False False  True  True  True  True  True  True  True False  True\n",
      " False False False  True False  True  True  True  True False False  True\n",
      "  True  True  True  True  True  True False  True  True  True False  True\n",
      "  True  True  True  True  True  True  True  True  True  True  True  True\n",
      "  True  True  True  True  True  True False False  True  True False  True\n",
      "  True  True False  True  True False False  True False  True  True  True\n",
      "  True  True False  True  True  True  True  True  True  True  True  True\n",
      "  True  True  True  True  True  True  True False False  True  True  True\n",
      "  True False False  True  True  True  True  True False  True  True False\n",
      "  True  True False False  True  True  True  True  True  True  True  True\n",
      "  True  True  True False  True  True  True False  True False  True  True\n",
      "  True False  True  True  True  True  True  True  True  True  True  True\n",
      "  True False  True  True  True  True False False  True  True False  True\n",
      "  True False  True False False  True  True  True  True  True  True  True\n",
      " False  True  True  True  True  True False  True False  True  True  True\n",
      "  True  True  True  True  True  True  True  True  True False  True  True\n",
      "  True  True  True  True  True  True  True False  True False  True  True\n",
      " False  True False  True False  True False False  True  True  True False\n",
      "  True  True  True  True  True  True False False  True  True  True  True\n",
      " False  True False False False  True  True  True False  True  True]\n",
      "new_annotation  Fibroblast       MSC  Megakaryocyte   Myeloid    Neural  \\\n",
      "gene                                                                      \n",
      "AHR              -0.307708  1.226634      -1.322608 -1.558378  0.193219   \n",
      "AR                0.163686  1.705644      -0.634596 -0.198338  0.407283   \n",
      "ARID2             0.417091  1.146984      -0.259242  0.598175  0.557884   \n",
      "ARID3A           -0.491398  0.316980      -0.684942  0.160989  0.178892   \n",
      "ASCL1            -1.002526 -1.200717      -1.413680 -0.971306 -0.369672   \n",
      "...                    ...       ...            ...       ...       ...   \n",
      "ZNF740           -0.186366  0.732929      -0.329808  0.131907  1.361346   \n",
      "ZNF750           -0.873353 -0.357412      -1.471511 -1.209110 -0.315573   \n",
      "ZNF766           -0.794723 -0.937045      -0.934624 -0.829040 -0.340906   \n",
      "ZNF92            -0.516043 -0.479996      -1.347571 -1.618925 -0.693033   \n",
      "ZZZ3              0.317864  0.364512       0.437020  0.133325 -0.254792   \n",
      "\n",
      "new_annotation       var  \n",
      "gene                      \n",
      "AHR             1.297181  \n",
      "AR              0.781776  \n",
      "ARID2           0.253648  \n",
      "ARID3A          0.203761  \n",
      "ASCL1           0.152302  \n",
      "...                  ...  \n",
      "ZNF740          0.491632  \n",
      "ZNF750          0.260983  \n",
      "ZNF766          0.060797  \n",
      "ZNF92           0.269749  \n",
      "ZZZ3            0.077104  \n",
      "\n",
      "[270 rows x 6 columns]\n",
      "new_annotation  Fibroblast       MSC  Megakaryocyte   Myeloid    Neural\n",
      "ADNP             -1.051893 -0.858514      -1.349577 -1.244174 -0.776356\n",
      "AHR              -0.307708  1.226634      -1.322608 -1.558378  0.193219\n",
      "AR                0.163686  1.705644      -0.634596 -0.198338  0.407283\n",
      "ARID2             0.417091  1.146984      -0.259242  0.598175  0.557884\n",
      "ARID3A           -0.491398  0.316980      -0.684942  0.160989  0.178892\n",
      "...                    ...       ...            ...       ...       ...\n",
      "ZNF750           -0.873353 -0.357412      -1.471511 -1.209110 -0.315573\n",
      "ZNF766           -0.794723 -0.937045      -0.934624 -0.829040 -0.340906\n",
      "ZNF83             0.215214  0.351386       0.510253  0.316172  0.265720\n",
      "ZNF92            -0.516043 -0.479996      -1.347571 -1.618925 -0.693033\n",
      "ZZZ3              0.317864  0.364512       0.437020  0.133325 -0.254792\n",
      "\n",
      "[359 rows x 5 columns]\n",
      "tf_activities done\n",
      "CTR input condition done\n",
      "CTR input cluster done\n",
      "intranet input condition done\n",
      "intranet input cluster done\n",
      "col_num [ True  True  True  True  True False  True  True  True  True  True  True\n",
      "  True  True  True  True  True  True  True False  True False  True  True\n",
      " False  True  True  True  True  True  True False False  True  True  True\n",
      "  True  True  True  True  True  True False  True  True  True  True False\n",
      " False  True  True  True  True  True  True  True False  True  True  True\n",
      "  True  True  True  True  True  True  True  True  True  True  True  True\n",
      "  True  True  True  True  True  True  True  True False  True  True  True\n",
      "  True  True  True  True  True  True  True  True False  True  True  True\n",
      "  True  True  True  True  True  True False  True  True  True  True  True\n",
      " False  True False  True False  True  True False  True False  True  True\n",
      "  True False  True  True  True False  True  True  True  True  True False\n",
      "  True  True  True  True  True  True  True  True False  True False  True\n",
      "  True  True  True  True  True  True  True  True  True  True  True  True\n",
      "  True  True  True  True  True  True  True  True  True False  True False\n",
      "  True  True False  True  True  True  True  True  True  True False  True\n",
      "  True  True  True  True  True  True  True  True  True  True  True  True\n",
      "  True  True  True  True  True  True  True  True  True  True  True  True\n",
      " False  True  True False  True  True  True  True  True False  True  True\n",
      "  True False  True  True  True  True  True  True False  True  True False\n",
      "  True  True False  True  True  True False  True  True  True  True  True\n",
      "  True  True  True  True  True  True  True  True  True False  True  True\n",
      "  True  True  True False  True  True  True  True  True  True  True  True\n",
      "  True  True  True  True  True  True False  True  True  True  True  True\n",
      "  True False  True  True False False  True  True  True  True  True  True\n",
      "  True  True  True  True  True  True False  True  True  True  True  True\n",
      "  True  True  True  True  True  True False  True  True  True  True  True\n",
      "  True  True  True  True  True  True  True  True  True False  True  True\n",
      "  True False  True  True False  True  True  True  True  True  True  True\n",
      "  True  True  True  True  True  True  True  True  True  True  True  True\n",
      "  True  True False  True  True  True  True  True  True  True  True]\n",
      "new_annotation  Fibroblast       MSC  Megakaryocyte   Myeloid    Neural  \\\n",
      "gene                                                                      \n",
      "ADNP             -0.870116 -0.638793      -0.956318 -1.173983 -0.241832   \n",
      "AHR              -0.779942  1.512223      -1.687008 -1.425144 -0.969373   \n",
      "AR               -0.045079  1.157381      -0.124143 -0.186571  0.431653   \n",
      "ARID2             0.000928  1.196451       0.239218 -0.520630  0.924855   \n",
      "ARID3A           -0.793377  0.851371      -0.267953 -1.128399  0.130700   \n",
      "...                    ...       ...            ...       ...       ...   \n",
      "ZNF750           -1.877062 -0.265979      -1.669147 -1.741956 -1.572268   \n",
      "ZNF766           -0.877722 -0.655792      -0.825913 -0.900506 -0.038935   \n",
      "ZNF83             0.431817  0.266376       1.134436  0.747866  1.349940   \n",
      "ZNF92            -1.322473 -0.231719      -1.795834 -1.618380 -1.194463   \n",
      "ZZZ3             -0.220140  0.327302      -0.243857 -0.059597 -0.534232   \n",
      "\n",
      "new_annotation       var  \n",
      "gene                      \n",
      "ADNP            0.125981  \n",
      "AHR             1.617089  \n",
      "AR              0.318483  \n",
      "ARID2           0.484353  \n",
      "ARID3A          0.606189  \n",
      "...                  ...  \n",
      "ZNF750          0.432362  \n",
      "ZNF766          0.129628  \n",
      "ZNF83           0.209086  \n",
      "ZNF92           0.369338  \n",
      "ZZZ3            0.099319  \n",
      "\n",
      "[312 rows x 6 columns]\n",
      "new_annotation  Fibroblast       MSC  Megakaryocyte   Myeloid    Neural\n",
      "ADNP             -0.870116 -0.638793      -0.956318 -1.173983 -0.241832\n",
      "AHR              -0.779942  1.512223      -1.687008 -1.425144 -0.969373\n",
      "AR               -0.045079  1.157381      -0.124143 -0.186571  0.431653\n",
      "ARID2             0.000928  1.196451       0.239218 -0.520630  0.924855\n",
      "ARID3A           -0.793377  0.851371      -0.267953 -1.128399  0.130700\n",
      "...                    ...       ...            ...       ...       ...\n",
      "ZNF750           -1.877062 -0.265979      -1.669147 -1.741956 -1.572268\n",
      "ZNF766           -0.877722 -0.655792      -0.825913 -0.900506 -0.038935\n",
      "ZNF83             0.431817  0.266376       1.134436  0.747866  1.349940\n",
      "ZNF92            -1.322473 -0.231719      -1.795834 -1.618380 -1.194463\n",
      "ZZZ3             -0.220140  0.327302      -0.243857 -0.059597 -0.534232\n",
      "\n",
      "[359 rows x 5 columns]\n",
      "tf_activities done\n",
      "CTR input condition done\n",
      "CTR input cluster done\n",
      "intranet input condition done\n",
      "intranet input cluster done\n"
     ]
    }
   ],
   "source": [
    "result = IntraTalker_analysis(anndataobject= \"LR2TF_test_run/anndata_object.h5ad\", \n",
    "                              tf_activities= \"decoupler_results.csv\",\n",
    "                              arguments_list= {\"out_path\" : \"script_test\", \n",
    "                                                \"celltype\" : \"new_annotation\",\n",
    "                                                \"condition\" : \"protocol\", \n",
    "                                                \"organism\" : \"human\", \n",
    "                                                \"comparison_list\" : [\"PMF,MF2\", \"control\"], #[\"control\", \"PMF,MF2\"]], \n",
    "                                                \"meanchange\" : \"0.5\",\n",
    "                                                \"pval\" : None, \n",
    "                                                \"num_cell_filter\": None,\n",
    "                                                \"reg\" : \"LR2TF_test_run/filterd_regulon.csv\",                                                                                              \n",
    "                                                \"plot\" : True,\n",
    "                                                \"decoupler_matrix_format\" : \"Python\"})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1222,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       gene  tag        cluster   t_value\n",
      "0      ARNT    *  Megakaryocyte -0.564721\n",
      "1      ATF1    *  Megakaryocyte -0.271672\n",
      "2      ATF3    *  Megakaryocyte  0.190079\n",
      "3     BACH1   **  Megakaryocyte  0.236442\n",
      "4     BACH2    *  Megakaryocyte  0.632772\n",
      "..      ...  ...            ...       ...\n",
      "375  ZNF644  ***         Neural  0.774643\n",
      "376  ZNF740  ***         Neural -0.068152\n",
      "377  ZNF750  ***         Neural -0.507218\n",
      "378   ZNF83  ***         Neural  0.657175\n",
      "379   ZNF92  ***         Neural -0.283061\n",
      "\n",
      "[380 rows x 4 columns]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>source</th>\n",
       "      <th>target</th>\n",
       "      <th>gene_A</th>\n",
       "      <th>gene_B</th>\n",
       "      <th>type_gene_A</th>\n",
       "      <th>type_gene_B</th>\n",
       "      <th>MeanLR</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Megakaryocyte</td>\n",
       "      <td>Megakaryocyte</td>\n",
       "      <td>ATF3</td>\n",
       "      <td>ANXA1</td>\n",
       "      <td>Transcription_Factor</td>\n",
       "      <td>Ligand</td>\n",
       "      <td>0.190079</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Megakaryocyte</td>\n",
       "      <td>Megakaryocyte</td>\n",
       "      <td>ATF3</td>\n",
       "      <td>ANXA2</td>\n",
       "      <td>Transcription_Factor</td>\n",
       "      <td>Ligand</td>\n",
       "      <td>0.190079</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Megakaryocyte</td>\n",
       "      <td>Megakaryocyte</td>\n",
       "      <td>ATF3</td>\n",
       "      <td>CCL5</td>\n",
       "      <td>Transcription_Factor</td>\n",
       "      <td>Ligand</td>\n",
       "      <td>0.190079</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Megakaryocyte</td>\n",
       "      <td>Megakaryocyte</td>\n",
       "      <td>ATF3</td>\n",
       "      <td>CIRBP</td>\n",
       "      <td>Transcription_Factor</td>\n",
       "      <td>Ligand</td>\n",
       "      <td>0.190079</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Megakaryocyte</td>\n",
       "      <td>Megakaryocyte</td>\n",
       "      <td>ATF3</td>\n",
       "      <td>SORL1</td>\n",
       "      <td>Transcription_Factor</td>\n",
       "      <td>Ligand</td>\n",
       "      <td>0.190079</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5280</th>\n",
       "      <td>Neural</td>\n",
       "      <td>Neural</td>\n",
       "      <td>INSR</td>\n",
       "      <td>ZNF24</td>\n",
       "      <td>Receptor</td>\n",
       "      <td>Transcription Factor</td>\n",
       "      <td>0.532363</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5281</th>\n",
       "      <td>Neural</td>\n",
       "      <td>Neural</td>\n",
       "      <td>NGFR</td>\n",
       "      <td>ZNF274</td>\n",
       "      <td>Receptor</td>\n",
       "      <td>Transcription Factor</td>\n",
       "      <td>1.279600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5282</th>\n",
       "      <td>Neural</td>\n",
       "      <td>Neural</td>\n",
       "      <td>ZNF318</td>\n",
       "      <td>LGALS1</td>\n",
       "      <td>Transcription_Factor</td>\n",
       "      <td>Ligand</td>\n",
       "      <td>0.713510</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5283</th>\n",
       "      <td>Neural</td>\n",
       "      <td>Neural</td>\n",
       "      <td>ZNF589</td>\n",
       "      <td>ANP32B</td>\n",
       "      <td>Transcription_Factor</td>\n",
       "      <td>Ligand</td>\n",
       "      <td>0.506688</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5284</th>\n",
       "      <td>Neural</td>\n",
       "      <td>Neural</td>\n",
       "      <td>ZNF644</td>\n",
       "      <td>ANP32B</td>\n",
       "      <td>Transcription_Factor</td>\n",
       "      <td>Ligand</td>\n",
       "      <td>0.774643</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5285 rows  7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             source         target  gene_A  gene_B           type_gene_A  \\\n",
       "0     Megakaryocyte  Megakaryocyte    ATF3   ANXA1  Transcription_Factor   \n",
       "1     Megakaryocyte  Megakaryocyte    ATF3   ANXA2  Transcription_Factor   \n",
       "2     Megakaryocyte  Megakaryocyte    ATF3    CCL5  Transcription_Factor   \n",
       "3     Megakaryocyte  Megakaryocyte    ATF3   CIRBP  Transcription_Factor   \n",
       "4     Megakaryocyte  Megakaryocyte    ATF3   SORL1  Transcription_Factor   \n",
       "...             ...            ...     ...     ...                   ...   \n",
       "5280         Neural         Neural    INSR   ZNF24              Receptor   \n",
       "5281         Neural         Neural    NGFR  ZNF274              Receptor   \n",
       "5282         Neural         Neural  ZNF318  LGALS1  Transcription_Factor   \n",
       "5283         Neural         Neural  ZNF589  ANP32B  Transcription_Factor   \n",
       "5284         Neural         Neural  ZNF644  ANP32B  Transcription_Factor   \n",
       "\n",
       "               type_gene_B    MeanLR  \n",
       "0                   Ligand  0.190079  \n",
       "1                   Ligand  0.190079  \n",
       "2                   Ligand  0.190079  \n",
       "3                   Ligand  0.190079  \n",
       "4                   Ligand  0.190079  \n",
       "...                    ...       ...  \n",
       "5280  Transcription Factor  0.532363  \n",
       "5281  Transcription Factor  1.279600  \n",
       "5282                Ligand  0.713510  \n",
       "5283                Ligand  0.506688  \n",
       "5284                Ligand  0.774643  \n",
       "\n",
       "[5285 rows x 7 columns]"
      ]
     },
     "execution_count": 1222,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#inputt = pd.read_csv(\"new_test//TF_results//control//significant_condition_tf_results_control.csv\")\n",
    "inputt = pd.read_csv(\"new_test/TF_results/PMF_MF2/significant_condition_tf_results_PMF_MF2.csv\")\n",
    "inputt = inputt.iloc[:,1:5]\n",
    "inputt.rename(columns={\"z_score\" : \"t_value\"}, inplace=True)\n",
    "#inputt = inputt.set_index(\"tf\")\n",
    "print(inputt)\n",
    "\n",
    "reguloninput = pd.read_csv(\"filterd_regulon.csv\")\n",
    "reguloninput.rename(columns={\"source\" : \"tf\"}, inplace=True)\n",
    "\n",
    "generate_CrossTalkeR_input(inputt, result.average_gene_expression[\"control\"], \"R_CTR_input_w_py_code\", regulon = reguloninput, organism = \"human\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1223,
   "metadata": {},
   "outputs": [],
   "source": [
    "result.CTR_input_condition[\"control\"].to_csv(\"py_ctr_input_wo_ctr_exp_tables.csv\", index = False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1224,
   "metadata": {},
   "outputs": [],
   "source": [
    "result.intracellular_network_condition[\"control\"].to_csv(\"py_intra_network_ctrl.csv\")\n",
    "result.intracellular_network_condition[\"PMF,MF2\"].to_csv(\"py_intra_network_PMF.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1225,
   "metadata": {},
   "outputs": [],
   "source": [
    "result.intracellular_network_cluster[\"control\"].to_csv(\"py_intra_network_ctrl_cluster.csv\")\n",
    "result.intracellular_network_cluster[\"PMF,MF2\"].to_csv(\"py_intra_network_PMF_cluster.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1226,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_node_type(df):\n",
    "    \n",
    "    df['gene_A'] = np.where(df['type_gene_A'] == 'Ligand', df['gene_A'] + '|L', df['gene_A'])\n",
    "    df['gene_A'] = np.where(df['type_gene_A'] == 'Receptor', df['gene_A'] + '|R', df['gene_A'])\n",
    "    df['gene_A'] = np.where(df['type_gene_A'] == 'Transcription Factor', df['gene_A'] + '|TF', df['gene_A'])\n",
    "    df['gene_B'] = np.where(df['type_gene_B'] == 'Ligand', df['gene_B'] + '|L', df['gene_B'])\n",
    "    df['gene_B'] = np.where(df['type_gene_B'] == 'Receptor', df['gene_B'] + '|R', df['gene_B'])\n",
    "    df['gene_B'] = np.where(df['type_gene_B'] == 'Transcription Factor', df['gene_B'] + '|TF', df['gene_B'])\n",
    "    return df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def combine_LR_and_TF(tf_table, LR_prediction, out_path, condition, add_nodetype = False):\n",
    "\n",
    "  if isinstance(LR_prediction, pd.DataFrame):\n",
    "    lr_table = LR_prediction\n",
    "  else: \n",
    "    lr_table = pd.read_csv(LR_prediction, index_col=0)\n",
    "  \n",
    "\n",
    "  intra_connections = pd.DataFrame()\n",
    "  for celltype in np.unique([lr_table[\"source\"], lr_table[\"target\"]]):\n",
    "    lr_filtered_ligands = lr_table[lr_table[\"source\"] == celltype]\n",
    "    lr_filtered_receptors = lr_table[lr_table[\"target\"] == celltype]\n",
    "    lr_ligands = np.unique(lr_filtered_ligands[\"gene_A\"])\n",
    "    lr_receptors = np.unique(lr_filtered_receptors[\"gene_B\"])\n",
    "    #print(condition, celltype, lr_receptors)\n",
    "\n",
    "    tf_table_receptors = tf_table[(tf_table[\"target\"] == celltype) & (tf_table[\"type_gene_A\"] == \"Receptor\")]\n",
    "    tf_table_ligands = tf_table[(tf_table[\"source\"] == celltype) & (tf_table[\"type_gene_B\"] == \"Ligand\")]\n",
    "\n",
    "    tf_receptor_interactions =  tf_table_receptors[tf_table_receptors[\"gene_A\"].isin(lr_receptors)]\n",
    "    tf_ligand_interactions = tf_table_ligands[tf_table_ligands[\"gene_B\"].isin(lr_ligands)]\n",
    "\n",
    "\n",
    "    intra_connections = pd.concat([intra_connections, tf_receptor_interactions, tf_ligand_interactions])\n",
    "  intra_connections[\"all_pair\"] = (intra_connections[\"source\"] + \"/\" \n",
    "                                    + intra_connections[\"gene_A\"] + \"/\"\n",
    "                                    + intra_connections[\"target\"] + \"/\"\n",
    "                                    + intra_connections[\"gene_B\"])\n",
    "    \n",
    "  intra_connections = intra_connections.drop_duplicates(subset=[\"all_pair\"])\n",
    "  intra_connections.drop(columns=[\"all_pair\"], inplace=True)\n",
    "\n",
    "  complete_interactions = pd.concat([intra_connections, lr_table])\n",
    "\n",
    "  if add_nodetype:\n",
    "    complete_interactions = add_node_type(complete_interactions)\n",
    "      \n",
    "  complete_interactions.to_csv((out_path + \"CrossTalkeR_input_\" + condition + \".csv\"), index=0)\n",
    "  return(complete_interactions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1228,
   "metadata": {},
   "outputs": [],
   "source": [
    "def combine_LR_and_TF_unfiltered(tf_table, LR_prediction, out_path, condition, add_nodetype = False):\n",
    "\n",
    "  if isinstance(LR_prediction, pd.DataFrame):\n",
    "    lr_table = LR_prediction\n",
    "  else: \n",
    "    lr_table = pd.read_csv(LR_prediction, index_col=0)\n",
    "  \n",
    "\n",
    "\n",
    "  complete_interactions = pd.concat([tf_table, lr_table])\n",
    "\n",
    "  if add_nodetype:\n",
    "    complete_interactions = add_node_type(complete_interactions)\n",
    "      \n",
    "  complete_interactions.to_csv((out_path + \"CrossTalkeR_input_\" + condition + \"_unfiltered.csv\"), index=0)\n",
    "  return(complete_interactions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1229,
   "metadata": {},
   "outputs": [],
   "source": [
    "def combine_LR_and_TF_complexes(tf_table, LR_prediction, out_path, condition, add_nodetype = False):\n",
    "\n",
    "  if isinstance(LR_prediction, pd.DataFrame):\n",
    "    lr_table = LR_prediction\n",
    "  else: \n",
    "    lr_table = pd.read_csv(LR_prediction, index_col=False)\n",
    "  \n",
    "  intra_connections = pd.DataFrame()\n",
    "  for celltype in np.unique([lr_table[\"source\"], lr_table[\"target\"]]):\n",
    "    lr_filtered_ligands = lr_table[lr_table[\"source\"] == celltype]\n",
    "    lr_filtered_receptors = lr_table[lr_table[\"target\"] == celltype]\n",
    "    lr_ligands = np.unique(lr_filtered_ligands[\"gene_A\"])\n",
    "    lr_receptors = np.unique(lr_filtered_receptors[\"gene_B\"])\n",
    "    #print(lr_filtered_receptors)\n",
    "\n",
    "    lr_receptors = pd.Series(lr_receptors)\n",
    "    contains_complex = lr_receptors.str.contains(\"_\", na=False)\n",
    "    \n",
    "    R_with_complex = lr_receptors[contains_complex]\n",
    "    #print(\"R_with_complex\", R_with_complex)\n",
    "    R_without_complex = lr_receptors[(~contains_complex)]\n",
    "  \n",
    "    tf_table_receptors = tf_table[(tf_table[\"target\"] == celltype) & (tf_table[\"type_gene_A\"] == \"Receptor\")]\n",
    "    tf_receptor_interactions =  tf_table_receptors[tf_table_receptors[\"gene_A\"].isin(R_without_complex)]\n",
    "\n",
    "    c_receptors = tf_table_receptors[tf_table_receptors[\"gene_A\"].apply(lambda x: any(gene in x.split(\"+\") for gene in lr_receptors))]\n",
    "    #print(\"c receptors\", c_receptors)\n",
    "\n",
    "    complex_df = pd.DataFrame()\n",
    "    if len(R_with_complex) > 0:\n",
    "      for complex in R_with_complex:\n",
    "        receptors = complex.split(\"_\")\n",
    "        R_TF_with_complex = tf_table_receptors[tf_table_receptors[\"gene_A\"].isin(receptors)]\n",
    " \n",
    "        if len(R_TF_with_complex) == 0:\n",
    "          continue\n",
    "        \n",
    "        R_TF_with_complex.drop_duplicates()\n",
    "        R_TF_with_complex.loc[:,\"gene_A\"] = complex\n",
    "        complex_df = pd.concat([complex_df, R_TF_with_complex])\n",
    "\n",
    "      #complex_df.drop_duplicates()\n",
    "\n",
    "    tf_receptor_interactions = pd.concat([tf_receptor_interactions, complex_df])\n",
    "    #print(\"tf_receptor_interactions\", tf_receptor_interactions)\n",
    "    \n",
    "    tf_table_ligands = tf_table[(tf_table[\"source\"] == celltype) & (tf_table[\"type_gene_B\"] == \"Ligand\")]\n",
    "\n",
    "    \n",
    "    tf_ligand_interactions = tf_table_ligands[tf_table_ligands[\"gene_B\"].isin(lr_ligands)]\n",
    "\n",
    "    intra_connections = pd.concat([intra_connections, tf_receptor_interactions, c_receptors, tf_ligand_interactions])\n",
    "  \n",
    "  intra_connections[\"all_pair\"] = (intra_connections[\"source\"] + \"/\" \n",
    "                                    + intra_connections[\"gene_A\"] + \"/\"\n",
    "                                    + intra_connections[\"target\"] + \"/\"\n",
    "                                    + intra_connections[\"gene_B\"])\n",
    "  #print(\"intra_connections\", intra_connections)\n",
    "  intra_connections = intra_connections.drop_duplicates(subset=[\"all_pair\"])\n",
    "  intra_connections.drop(columns=[\"all_pair\"], inplace=True)\n",
    "\n",
    "  complete_interactions = pd.concat([intra_connections, lr_table])\n",
    "  \n",
    "  if add_nodetype:\n",
    "    complete_interactions = add_node_type(complete_interactions)\n",
    "      \n",
    "  complete_interactions.to_csv((out_path + \"CrossTalkeR_input_\" + condition + \".csv\"), index=False)\n",
    "  return(complete_interactions)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1230,
   "metadata": {},
   "outputs": [],
   "source": [
    "#LINUX\n",
    "table_ctr = pd.read_csv(\"/home/larissa/Documents/LR2TF_HiWi/LR2TF_test_run/CTR_LR.csv\", index_col=False)\n",
    "table_exp = pd.read_csv(\"/home/larissa/Documents/LR2TF_HiWi/LR2TF_test_run/EXP_LR.csv\", index_col= False)\n",
    "\n",
    "\n",
    "ctr_input = combine_LR_and_TF_complexes(result.CTR_input_condition[\"control\"], table_ctr, \"script_test/\", \"control\")\n",
    "exp_input = combine_LR_and_TF_complexes(result.CTR_input_condition[\"PMF,MF2\"], table_exp, \"script_test/\", \"PMF_MF2\")\n",
    "\n",
    "ctr_input_cluster = combine_LR_and_TF_complexes(result.CTR_input_cluster[\"control\"], table_ctr, \"script_test/\", \"control_cluster\")\n",
    "exp_input_cluster = combine_LR_and_TF_complexes(result.CTR_input_cluster[\"PMF,MF2\"], table_exp, \"script_test/\", \"PMF_MF2_cluster\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1231,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'LR2TF_test_run\\\\CTR_LR.csv'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1231], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m#WINDOWS\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m table_ctr \u001b[38;5;241m=\u001b[39m \u001b[43mpd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread_csv\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mLR2TF_test_run\u001b[39;49m\u001b[38;5;130;43;01m\\\\\u001b[39;49;00m\u001b[38;5;124;43mCTR_LR.csv\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      3\u001b[0m table_exp \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mread_csv(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mLR2TF_test_run\u001b[39m\u001b[38;5;130;01m\\\\\u001b[39;00m\u001b[38;5;124mEXP_LR.csv\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m      5\u001b[0m \u001b[38;5;66;03m#tmp= pd.read_csv(\"py_output_in_R.csv\")\u001b[39;00m\n",
      "File \u001b[0;32m~/.local/lib/python3.12/site-packages/pandas/io/parsers/readers.py:1026\u001b[0m, in \u001b[0;36mread_csv\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, date_format, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options, dtype_backend)\u001b[0m\n\u001b[1;32m   1013\u001b[0m kwds_defaults \u001b[38;5;241m=\u001b[39m _refine_defaults_read(\n\u001b[1;32m   1014\u001b[0m     dialect,\n\u001b[1;32m   1015\u001b[0m     delimiter,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1022\u001b[0m     dtype_backend\u001b[38;5;241m=\u001b[39mdtype_backend,\n\u001b[1;32m   1023\u001b[0m )\n\u001b[1;32m   1024\u001b[0m kwds\u001b[38;5;241m.\u001b[39mupdate(kwds_defaults)\n\u001b[0;32m-> 1026\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_read\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilepath_or_buffer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.local/lib/python3.12/site-packages/pandas/io/parsers/readers.py:620\u001b[0m, in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    617\u001b[0m _validate_names(kwds\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnames\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m))\n\u001b[1;32m    619\u001b[0m \u001b[38;5;66;03m# Create the parser.\u001b[39;00m\n\u001b[0;32m--> 620\u001b[0m parser \u001b[38;5;241m=\u001b[39m \u001b[43mTextFileReader\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilepath_or_buffer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    622\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m chunksize \u001b[38;5;129;01mor\u001b[39;00m iterator:\n\u001b[1;32m    623\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m parser\n",
      "File \u001b[0;32m~/.local/lib/python3.12/site-packages/pandas/io/parsers/readers.py:1620\u001b[0m, in \u001b[0;36mTextFileReader.__init__\u001b[0;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[1;32m   1617\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptions[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhas_index_names\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m kwds[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhas_index_names\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[1;32m   1619\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles: IOHandles \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m-> 1620\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_engine \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_make_engine\u001b[49m\u001b[43m(\u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mengine\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.local/lib/python3.12/site-packages/pandas/io/parsers/readers.py:1880\u001b[0m, in \u001b[0;36mTextFileReader._make_engine\u001b[0;34m(self, f, engine)\u001b[0m\n\u001b[1;32m   1878\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m mode:\n\u001b[1;32m   1879\u001b[0m         mode \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m-> 1880\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles \u001b[38;5;241m=\u001b[39m \u001b[43mget_handle\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1881\u001b[0m \u001b[43m    \u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1882\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1883\u001b[0m \u001b[43m    \u001b[49m\u001b[43mencoding\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mencoding\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1884\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcompression\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcompression\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1885\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmemory_map\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmemory_map\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1886\u001b[0m \u001b[43m    \u001b[49m\u001b[43mis_text\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mis_text\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1887\u001b[0m \u001b[43m    \u001b[49m\u001b[43merrors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mencoding_errors\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mstrict\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1888\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstorage_options\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mstorage_options\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1889\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1890\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1891\u001b[0m f \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles\u001b[38;5;241m.\u001b[39mhandle\n",
      "File \u001b[0;32m~/.local/lib/python3.12/site-packages/pandas/io/common.py:873\u001b[0m, in \u001b[0;36mget_handle\u001b[0;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[1;32m    868\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(handle, \u001b[38;5;28mstr\u001b[39m):\n\u001b[1;32m    869\u001b[0m     \u001b[38;5;66;03m# Check whether the filename is to be opened in binary mode.\u001b[39;00m\n\u001b[1;32m    870\u001b[0m     \u001b[38;5;66;03m# Binary mode does not support 'encoding' and 'newline'.\u001b[39;00m\n\u001b[1;32m    871\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m ioargs\u001b[38;5;241m.\u001b[39mencoding \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m ioargs\u001b[38;5;241m.\u001b[39mmode:\n\u001b[1;32m    872\u001b[0m         \u001b[38;5;66;03m# Encoding\u001b[39;00m\n\u001b[0;32m--> 873\u001b[0m         handle \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mopen\u001b[39;49m\u001b[43m(\u001b[49m\n\u001b[1;32m    874\u001b[0m \u001b[43m            \u001b[49m\u001b[43mhandle\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    875\u001b[0m \u001b[43m            \u001b[49m\u001b[43mioargs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    876\u001b[0m \u001b[43m            \u001b[49m\u001b[43mencoding\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mioargs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mencoding\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    877\u001b[0m \u001b[43m            \u001b[49m\u001b[43merrors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43merrors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    878\u001b[0m \u001b[43m            \u001b[49m\u001b[43mnewline\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m    879\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    880\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    881\u001b[0m         \u001b[38;5;66;03m# Binary mode\u001b[39;00m\n\u001b[1;32m    882\u001b[0m         handle \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mopen\u001b[39m(handle, ioargs\u001b[38;5;241m.\u001b[39mmode)\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'LR2TF_test_run\\\\CTR_LR.csv'"
     ]
    }
   ],
   "source": [
    "#WINDOWS\n",
    "table_ctr = pd.read_csv(\"LR2TF_test_run\\\\CTR_LR.csv\" )\n",
    "table_exp = pd.read_csv(\"LR2TF_test_run\\\\EXP_LR.csv\")\n",
    "\n",
    "#tmp= pd.read_csv(\"py_output_in_R.csv\")\n",
    "\n",
    "ctr_input = combine_LR_and_TF_complexes(result.CTR_input_condition[\"control\"], table_ctr, \"script_test/\", \"control\")\n",
    "exp_input = combine_LR_and_TF_complexes(result.CTR_input_condition[\"PMF,MF2\"], table_exp, \"script_test/\", \"PMF_MF2\")\n",
    "\n",
    "#ctr_input = combine_LR_and_TF_complexes(tmp, table_ctr, \"script_test/\", \"control\")\n",
    "\n",
    "ctr_input_cluster = combine_LR_and_TF_complexes(result.CTR_input_cluster[\"control\"], table_ctr, \"script_test/\", \"control_cluster\")\n",
    "exp_input_cluster = combine_LR_and_TF_complexes(result.CTR_input_cluster[\"PMF,MF2\"], table_exp, \"script_test/\", \"PMF_MF2_cluster\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "testpy",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
