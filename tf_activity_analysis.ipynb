{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import anndata as ad\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import scanpy as sc\n",
    "import decoupler as dc\n",
    "import os\n",
    "import re\n",
    "import statistics\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def validate_input_arguments (arguments_list):\n",
    "    if arguments_list[\"out_path\"] is None:\n",
    "        print(\"Please provide an output path\")\n",
    "    elif arguments_list[\"out_path\"][-1] != \"/\":\n",
    "        arguments_list[\"out_path\"] = arguments_list[\"out_path\"] + \"/\"\n",
    "\n",
    "    if arguments_list[\"celltype\"] is None:\n",
    "        print(\"Please provide the name of the metadata field containing cell type annotations\")\n",
    "\n",
    "    if arguments_list[\"condition\"] is None:\n",
    "        print(\"Please provide the name of the metadata field containing condition annotations\")\n",
    "\n",
    "    if arguments_list[\"organism\"] is None:\n",
    "        arguments_list[\"organism\"] = \"human\"\n",
    "\n",
    "    if arguments_list[\"comparison_list\"] is None:\n",
    "        arguments_list[\"comparison_list\"] = np.nan\n",
    "\n",
    "    if arguments_list[\"logfc\"] is None:\n",
    "        arguments_list[\"logfc\"] = 0.0\n",
    "\n",
    "    if arguments_list [\"pval\"] is None:\n",
    "        arguments_list[\"pval\"] = 0.05\n",
    "\n",
    "    if arguments_list[\"reg\"] is None:\n",
    "        arguments_list[\"reg\"] = load_dorothea_regulon(arguments_list[\"organism\"])\n",
    "\n",
    "    elif isinstance(arguments_list[\"reg\"], str):\n",
    "        arguments_list[\"reg\"] = pd.read_csv(arguments_list[\"reg\"], index_col=0)\n",
    "        arguments_list[\"reg\"] = pd.DataFrame.rename(arguments_list[\"reg\"], columns={\"source\" : \"tf\"})\n",
    "\n",
    "    if not \"tf\" in arguments_list[\"reg\"] and \"target\" in arguments_list[\"reg\"] and \"weight\"in arguments_list[\"reg\"]:\n",
    "        raise Exception(\"Not all necessary columns found in regulon table! Please make sure that the regulon has the columns source, target and weight!\")\n",
    "    \n",
    " \n",
    "   \n",
    "    return(arguments_list)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TFObj:\n",
    "    def __init__(self,\n",
    "    tf_activities_condition : list,\n",
    "    tf_activities_cluster : list,\n",
    "    average_gene_expression : list,\n",
    "    regulon : pd.DataFrame,\n",
    "    CTR_input_condition : list,\n",
    "    CTR_input_cluster : list,\n",
    "    intracellular_network_condition : list,\n",
    "    intracellular_network_cluster : list):\n",
    "\n",
    "        self.tf_activities_condition = tf_activities_condition\n",
    "        self.tf_activities_cluster = tf_activities_cluster\n",
    "        self.average_gene_expression = average_gene_expression\n",
    "        self.regulon = regulon\n",
    "        self.CTR_input_condition = CTR_input_condition\n",
    "        self.CTR_input_cluster = CTR_input_cluster\n",
    "        self.intracellular_network_condition = intracellular_network_condition\n",
    "        self.intracellular_network_cluster = intracellular_network_cluster\n",
    "\n",
    "def make_TFOBj(tf_activities_condition : list,\n",
    "    tf_activities_cluster : list,\n",
    "    average_gene_expression : list,\n",
    "    regulon : pd.DataFrame,\n",
    "    CTR_input_condition : list,\n",
    "    CTR_input_cluster : list,\n",
    "    intracellular_network_condition : list,\n",
    "    intracellular_network_cluster : list):\n",
    "\n",
    "        tf = TFObj(tf_activities_condition,\n",
    "            tf_activities_cluster,\n",
    "            average_gene_expression,\n",
    "            regulon,\n",
    "            CTR_input_condition,\n",
    "            CTR_input_cluster,\n",
    "            intracellular_network_condition,\n",
    "            intracellular_network_cluster)\n",
    "\n",
    "        return tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def AverageExpression(sub_object, celltype = None, name_iterable = None, outpath = None):\n",
    "    gene_ids = sub_object.var.index.values\n",
    "    #cluster line even necessary if not returned?\n",
    "    #clusters = anndataobject.obs[celltype].cat.categories\n",
    "    obs = sub_object[:,gene_ids].X.toarray()\n",
    "    obs = np.expm1(obs)\n",
    "    avg_df = pd.DataFrame(obs,columns=gene_ids,index= sub_object.obs[celltype])\n",
    "    avg_df = avg_df.groupby(level=0, observed=False).mean()\n",
    "    avg_df.T.to_csv(outpath + name_iterable + \"_average_gene_expression_by_cluster_exp.csv\")\n",
    "\n",
    "    return avg_df.T\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def eval_pval(p_val):\n",
    "    p_val = float(p_val)\n",
    "    if p_val < 0.001: \n",
    "      txt = \"***\"\n",
    "    elif p_val < 0.01: \n",
    "      txt = \"**\"\n",
    "    elif p_val < 0.05: \n",
    "      txt = \"*\"\n",
    "    else:\n",
    "      txt = \"ns\"\n",
    "    return(txt)\n",
    "\n",
    "\n",
    "def eval_log_fc_tag(log_fc):\n",
    "    if log_fc >= 1.0: \n",
    "      txt = \"***\"\n",
    "    elif log_fc > 0.5: \n",
    "      txt = \"**\"\n",
    "    elif log_fc > 0.0: \n",
    "      txt = \"*\"\n",
    "    else:\n",
    "      txt = \"ns\"\n",
    "    return(txt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_unfiltered_tf_scores(tf_scores_df, condition, celltype, out_path):   \n",
    "    summarized_tf_scores_df = tf_scores_df.groupby(celltype, observed = True).mean().T\n",
    "    #tf_scores_df.groupby(celltype, observed = True).apply(display)\n",
    "    #agg([\"mean\", \"var\"])\n",
    "    summarized_tf_scores_df.to_csv(out_path + \"/unfiltered_tf_scores_\" + condition + \".csv\")\n",
    "    return summarized_tf_scores_df\n",
    "\n",
    "#np.var() returns a value that is different from R's var(), whereas statistics.variance() is the same as R's var()\n",
    "def save_variable_tf_score(filtered_summarized_tf_scores_df, condition, out_path, plot):\n",
    "    filtered_summarized_tf_scores_df[\"var\"] = filtered_summarized_tf_scores_df.apply(statistics.variance, axis=1).unique()\n",
    "    filtered_summarized_tf_scores_df.to_csv(out_path + \"/variable_tf_scores_\" + condition + \".csv\")\n",
    "\n",
    "    if plot:\n",
    "        top_variable_tfs = filtered_summarized_tf_scores_df.sort_values(\"var\", ascending=False).head(n=20).drop(columns=\"var\")\n",
    "        fig, ax = plt.subplots(figsize=(8,7))   \n",
    "        ax = sns.heatmap(top_variable_tfs, cmap=\"vlag\", center=0, vmin=top_variable_tfs.min(axis=None), cbar_kws={\"label\": \"z-score\"})\n",
    "        ax.set(xlabel=\"Cell Type\", ylabel=\"Transcription Factor\")\n",
    "        ax.get_figure()\n",
    "        plt.savefig(out_path + \"/tf_activity_top20_variable_\" + condition + \".pdf\")\n",
    "        plt.close()\n",
    "\n",
    "    filtered_summarized_tf_scores_df_var = filtered_summarized_tf_scores_df\n",
    "    return filtered_summarized_tf_scores_df_var\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_tf_activity(filtered_summarized_tf_scores_df, tag_mapping, condition, out_path):\n",
    "    filtered_summarized_tf_scores_df = filtered_summarized_tf_scores_df.drop(columns=\"var\")\n",
    "    sns.clustermap(filtered_summarized_tf_scores_df, cbar_kws={\"label\": \"z-score\"}, figsize=(8,7), cmap=\"vlag\", center=0, yticklabels=False)\n",
    "    plt.savefig(out_path + \"/tf_activity_compressed_\" + condition + \".pdf\")\n",
    "    plt.close()\n",
    "\n",
    "    sns.clustermap(filtered_summarized_tf_scores_df, cbar_kws={\"label\": \"z-score\"}, figsize=(8,50), cmap=\"vlag\", center=0, annot= tag_mapping, fmt=\"\")\n",
    "    plt.savefig(out_path + \"/tf_activity_\" + condition + \".pdf\")\n",
    "    plt.close()\n",
    "\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def map_z_value_filtered(filtered_summarized_tf_scores_df, anndataobject_markers):\n",
    "    genes = []\n",
    "    clusters = []\n",
    "    z_scores = []  \n",
    "\n",
    "    anndataobject_markers = anndataobject_markers.set_index(\"gene\")\n",
    "    #print(filtered_summarized_tf_scores_df)\n",
    "    \n",
    "    for i in range(len(anndataobject_markers.index)):\n",
    "        a = anndataobject_markers.index[i]\n",
    "        for j in range(len(filtered_summarized_tf_scores_df.index)):\n",
    "            b = filtered_summarized_tf_scores_df.index[j]\n",
    "            if a == b:\n",
    "                c = anndataobject_markers.columns.get_loc(\"cluster\")\n",
    "                cluster = anndataobject_markers.iloc[i, c]\n",
    "                gene_rows = filtered_summarized_tf_scores_df.iloc[j]\n",
    "                if isinstance(gene_rows, pd.Series):\n",
    "                    gene_rows = gene_rows.to_frame().T\n",
    "\n",
    "                for _, gene_row in gene_rows.iterrows():\n",
    "                     score = gene_row[cluster]\n",
    "                     genes.append(a)\n",
    "                     clusters.append(cluster)\n",
    "                     z_scores.append(score)\n",
    "\n",
    "    z_score_df = pd.DataFrame({\n",
    "        'gene': genes,\n",
    "        'cluster': clusters,\n",
    "        'z_score': z_scores\n",
    "    })\n",
    "\n",
    "    return z_score_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_significant_tfs_single(tf_activities_sub, celltype, condition, out_path, pval, logfc, name, plot):\n",
    "    \n",
    "    #does not work if condition is None\n",
    "    renamed_condition = condition.replace(\",\", \"_\")\n",
    "    name = name.replace(\",\", \"_\")\n",
    "\n",
    "    single_result_path = out_path + renamed_condition \n",
    "    if not os.path.isdir(single_result_path):\n",
    "        os.mkdir(single_result_path)\n",
    "\n",
    "    tf_activities_scaled = sc.pp.scale(tf_activities_sub, copy= True)\n",
    "\n",
    "    #tf_activities_sub = sc.pp.normalize_total(tf_activities_scaled, copy=True)\n",
    "    #tf_activities_sub = sc.pp.log1p(tf_activities_sub, copy=True) \n",
    "    # \"warning: seems to be already log transformed\"\n",
    "\n",
    "    number_of_clusters = len(tf_activities_sub.obs[\"new_annotation\"].cat.categories) \n",
    "\n",
    "\n",
    "    sc.tl.rank_genes_groups(tf_activities_sub, groupby= \"new_annotation\", reference=\"rest\", method=\"wilcoxon\", key_added=\"wilcoxon_markers\", corr_method= \"bonferroni\")\n",
    "    #sc.tl.filter_rank_genes_groups(anndataobject, min_in_group_fraction=0, key=\"wilcoxon_markers\", key_added= \"wilcoxon_markers_filtered\")\n",
    "    \n",
    "\n",
    "    sc.tl.rank_genes_groups(tf_activities_sub, groupby= \"new_annotation\", reference=\"rest\", method=\"t-test_overestim_var\", key_added=\"t_test_overestim_var_markers\", corr_method= \"bonferroni\" )\n",
    "    #sc.tl.filter_rank_genes_groups(anndataobject, min_in_group_fraction=0, key=\"t_test_overestim_var_markers\", key_added=\"t_test_overestim_filtered\")\n",
    "\n",
    "\n",
    "    result1 = tf_activities_sub.uns['wilcoxon_markers']\n",
    "    groups = result1['names'].dtype.names\n",
    "    anndataobject_markers = pd.DataFrame(\n",
    "    {group + '_' + key[:1]: result1[key][group]\n",
    "    for group in groups for key in ['names','logfoldchanges','pvals','pvals_adj']})\n",
    "\n",
    "    result2 = tf_activities_sub.uns['t_test_overestim_var_markers']\n",
    "    groups = result2['names'].dtype.names\n",
    "    anndataobject_markers = pd.DataFrame(\n",
    "    {group + '_' + key[:1]: result2[key][group]\n",
    "    for group in groups for key in ['names','logfoldchanges','pvals','pvals_adj']})\n",
    "\n",
    "    anndataobject_markers_wilcoxon = sc.get.rank_genes_groups_df(tf_activities_sub, group = None, log2fc_min=0, key=\"wilcoxon_markers\")\n",
    "    \n",
    "    anndataobject_markers_wilcoxon.rename(columns={\"names\":\"gene\", \"group\": \"cluster\"}, inplace=True)\n",
    "    \n",
    "    #documentation says this won't update the main dataframe but will only overwrite a copy in future pandas versions (after v3)\n",
    "    anndataobject_markers_wilcoxon[\"tag\"] = None\n",
    "    anndataobject_markers_wilcoxon[\"log_fc_tag\"] = None\n",
    "    for i in range(len(anndataobject_markers_wilcoxon[\"pvals_adj\"])):\n",
    "         anndataobject_markers_wilcoxon[\"tag\"].iloc[i,] = eval_pval(anndataobject_markers_wilcoxon[\"pvals_adj\"].iloc[i,])\n",
    "         anndataobject_markers_wilcoxon[\"log_fc_tag\"].iloc[i,] = eval_log_fc_tag(anndataobject_markers_wilcoxon[\"logfoldchanges\"].iloc[i,])\n",
    "     \n",
    "\n",
    "    anndataobject_markers_wilcoxon.to_csv(single_result_path + \"/\" + name + \"_specific_markers_wilcoxon_test.csv\",index=0)\n",
    "\n",
    "    anndataobject_markers_t_over = sc.get.rank_genes_groups_df(tf_activities_sub, group = None, log2fc_min=0, key=\"t_test_overestim_var_markers\")\n",
    " \n",
    "    anndataobject_markers_t_over.rename(columns={\"names\":\"gene\", \"group\": \"cluster\"}, inplace=True)\n",
    "\n",
    "    anndataobject_markers_t_over[\"tag\"] = None\n",
    "    anndataobject_markers_t_over[\"log_fc_tag\"] = None\n",
    "    for i in range(len(anndataobject_markers_t_over[\"pvals_adj\"])):\n",
    "         anndataobject_markers_t_over[\"tag\"].iloc[i,] = eval_pval(anndataobject_markers_t_over[\"pvals_adj\"].iloc[i,])\n",
    "         anndataobject_markers_t_over[\"log_fc_tag\"].iloc[i,] = eval_pval(anndataobject_markers_t_over[\"logfoldchanges\"].iloc[i,])\n",
    "\n",
    "    anndataobject_markers_t_over.to_csv(single_result_path + \"/\" + name + \"_specific_markers_t_test_overestim_test.csv\",index=0)\n",
    "\n",
    "   #tag mapping wilcoxon\n",
    "    tag_mapping_wilcox = anndataobject_markers_wilcoxon[[\"gene\", \"tag\", \"log_fc_tag\", \"cluster\", \"pvals_adj\", \"logfoldchanges\"]]\n",
    "    tag_mapping_wilcox = tag_mapping_wilcox[(tag_mapping_wilcox[\"pvals_adj\"] < float(pval)) & \n",
    "                              ((tag_mapping_wilcox[\"logfoldchanges\"] > float(logfc)) | \n",
    "                              (tag_mapping_wilcox[\"logfoldchanges\"] < -float(logfc)))]\n",
    "\n",
    "    tag_mapping_wilcox = tag_mapping_wilcox.pivot(index=\"gene\", columns=\"cluster\", values=\"tag\")\n",
    "    clusters = anndataobject_markers_wilcoxon[\"cluster\"].unique()\n",
    "\n",
    "    for cluster in clusters:\n",
    "        if cluster not in tag_mapping_wilcox.columns:\n",
    "            tag_mapping_wilcox[cluster] = np.nan\n",
    "\n",
    "    tag_mapping_wilcox.fillna(\"ns\", inplace=True)\n",
    "\n",
    "    tf_activities_scaled.obs_names = tf_activities_scaled.obs[celltype]\n",
    "    tf_scores_df = tf_activities_scaled.to_df()\n",
    "    tf_scores_df.columns.name = None\n",
    "    unfiltered_tf_scores = create_unfiltered_tf_scores(tf_scores_df, condition, celltype, single_result_path)\n",
    "   \n",
    "    #Filter to only include tfs that match the tag_mapping/are markers\n",
    "    col_num = tf_scores_df.columns.isin(tag_mapping_wilcox.index)  \n",
    "    filtered_tf_scores_df = tf_scores_df.loc[:, col_num] \n",
    "    \n",
    "    filtered_summarized_tf_scores_df = filtered_tf_scores_df.groupby(celltype, observed = False).mean().T\n",
    "    filtered_summarized_tf_scores_df.index.name = \"gene\"\n",
    "    filtered_summarized_tf_scores_df.to_csv(f'{single_result_path}/tf_scores_{condition}.csv')\n",
    "    tf_scores_variable_table = save_variable_tf_score(filtered_summarized_tf_scores_df, condition, single_result_path, plot)\n",
    "\n",
    "    if plot:\n",
    "        plot_tf_activity(filtered_summarized_tf_scores_df, tag_mapping_wilcox, condition, single_result_path)\n",
    "    \n",
    "    #filtered_summarized_tf_scores_df.index = re.sub((\".,\"), \"_\", filtered_summarized_tf_scores_df.index)\n",
    "    anndataobject_markers_wilcoxon_merged = anndataobject_markers_wilcoxon.merge(map_z_value_filtered(filtered_summarized_tf_scores_df, anndataobject_markers_wilcoxon),  on=['gene', 'cluster'], how='inner')\n",
    "    anndataobject_markers_wilcoxon_merged = anndataobject_markers_wilcoxon_merged[anndataobject_markers_wilcoxon_merged.tag != \"ns\"]\n",
    "    anndataobject_markers_wilcoxon_merged.dropna(inplace=True)\n",
    "    res_wilcoxon = anndataobject_markers_wilcoxon_merged[[\"gene\",\"tag\", \"cluster\", \"z_score\"]]\n",
    "\n",
    "    #anndataobject_markers_t_over_merged = anndataobject_markers_t_over.merge(map_z_value_filtered(filtered_summarized_tf_scores_df, anndataobject_markers_t_over),  on=['gene', 'cluster'], how='inner')\n",
    "    #anndataobject_markers_t_over_merged = anndataobject_markers_t_over_merged[anndataobject_markers_t_over_merged.tag != \"ns\"]\n",
    "    #anndataobject_markers_t_over_merged.dropna(inplace=True)\n",
    "    #res_t_test = anndataobject_markers_t_over[[\"gene\",\"tag\", \"cluster\", \"z_score\"]]\n",
    "\n",
    "    res_wilcoxon.to_csv(single_result_path + \"/\" + name + \"_significant_markers_wilcoxon.csv\", index=0)\n",
    "    #res_t_test.to_csv(single_result_path + \"/\" + name + \"_significant_markers_t_test.csv\", index=0)\n",
    "\n",
    "     #//TODO: \n",
    "    #delete one variant and put test type as a variable\n",
    "\n",
    "    res = {}\n",
    "    res[\"cluster\"] = res_wilcoxon\n",
    "\n",
    "    return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#check if it's okay to not pre set the column type as string or float (maybe no problem in python but was problem in r)\n",
    "\n",
    "def create_empty_CTR_dataframe():\n",
    "  \n",
    "  empty_df = pd.DataFrame(\n",
    "    columns=[\n",
    "    \"source\",\n",
    "    \"target\",\n",
    "    \"gene_A\",\n",
    "    \"gene_B\",\n",
    "    \"type_gene_A\",\n",
    "    \"type_gene_B\",\n",
    "    \"MeanLR\"\n",
    "    ])\n",
    "  \n",
    "  return(empty_df)\n",
    "\n",
    "\n",
    "def add_entry_to_CTR_dataframe(source, target, gene_A, gene_B, type_gene_A, type_gene_B, MeanLR, row):\n",
    "  df = pd.DataFrame(\n",
    "      {\"source\" : source,\n",
    "      \"target\" : target,\n",
    "      \"gene_A\" : gene_A,\n",
    "      \"gene_B\" : gene_B,\n",
    "      \"type_gene_A\" : type_gene_A,\n",
    "      \"type_gene_B\" : type_gene_B,\n",
    "      \"MeanLR\" : MeanLR}, index=[row])\n",
    "\n",
    "  return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_CrossTalkeR_input(tf_activities, gene_expression, out_path, regulon = None):\n",
    "\n",
    "  ligands = pd.read_csv(\"ligands_human.csv\")\n",
    "  R2TF = pd.read_csv(\"rtf_db.csv\")\n",
    "\n",
    "  sorted_regulon = regulon[[\"tf\", \"target\"]]\n",
    "  #sorted_regulon.rename(columns={\"target\" : \"targets\"})\n",
    "  sorted_regulon = sorted_regulon.set_index(\"tf\")\n",
    "\n",
    "  R2TF = R2TF.set_index(\"tf\")\n",
    "  output_df = create_empty_CTR_dataframe()\n",
    "  tf_l = create_empty_CTR_dataframe()\n",
    "  r_tf = create_empty_CTR_dataframe()\n",
    "\n",
    "  for row in range(len((tf_activities))):\n",
    "\n",
    "    #if (tf_activities[\"z_score\"].iloc[row] > 0):\n",
    "    tf = str(tf_activities[\"gene\"].iloc[row])\n",
    "    if tf in sorted_regulon.index:\n",
    "      targets = sorted_regulon.loc[tf, \"target\"]\n",
    "\n",
    "    if tf in R2TF.index:\n",
    "        receptors = R2TF.loc[tf, \"receptor\"]\n",
    "\n",
    "    else:\n",
    "        receptors = []\n",
    "    tf_ligands = np.intersect1d(targets, ligands)\n",
    "\n",
    "    if len(tf_ligands) > 0:\n",
    "      for ligand in tf_ligands:\n",
    "          expressed = False\n",
    "          if ligand in gene_expression.index:\n",
    "            ex_value = gene_expression.loc[ligand, tf_activities.iloc[row, 2]]\n",
    "            if (ex_value != 0):\n",
    "              expressed = True\n",
    "          \n",
    "          df_list_l = []\n",
    "            \n",
    "          if (expressed == True):\n",
    "            df_list_l = add_entry_to_CTR_dataframe(source = tf_activities.iloc[row, 2],\n",
    "                                                    target = tf_activities.iloc[row, 2],\n",
    "                                                    gene_A =tf_activities.iloc[row, 0],\n",
    "                                                    gene_B = ligand,\n",
    "                                                    type_gene_A = \"Transcription_Factor\",\n",
    "                                                    type_gene_B= \"Ligand\",\n",
    "                                                    MeanLR= tf_activities.iloc[row, 3],\n",
    "                                                    row= row)\n",
    "              \n",
    "            tf_l = pd.concat([tf_l, df_list_l], ignore_index=True)\n",
    "            \n",
    "    \n",
    "      if (len(receptors) > 0):\n",
    "        for receptor in receptors:\n",
    "          df_list_r = [] \n",
    "          df_list_r = add_entry_to_CTR_dataframe(tf_activities.iloc[row, 2],\n",
    "                                              tf_activities.iloc[row, 2],\n",
    "                                              receptor,\n",
    "                                              tf_activities.iloc[row, 0],\n",
    "                                              \"Receptor\",\n",
    "                                              \"Transcription Factor\",\n",
    "                                              tf_activities.iloc[row, 3],\n",
    "                                              row)\n",
    "              \n",
    "          print(df_list_r)\n",
    "            \n",
    "          r_tf = pd.concat([r_tf, df_list_r], ignore_index=True)\n",
    "\n",
    "      #tf_l.to_csv(single_result_path + \"/\" + renamed_condition + \"_ctr_test_l.csv\", index=0)\n",
    "      #r_tf.to_csv(single_result_path + \"/\" + renamed_condition + \"_ctr_test_r.csv\", index=0)\n",
    "\n",
    "  #    r_tf[\"gene_A\"] <- gsub(\"_\", \"+\", r_tf$gene_A, fixed = TRUE)\n",
    "   #   r_tf[\"gene_B\"] <- gsub(\"_\", \"+\", r_tf$gene_B, fixed = TRUE)\n",
    "   #   tf_l[\"gene_A\"] <- gsub(\"_\", \"+\", tf_l$gene_A, fixed = TRUE)\n",
    "   #   tf_l[\"gene_B\"] <- gsub(\"_\", \"+\", tf_l$gene_B, fixed = TRUE)\n",
    "\n",
    "  output_df = pd.concat([output_df, r_tf], ignore_index=True)\n",
    "  output_df = pd.concat([output_df, tf_l], ignore_index=True)\n",
    "  #output_df.to_csv(\"tf_l_r.csv\", index=0)\n",
    "\n",
    "\n",
    "  return output_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_intracellular_network(tf_activity_scores, gene_expression_list, outpath, regulon, organism = \"human\"):\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#ignore extra tfs from decoupler while writing script \n",
    "\n",
    "def tf_activity_analysis (anndataobject, arguments_list = None):\n",
    "    \n",
    "    if (isinstance(anndataobject, str)):\n",
    "        anndataobject = ad.read_h5ad(anndataobject)\n",
    "\n",
    "    arguments_list = validate_input_arguments(arguments_list)\n",
    "\n",
    "    if not os.path.isdir(arguments_list[\"out_path\"]):\n",
    "        os.mkdir(arguments_list[\"out_path\"])\n",
    "        tf_path = arguments_list[\"out_path\"] + \"TF_results/\"\n",
    "        os.mkdir(tf_path)\n",
    "    else:\n",
    "        tf_path = arguments_list[\"out_path\"] + \"TF_results/\"\n",
    "\n",
    "    #rename the arguments inserted into argument list (eg protocol to condition)(unfinished)\n",
    "    condition = anndataobject.obs[arguments_list[\"condition\"]]\n",
    "\n",
    "    #checks for tf activity csv, if nothing there, runs decoupler\n",
    "    if isinstance(arguments_list[\"tf_activities\"], str):\n",
    "         tf_activities = ad.read_csv(arguments_list[\"tf_activities\"])\n",
    "         #print(tf_activities.obs.index)\n",
    "         tf_activities.obs = anndataobject.obs.reindex(tf_activities.obs.index)\n",
    "         tf_activities.obsm = anndataobject.obsm\n",
    "         tf_activities.uns = anndataobject.uns\n",
    "    elif arguments_list[\"tf_activities\"] is None:\n",
    "         dc.run_ulm(mat = anndataobject, net = (arguments_list[\"reg\"]), source ='tf', target ='target', weight ='weight', verbose = True, use_raw = False)\n",
    "         tf_activities = anndataobject.obsm['ulm_estimate']\n",
    "         tf_activities.to_csv(\"decoupler_results_test.csv\")\n",
    "\n",
    "    #sets the stage for decision if single condition or comparison analysis is done\n",
    "\n",
    "    if not np.isnan(arguments_list[\"comparison_list\"]):\n",
    "        if len(arguments_list[\"comparison_list\"]) > 0 & len(anndataobject.obs[\"comparison_list\"]) < 2:\n",
    "            arguments_list[\"comparison_list\"] <- np.nan\n",
    "            print(\"Only one condition was found in the data, although a list of comparisons was provided. The analyses are performed only for the present condition!\")\n",
    "\n",
    "    #code for single condition  analysis\n",
    "\n",
    "    if np.isnan(arguments_list[\"comparison_list\"]):\n",
    "\n",
    "        result_list = {}\n",
    "        gene_expression_list = {}\n",
    "        CTR_cluster_list = {}\n",
    "        intranet_cluster_list = {}\n",
    "\n",
    "        #creates loop until after tf activity score\n",
    "        \n",
    "        for name_iterable in anndataobject.obs.protocol.unique():\n",
    "            sub_object = anndataobject[anndataobject.obs.protocol == name_iterable]\n",
    "            tf_activities_sub = tf_activities[tf_activities.obs.protocol == name_iterable]\n",
    "\n",
    "            sub_object_avg = AverageExpression(sub_object, name_iterable= name_iterable, celltype = arguments_list[\"celltype\"], outpath= arguments_list[\"out_path\"])\n",
    "            \n",
    "            #check how sub object is returned by average expression (subobject.T) or rename return?\n",
    "            tf_activity_scores = get_significant_tfs_single(tf_activities_sub, celltype = arguments_list[\"celltype\"],condition = name_iterable, out_path= tf_path, pval = arguments_list[\"pval\"], logfc = arguments_list[\"logfc\"], name = name_iterable, plot = arguments_list[\"plot\"])\n",
    "\n",
    "            #result_condition_list[[name_iterable]] = tf_activity_scores[]\n",
    "            result_list[name_iterable] = tf_activity_scores\n",
    "            #turn them into dictionaries?\n",
    "            \n",
    "            gene_expression_list[name_iterable] = sub_object_avg\n",
    "            \n",
    "            if (arguments_list[\"organism\"] == \"human\"):\n",
    "            \n",
    "                CTR_cluster_list[name_iterable] = generate_CrossTalkeR_input(tf_activity_scores[\"cluster\"],\n",
    "                                                                            gene_expression_list[name_iterable],\n",
    "                                                                            arguments_list[\"out_path\"],                                             \n",
    "                                                                            arguments_list[\"reg\"])\n",
    "    \n",
    "            #else:\n",
    "   \n",
    "            #    CTR_cluster_list[[name_iterable]] = generate_CrossTalkeR_input_mouse(tf_activity_scores[\"cluster\"],\n",
    "            #                                                                        gene_expression_list[name_iterable]\n",
    "            #                                                                        arguments_list[\"out_path\"],\n",
    "            #                                                                        arguments_list[\"reg\"])\n",
    "              \n",
    "            intranet_cluster_list[name_iterable] = generate_intracellular_network(tf_activity_scores[\"cluster\"],\n",
    "                                                                                  gene_expression_list[name_iterable],\n",
    "                                                                                  arguments_list[\"out_path\"],\n",
    "                                                                                  arguments_list[\"reg\"],\n",
    "                                                                                  arguments_list[\"organism\"])\n",
    "            \n",
    "            tf = make_TFOBj(\n",
    "                tf_activities_condition = list(),\n",
    "                tf_activities_cluster = result_list,\n",
    "                average_gene_expression = gene_expression_list,\n",
    "                regulon = arguments_list[\"reg\"],\n",
    "                CTR_input_condition = list(),\n",
    "                CTR_input_cluster = CTR_cluster_list,\n",
    "                intracellular_network_condition = list(),\n",
    "                intracellular_network_cluster = intranet_cluster_list)\n",
    "\n",
    "        return tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result = tf_activity_analysis(anndataobject= \"LR2TF_test_run/anndata_object.h5ad\", arguments_list= {\"out_path\" : \"script_test\", \"celltype\" : \"new_annotation\", \"condition\" : \"protocol\", \"organism\" : None, \"comparison_list\" : None, \"logfc\" : \"0\", \"pval\" : None, \"reg\" : \"filterd_regulon.csv\", \"tf_activities\" : \"decoupler_results.csv\", \"plot\" : True})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_node_type(df):\n",
    "  df = mutate(gene_A = ifelse(type_gene_A == \"Ligand\", paste0(gene_A, \"|L\"), gene_A))\n",
    "\n",
    "  df = mutate(gene_A = ifelse(type_gene_A == \"Receptor\", paste0(gene_A, \"|R\"), gene_A))\n",
    "\n",
    "  df = mutate(gene_A = ifelse(type_gene_A == \"Transcription Factor\", paste0(gene_A, \"|TF\"), gene_A))\n",
    "  \n",
    "  df = mutate(gene_B = ifelse(type_gene_B == \"Ligand\", paste0(gene_B, \"|L\"), gene_B))\n",
    "  df <- df %>%\n",
    "    mutate(gene_B = ifelse(type_gene_B == \"Receptor\", paste0(gene_B, \"|R\"), gene_B))\n",
    "  df <- df %>%\n",
    "    mutate(gene_B = ifelse(type_gene_B == \"Transcription Factor\", paste0(gene_B, \"|TF\"), gene_B))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def combine_LR_and_TF(tf_table, LR_prediction, out_path, condition, add_node_type = False):\n",
    "\n",
    "  if isinstance(LR_prediction, pd.DataFrame):\n",
    "    lr_table = LR_prediction\n",
    "  else: \n",
    "    #fix this\n",
    "    lr_table = read.csv(LR_prediction)\n",
    "    lr_table.rownames = lr_table.columns[\"X\"]\n",
    "    lr_table.columns[\"X\"] = None\n",
    "\n",
    "  lr_ligands = np.unique(lr_table[\"gene_A\"])\n",
    "  lr_receptors = np.unique(lr_table[\"gene_B\"])\n",
    "  \n",
    "  tf_receptor_interactions =  tf_table[tf_table['gene_A'].isin(lr_receptors)]\n",
    "  tf_ligand_interactions = tf_table[tf_table[\"gene_B\"].isin(lr_ligands)]\n",
    "\n",
    "  complete_interactions = pd.concat([tf_receptor_interactions, tf_ligand_interactions])\n",
    "  complete_interactions = pd.concat([complete_interactions, lr_table])\n",
    "  if (add_node_type):\n",
    "    complete_interactions = add_node_type(complete_interactions)\n",
    "    \n",
    "  complete_interactions.to_csv((out_path + \"CrossTalkeR_input_\" + condition + \".csv\"), index=0)\n",
    "  return(complete_interactions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#LINUX\n",
    "table_ctr = pd.read_csv(\"/home/larissa/Documents/LR2TF_HiWi/LR2TF_test_run/CTR_LR.csv\")\n",
    "table_exp = pd.read_csv(\"/home/larissa/Documents/LR2TF_HiWi/LR2TF_test_run/EXP_LR.csv\")\n",
    "\n",
    "ctr_input = combine_LR_and_TF(result.CTR_input_cluster[\"control\"], table_ctr, \"script_test/\", \"control\")\n",
    "exp_input = combine_LR_and_TF(result.CTR_input_cluster[\"PMF,MF2\"], table_exp, \"script_test/\", \"PMF_MF2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#WINDOWS\n",
    "table_ctr = pd.read_csv(\"LR2TF_test_run\\\\CTR_LR.csv\")\n",
    "table_exp = pd.read_csv(\"LR2TF_test_run\\\\EXP_LR.csv\")\n",
    "\n",
    "ctr_input = combine_LR_and_TF(result.CTR_input_cluster[\"control\"], table_ctr, \"script_test/\", \"control\")\n",
    "exp_input = combine_LR_and_TF(result.CTR_input_cluster[\"PMF,MF2\"], table_exp, \"script_test/\", \"PMF_MF2\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
